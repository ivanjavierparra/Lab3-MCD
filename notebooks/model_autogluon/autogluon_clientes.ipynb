{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b63502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9b1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellin = pd.read_csv(\"datasets/sell-in.csv\", sep='\\t')\n",
    "productos = pd.read_csv(\"datasets/tb_productos.csv\", sep='\\t')\n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87af7d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell-In: 2945818 filas y 7 columnas\n",
      "Productos: 1262 filas y 6 columnas\n",
      "Stocks: 13691 filas y 3 columnas\n"
     ]
    }
   ],
   "source": [
    "# VerificaciÃ³n inicial\n",
    "print(f\"Sell-In: {sellin.shape[0]} filas y {sellin.shape[1]} columnas\")\n",
    "print(f\"Productos: {productos.shape[0]} filas y {productos.shape[1]} columnas\")\n",
    "print(f\"Stocks: {stocks.shape[0]} filas y {stocks.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8d8944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas-Productos-Stocks: 2988650 filas y 13 columnas\n"
     ]
    }
   ],
   "source": [
    "# 3. MERGE INICIAL\n",
    "df = sellin.merge(productos, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(f\"Ventas-Productos-Stocks: {df.shape[0]} filas y {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3560cda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 6)\n"
     ]
    }
   ],
   "source": [
    "productos_clean = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "print(productos_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8ecba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2945818, 7)\n",
      "(2945818, 13)\n"
     ]
    }
   ],
   "source": [
    "df = sellin.merge(productos_clean, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(sellin.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a650eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  product_id  customer_id        tn\n",
      "0   201701       20001        10234   0.33579\n",
      "1   201701       20001        10032  12.31230\n",
      "2   201701       20001        10217   0.00000\n",
      "3   201701       20001        10125   0.08954\n",
      "4   201701       20001        10012   6.97324\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que df ya contiene las columnas: periodo, customer_id, product_id, tn\n",
    "df[\"periodo_dt\"] = pd.to_datetime(df[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "# Paso 1: Rango total de periodos\n",
    "todos_los_periodos = pd.date_range(start=df[\"periodo_dt\"].min(), end=df[\"periodo_dt\"].max(), freq=\"MS\")\n",
    "\n",
    "# Paso 2: Todos los clientes Ãºnicos\n",
    "todos_los_clientes = df[\"customer_id\"].unique()\n",
    "\n",
    "# Paso 3: Determinar vida Ãºtil de cada producto\n",
    "vida_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Paso 4: Generar combinaciones (periodo, producto) considerando restricciones\n",
    "combinaciones_producto_periodo = []\n",
    "fecha_limite_nuevos = pd.to_datetime(\"2017-03\", format=\"%Y-%m\")\n",
    "\n",
    "# Los productos de 35 y 36 meeses de vida son considerados \"vitales\"\n",
    "productos_vitales = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "mask = (productos_vitales['min'] == '2017-01-01') & ((productos_vitales['max'] == '2019-12-01'))\n",
    "productos_vitales = productos_vitales[mask]['product_id'].unique()  \n",
    "\n",
    "for _, row in vida_producto.iterrows():\n",
    "    producto = row[\"product_id\"]\n",
    "    min_fecha = row[\"min\"]\n",
    "    max_fecha = row[\"max\"]\n",
    "    periodos_validos = pd.date_range(start=min_fecha, end=max_fecha, freq=\"MS\")\n",
    "    es_nuevo = min_fecha >= fecha_limite_nuevos  # solo si el producto es nuevo a partir de 2017-02\n",
    "    \n",
    "    for p in periodos_validos:\n",
    "        if producto in productos_vitales:\n",
    "            combinaciones_producto_periodo.append((p, producto))\n",
    "            continue\n",
    "        # Excluir primeros 3 meses si es nuevo (a partir de 2017-02)\n",
    "        if es_nuevo and (p < min_fecha + pd.DateOffset(months=3)):\n",
    "            continue\n",
    "        # Excluir Ãºltimos 3 meses del producto\n",
    "        if p > max_fecha - pd.DateOffset(months=3):\n",
    "            continue\n",
    "        combinaciones_producto_periodo.append((p, producto))\n",
    "\n",
    "df_producto_periodo = pd.DataFrame(combinaciones_producto_periodo, columns=[\"periodo_dt\", \"product_id\"])\n",
    "\n",
    "# Paso 5: Generar combinaciones de todos los clientes con (periodo, producto)\n",
    "combinaciones = []\n",
    "for _, row in df_producto_periodo.iterrows():\n",
    "    periodo = row[\"periodo_dt\"]\n",
    "    producto = row[\"product_id\"]\n",
    "    for cliente in todos_los_clientes:\n",
    "        # if producto in df[df[\"customer_id\"] == cliente][\"product_id\"].unique(): ###### <------ ESTO TARDA 3 AÃ‘OS\n",
    "        combinaciones.append((periodo, producto, cliente)) \n",
    "\n",
    "df_completo = pd.DataFrame(combinaciones, columns=[\"periodo_dt\", \"product_id\", \"customer_id\"])\n",
    "\n",
    "# Paso 6: Unir con toneladas efectivas\n",
    "df_merge = df_completo.merge(df[[\"periodo_dt\", \"product_id\", \"customer_id\", \"tn\"]],\n",
    "                             on=[\"periodo_dt\", \"product_id\", \"customer_id\"],\n",
    "                             how=\"left\")\n",
    "df_merge[\"tn\"] = df_merge[\"tn\"].fillna(0)\n",
    "\n",
    "# Paso 7: Recuperar periodo AAAAMM si lo necesitÃ¡s\n",
    "df_merge[\"periodo\"] = df_merge[\"periodo_dt\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "\n",
    "# Resultado final\n",
    "df_final = df_merge[[\"periodo\", \"product_id\", \"customer_id\", \"tn\"]]\n",
    "\n",
    "# Vista previa\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9a94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['item_id'] = df_final['customer_id'].astype(str) + '_' + df_final['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a41047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"periodo_dt\"] = pd.to_datetime(df_final[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb83099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>item_id</th>\n",
       "      <th>periodo_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>10234</td>\n",
       "      <td>0.33579</td>\n",
       "      <td>10234_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>10032</td>\n",
       "      <td>12.31230</td>\n",
       "      <td>10032_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>10217</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10217_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>10125</td>\n",
       "      <td>0.08954</td>\n",
       "      <td>10125_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>10012</td>\n",
       "      <td>6.97324</td>\n",
       "      <td>10012_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  product_id  customer_id        tn      item_id periodo_dt\n",
       "0   201701       20001        10234   0.33579  10234_20001 2017-01-01\n",
       "1   201701       20001        10032  12.31230  10032_20001 2017-01-01\n",
       "2   201701       20001        10217   0.00000  10217_20001 2017-01-01\n",
       "3   201701       20001        10125   0.08954  10125_20001 2017-01-01\n",
       "4   201701       20001        10012   6.97324  10012_20001 2017-01-01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6225ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=[\"customer_id\", \"product_id\", \"periodo\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c710e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>item_id</th>\n",
       "      <th>periodo_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.33579</td>\n",
       "      <td>10234_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.31230</td>\n",
       "      <td>10032_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>10217_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08954</td>\n",
       "      <td>10125_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.97324</td>\n",
       "      <td>10012_20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tn      item_id periodo_dt\n",
       "0   0.33579  10234_20001 2017-01-01\n",
       "1  12.31230  10032_20001 2017-01-01\n",
       "2   0.00000  10217_20001 2017-01-01\n",
       "3   0.08954  10125_20001 2017-01-01\n",
       "4   6.97324  10012_20001 2017-01-01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39f7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.rename(columns={'periodo_dt': 'timestamp', 'tn': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d930fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10234_20001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.33579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032_20001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>12.31230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10217_20001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125_20001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.08954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012_20001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>6.97324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10591_21281</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559_21281</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560_21281</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10582_21281</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10572_21281</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16976292 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          target\n",
       "item_id     timestamp           \n",
       "10234_20001 2017-01-01   0.33579\n",
       "10032_20001 2017-01-01  12.31230\n",
       "10217_20001 2017-01-01   0.00000\n",
       "10125_20001 2017-01-01   0.08954\n",
       "10012_20001 2017-01-01   6.97324\n",
       "...                          ...\n",
       "10591_21281 2017-05-01   0.00000\n",
       "10559_21281 2017-05-01   0.00000\n",
       "10560_21281 2017-05-01   0.00000\n",
       "10582_21281 2017-05-01   0.00000\n",
       "10572_21281 2017-05-01   0.00000\n",
       "\n",
       "[16976292 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TimeSeriesDataFrame(df_final)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f5cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž NÃºmero de series: 662670\n",
      "ðŸ”Ž Longitudes por serie:\n",
      "count    662670.000000\n",
      "mean         25.618018\n",
      "std          12.336436\n",
      "min           1.000000\n",
      "25%          15.000000\n",
      "50%          36.000000\n",
      "75%          36.000000\n",
      "max          36.000000\n",
      "dtype: float64\n",
      "ðŸ”Ž Target - estadÃ­sticas globales:\n",
      "count    1.697629e+07\n",
      "mean     7.560725e-02\n",
      "std      1.297295e+00\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      5.478785e+02\n",
      "Name: target, dtype: float64\n",
      "ðŸ”Ž NaN en target: 0\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” 3ï¸âƒ£ Validar datos antes de fit\n",
    "print(f\"ðŸ”Ž NÃºmero de series: {data.num_items}\")\n",
    "print(f\"ðŸ”Ž Longitudes por serie:\\n{data.num_timesteps_per_item().describe()}\")\n",
    "print(f\"ðŸ”Ž Target - estadÃ­sticas globales:\\n{data['target'].describe()}\")\n",
    "print(f\"ðŸ”Ž NaN en target: {data['target'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e20b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_series = data.num_timesteps_per_item() >= 3\n",
    "valid_item_ids = valid_series[valid_series].index\n",
    "data = data[data.index.get_level_values('item_id').isin(valid_item_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9698fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo productos a predecir\n",
    "productos_ids = productos_a_predecir['product_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a36222cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frequency 'M' stored as 'ME'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 60s\n",
      "AutoGluon will save models to 'c:\\Users\\iparra\\Documents\\GestionDeDatos\\Austral\\Lab3\\Lab3-MCD-main\\Lab3-MCD-main\\AutogluonModels\\ag-20250531_013034'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.4\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          24\n",
      "GPU Count:          0\n",
      "Memory Avail:       0.92 GB / 15.67 GB (5.9%)\n",
      "Disk Space Avail:   120.72 GB / 446.17 GB (27.1%)\n",
      "===================================================\n",
      "Setting presets to: fast_training\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'ME',\n",
      " 'hyperparameters': 'very_light',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 60,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'MS' has been resampled to frequency 'ME'.\n",
      "Provided train_data has 16939278 rows, 636999 time series. Median time series length is 36 (min=3, max=36). \n",
      "\tRemoving 53730 short time series from train_data. Only series with length >= 7 will be used for training.\n",
      "\tAfter filtering, train_data has 16729134 rows, 583269 time series. Median time series length is 36 (min=7, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-05-30 22:55:01\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta']\n",
      "Stopping training due to lack of time remaining. Time left: -1671.0 seconds\n",
      "Not fitting ensemble due to lack of time remaining. Time left: -1671.0 seconds\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 265.19 s\n",
      "Trainer has no fit models that can predict.\n",
      "data with frequency 'MS' has been resampled to frequency 'ME'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m TimeSeriesPredictor(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(data,time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,presets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfast_training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogluon\\timeseries\\predictor.py:859\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.predict\u001b[1;34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m known_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_data_frame(known_covariates)\n\u001b[1;32m--> 859\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(TimeSeriesDataFrame, predictions\u001b[38;5;241m.\u001b[39mreindex(original_item_id_order, level\u001b[38;5;241m=\u001b[39mITEMID))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogluon\\timeseries\\learner.py:174\u001b[0m, in \u001b[0;36mTimeSeriesLearner.predict\u001b[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform_future_known_covariates(known_covariates)\n\u001b[0;32m    173\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_covariates_with_forecast_index(known_covariates\u001b[38;5;241m=\u001b[39mknown_covariates, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogluon\\timeseries\\trainer.py:778\u001b[0m, in \u001b[0;36mTimeSeriesTrainer.predict\u001b[1;34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    772\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m     random_seed: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeSeriesDataFrame:\n\u001b[1;32m--> 778\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m     model_pred_dict, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_pred_dict(\n\u001b[0;32m    780\u001b[0m         model_names\u001b[38;5;241m=\u001b[39m[model_name],\n\u001b[0;32m    781\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    784\u001b[0m         random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    786\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model_pred_dict[model_name]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogluon\\timeseries\\trainer.py:754\u001b[0m, in \u001b[0;36mTimeSeriesTrainer._get_model_for_prediction\u001b[1;34m(self, model, verbose)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 754\u001b[0m         best_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;241m=\u001b[39m best_model_name\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\autogluon\\timeseries\\trainer.py:214\u001b[0m, in \u001b[0;36mTimeSeriesTrainer.get_model_best\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(target='target', prediction_length=2, freq=\"M\").fit(data,time_limit=60,presets='fast_training')\n",
    "predictions = predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5aac91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>1302.976815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20002</td>\n",
       "      <td>1102.488131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>666.269509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20004</td>\n",
       "      <td>550.978395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20005</td>\n",
       "      <td>577.405090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           tn\n",
       "1       20001  1302.976815\n",
       "3       20002  1102.488131\n",
       "5       20003   666.269509\n",
       "7       20004   550.978395\n",
       "9       20005   577.405090"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_v1 = predictions.copy()\n",
    "predictions_v1 = predictions_v1.reset_index()\n",
    "predictions_v1 = predictions_v1[[\"item_id\", \"timestamp\", \"mean\"]]\n",
    "predictions_v1 = predictions_v1[predictions_v1.timestamp == \"2020-02-29\"]\n",
    "predictions_v1 = predictions_v1.drop(columns = {\"timestamp\"})\n",
    "predictions_v1 = predictions_v1.rename(columns = {\"item_id\":\"product_id\", \"mean\":\"tn\"})\n",
    "predictions_v1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a60e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1 = predictions_v1[predictions_v1['product_id'].isin(productos_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb4a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1.to_csv(\"./kaggle/predictions_autogluon.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
