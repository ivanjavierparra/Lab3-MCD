{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee82db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a45cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTOY_EN_KAGGLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3b1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        # Arquitectura\n",
    "        \"lstm_units_1\": 64,\n",
    "        \"lstm_units_2\": 32,\n",
    "        \"dense_units\": 16,\n",
    "        \"dropout_rate\": 0.3,\n",
    "\n",
    "        # Entrenamiento\n",
    "        \"epochs\": 150,\n",
    "        \"batch_size\": 250,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"learning_rate\": None,  # Si querés usar Adam con tasa específica\n",
    "\n",
    "        # Regularización\n",
    "        \"l2_lambda\": 0.001,\n",
    "\n",
    "        # Optimizador\n",
    "        \"optimizer\": \"rmsprop\",  # adam, sgd, rmsprop, etc.\n",
    "\n",
    "        # Preprocesamiento\n",
    "        \"scaler_name\": \"robust\",  # standard o robust\n",
    "\n",
    "        # Ventana temporal\n",
    "        \"window_size\": 3,\n",
    "        \"feature_cols\" : ['tn', 'tn_lag1', \n",
    "                          #'tn_lag6', \n",
    "                          #'tn_lag12', \n",
    "                          'tn_diff1', \n",
    "                          #'tn_diff6',\n",
    "                'rolling_mean3', 'rolling_std3', 'rolling_max3', 'rolling_min3','rolling_max6','rolling_min6',\"size\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f76caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31362, 12)\n"
     ]
    }
   ],
   "source": [
    "if ESTOY_EN_KAGGLE:\n",
    "    df = pd.read_csv(\"../entregable/datasets/periodo_x_producto_con_target_transformado_con_feature_engineering_201912.csv\", sep=',', encoding='utf-8')\n",
    "else:\n",
    "    # Cargar de nuevo por claridad\n",
    "    df = pd.read_csv(\"../../data/raw/sell-in.csv\", sep=\"\\t\")\n",
    "\n",
    "df[\"periodo\"] = pd.to_datetime(df[\"periodo\"], format=\"%Y%m\")\n",
    "\n",
    "# Agregación mensual por producto\n",
    "df = df.groupby([\"product_id\", \"periodo\"]).agg({\"tn\": \"sum\"}).sort_values([\"product_id\", \"periodo\"]).reset_index()\n",
    "\n",
    "# Crear características por producto\n",
    "def agregar_features(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([\"product_id\", \"periodo\"])\n",
    "    \n",
    "    # Crear features con groupby + transform\n",
    "    df[\"tn_lag1\"] = df.groupby(\"product_id\")[\"tn\"].shift(1)\n",
    "    #df[\"tn_lag6\"] = df.groupby(\"product_id\")[\"tn\"].shift(6)\n",
    "    #df[\"tn_lag12\"] = df.groupby(\"product_id\")[\"tn\"].shift(12)\n",
    "\n",
    "    df[\"tn_diff1\"] = df[\"tn\"] - df[\"tn_lag1\"]\n",
    "    #df[\"tn_diff6\"] = df[\"tn\"] - df[\"tn_lag6\"]\n",
    "    df[\"size\"] = df.groupby(\"product_id\")[\"tn\"].transform(\"size\")\n",
    "    \n",
    "\n",
    "    df[\"rolling_mean3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).mean())\n",
    "    df[\"rolling_std3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).std())\n",
    "    \n",
    "    df[\"rolling_max3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).max())\n",
    "    df[\"rolling_min3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).min())\n",
    "    df[\"rolling_max6\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(6).max())\n",
    "    df[\"rolling_min6\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(6).min())\n",
    "\n",
    "    return df\n",
    "\n",
    "df_features = agregar_features(df).fillna(0)\n",
    "del df\n",
    "gc.collect()\n",
    "print(df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d921303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25844, 12)\n"
     ]
    }
   ],
   "source": [
    "# Último período disponible\n",
    "ultimo_mes = df_features[\"periodo\"].max()\n",
    "\n",
    "# Definir los 3 meses anteriores\n",
    "ultimos_3_meses = pd.date_range(end=ultimo_mes - pd.DateOffset(months=1), periods=3, freq='MS')\n",
    "\n",
    "# Filtrar productos con datos en al menos 3 de esos meses\n",
    "df_filtrado = df_features[df_features[\"periodo\"].isin(ultimos_3_meses)]\n",
    "\n",
    "# Contar cuántos meses tiene cada producto\n",
    "conteo_por_producto = df_filtrado[df_filtrado[\"tn\"] > 0].groupby(\"product_id\").size()\n",
    "\n",
    "# Seleccionar productos válidos\n",
    "productos_validos = conteo_por_producto[conteo_por_producto >= 3].index\n",
    "\n",
    "# Filtrar el dataframe original\n",
    "df_features = df_features[df_features[\"product_id\"].isin(productos_validos)].copy()\n",
    "print(df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5382a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ESTOY_EN_KAGGLE:\n",
    "    df_test = df_features[df_features[\"periodo\"] == pd.to_datetime(201912, format=\"%Y%m\")].copy()\n",
    "    df_features[df_features[\"periodo\"].isin(pd.to_datetime([201911, 201912], format=\"%Y%m\")) ]\n",
    "else:\n",
    "    df_test = df_features[df_features[\"periodo\"] == pd.to_datetime(201910, format=\"%Y%m\")].copy()\n",
    "    df_features[df_features[\"periodo\"].isin(pd.to_datetime([201910, 201911, 201912], format=\"%Y%m\")) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384dbeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. SCALING Y VENTANAS TEMPORALES\n",
    "# ================================\n",
    "\n",
    "window_size = config[\"window_size\"]\n",
    "scaler_name = config[\"scaler_name\"]\n",
    "\n",
    "feature_cols = config[\"feature_cols\"]\n",
    "\n",
    "# Agrupar por producto\n",
    "productos = df_features[\"product_id\"].unique()\n",
    "scalers = {}  # Guardamos los scalers por producto\n",
    "\n",
    "X, y, productos_list = [], [], []\n",
    "\n",
    "for producto in productos:\n",
    "    df_prod = df_features[df_features[\"product_id\"] == producto].copy()\n",
    "\n",
    "    if len(df_prod) < window_size + 2:\n",
    "        continue  # No tiene suficientes datos\n",
    "\n",
    "    # Escalado por producto\n",
    "    \n",
    "    scaler = StandardScaler() if scaler_name == \"standard\" else RobustScaler()\n",
    "    scaled_features = scaler.fit_transform(df_prod[feature_cols])\n",
    "    scalers[producto] = scaler\n",
    "\n",
    "    for i in range(window_size, len(df_prod) - 2):\n",
    "        X.append(scaled_features[i - window_size:i])  # (window_size, n_features)\n",
    "        y.append(scaled_features[i + 2][0])  ###### Target: tn escalado en t+2\n",
    "        productos_list.append(producto)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46a0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 3. TRAIN / TEST SPLIT\n",
    "# ================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# productos_train, productos_test = train_test_split(np.unique(productos_list), test_size=0.2, random_state=42)\n",
    "\n",
    "# train_mask = [p in productos_train for p in productos_list]\n",
    "# test_mask = [p in productos_test for p in productos_list]\n",
    "\n",
    "# X_train, X_test = X[train_mask], X[test_mask]\n",
    "# y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "# Primero reconstruimos la lista de periodos asociados a cada muestra\n",
    "periodos = []\n",
    "\n",
    "for producto in productos:\n",
    "    df_prod = df_features[df_features[\"product_id\"] == producto].copy()\n",
    "\n",
    "    if len(df_prod) < window_size + 2:\n",
    "        continue\n",
    "\n",
    "    for i in range(window_size, len(df_prod) - 2):\n",
    "        # El periodo objetivo (de y) es en t+2, entonces corresponde a:\n",
    "        periodo_target = df_prod.iloc[i + 2][\"periodo\"]\n",
    "        periodos.append(periodo_target)\n",
    "\n",
    "# Convertimos a numpy para facilitar indexado\n",
    "periodos = np.array(periodos)\n",
    "\n",
    "# Definimos el umbral de corte (por ejemplo, predecimos diciembre 2019)\n",
    "fecha_corte = pd.to_datetime(\"2019-12-01\")\n",
    "\n",
    "# Creamos máscaras según el periodo de y\n",
    "train_mask = periodos < fecha_corte\n",
    "test_mask = periodos == fecha_corte  # opcional: podrías usar > fecha_corte para más test\n",
    "\n",
    "# Aplicamos la máscara\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "y_train, y_test = y[train_mask], y[test_mask]\n",
    "productos_test = np.array(productos_list)[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8dbdc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con semilla 42 (1/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\.conda\\envs\\py311lab3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 0.6102 - mae: 0.5757 - val_loss: 0.8219 - val_mae: 0.7381 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5858 - mae: 0.5660 - val_loss: 0.7998 - val_mae: 0.7252 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.5770 - mae: 0.5622 - val_loss: 0.7867 - val_mae: 0.7174 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5726 - mae: 0.5606 - val_loss: 0.7841 - val_mae: 0.7163 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5686 - mae: 0.5592 - val_loss: 0.7762 - val_mae: 0.7119 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5672 - mae: 0.5587 - val_loss: 0.8043 - val_mae: 0.7272 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5655 - mae: 0.5578 - val_loss: 0.7961 - val_mae: 0.7228 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5641 - mae: 0.5575 - val_loss: 0.7832 - val_mae: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5637 - mae: 0.5573 - val_loss: 0.7931 - val_mae: 0.7210 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5616 - mae: 0.5566 - val_loss: 0.7981 - val_mae: 0.7239 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5613 - mae: 0.5562 - val_loss: 0.7918 - val_mae: 0.7205 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5585 - mae: 0.5547 - val_loss: 0.8063 - val_mae: 0.7285 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5588 - mae: 0.5552 - val_loss: 0.8116 - val_mae: 0.7313 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5583 - mae: 0.5547 - val_loss: 0.8039 - val_mae: 0.7276 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5585 - mae: 0.5548 - val_loss: 0.8009 - val_mae: 0.7258 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5564 - mae: 0.5537 - val_loss: 0.8181 - val_mae: 0.7355 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5568 - mae: 0.5540 - val_loss: 0.8054 - val_mae: 0.7282 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5565 - mae: 0.5537 - val_loss: 0.8228 - val_mae: 0.7386 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.5553 - mae: 0.5530 - val_loss: 0.8156 - val_mae: 0.7338 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5549 - mae: 0.5530 - val_loss: 0.8186 - val_mae: 0.7357 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5563 - mae: 0.5557 - val_loss: 0.7339 - val_mae: 0.6862 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5504 - mae: 0.5501 - val_loss: 0.7270 - val_mae: 0.6819 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5501 - mae: 0.5498 - val_loss: 0.7254 - val_mae: 0.6807 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5502 - mae: 0.5493 - val_loss: 0.7248 - val_mae: 0.6803 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5502 - mae: 0.5495 - val_loss: 0.7234 - val_mae: 0.6794 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5497 - mae: 0.5494 - val_loss: 0.7232 - val_mae: 0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5499 - mae: 0.5494 - val_loss: 0.7219 - val_mae: 0.6785 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5490 - mae: 0.5487 - val_loss: 0.7217 - val_mae: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5490 - mae: 0.5491 - val_loss: 0.7218 - val_mae: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5494 - mae: 0.5490 - val_loss: 0.7212 - val_mae: 0.6780 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5489 - mae: 0.5490 - val_loss: 0.7205 - val_mae: 0.6775 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5489 - mae: 0.5489 - val_loss: 0.7211 - val_mae: 0.6779 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5486 - mae: 0.5485 - val_loss: 0.7220 - val_mae: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.5488 - mae: 0.5490 - val_loss: 0.7236 - val_mae: 0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.5480 - mae: 0.5486 - val_loss: 0.7218 - val_mae: 0.6782 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5493 - mae: 0.5487 - val_loss: 0.7209 - val_mae: 0.6777 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5486 - mae: 0.5487 - val_loss: 0.7211 - val_mae: 0.6778 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5490 - mae: 0.5485 - val_loss: 0.7232 - val_mae: 0.6791 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5476 - mae: 0.5483 - val_loss: 0.7219 - val_mae: 0.6782 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5482 - mae: 0.5479 - val_loss: 0.7200 - val_mae: 0.6770 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5478 - mae: 0.5478 - val_loss: 0.7211 - val_mae: 0.6777 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5481 - mae: 0.5481 - val_loss: 0.7214 - val_mae: 0.6779 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5482 - mae: 0.5481 - val_loss: 0.7200 - val_mae: 0.6770 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5485 - mae: 0.5487 - val_loss: 0.7226 - val_mae: 0.6785 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5475 - mae: 0.5485 - val_loss: 0.7201 - val_mae: 0.6769 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5475 - mae: 0.5477 - val_loss: 0.7207 - val_mae: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5468 - mae: 0.5475 - val_loss: 0.7223 - val_mae: 0.6782 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5477 - mae: 0.5480 - val_loss: 0.7232 - val_mae: 0.6788 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5476 - mae: 0.5483 - val_loss: 0.7220 - val_mae: 0.6780 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5478 - mae: 0.5487 - val_loss: 0.7223 - val_mae: 0.6783 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5474 - mae: 0.5483 - val_loss: 0.7208 - val_mae: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5471 - mae: 0.5481 - val_loss: 0.7210 - val_mae: 0.6774 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5466 - mae: 0.5474 - val_loss: 0.7204 - val_mae: 0.6770 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5470 - mae: 0.5476 - val_loss: 0.7209 - val_mae: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5469 - mae: 0.5478 - val_loss: 0.7202 - val_mae: 0.6768 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5463 - mae: 0.5475 - val_loss: 0.7198 - val_mae: 0.6765 - learning_rate: 1.0000e-05\n",
      "Epoch 57/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5461 - mae: 0.5481 - val_loss: 0.7192 - val_mae: 0.6761 - learning_rate: 1.0000e-05\n",
      "Epoch 58/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5471 - mae: 0.5479 - val_loss: 0.7186 - val_mae: 0.6758 - learning_rate: 1.0000e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5453 - mae: 0.5469 - val_loss: 0.7185 - val_mae: 0.6757 - learning_rate: 1.0000e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5456 - mae: 0.5472 - val_loss: 0.7181 - val_mae: 0.6754 - learning_rate: 1.0000e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5459 - mae: 0.5472 - val_loss: 0.7179 - val_mae: 0.6753 - learning_rate: 1.0000e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5463 - mae: 0.5472 - val_loss: 0.7178 - val_mae: 0.6752 - learning_rate: 1.0000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5460 - mae: 0.5473 - val_loss: 0.7173 - val_mae: 0.6749 - learning_rate: 1.0000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5455 - mae: 0.5469 - val_loss: 0.7172 - val_mae: 0.6748 - learning_rate: 1.0000e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5464 - mae: 0.5476 - val_loss: 0.7174 - val_mae: 0.6750 - learning_rate: 1.0000e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5465 - mae: 0.5475 - val_loss: 0.7173 - val_mae: 0.6749 - learning_rate: 1.0000e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5466 - mae: 0.5478 - val_loss: 0.7172 - val_mae: 0.6748 - learning_rate: 1.0000e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5455 - mae: 0.5470 - val_loss: 0.7169 - val_mae: 0.6746 - learning_rate: 1.0000e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5461 - mae: 0.5472 - val_loss: 0.7167 - val_mae: 0.6745 - learning_rate: 1.0000e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5463 - mae: 0.5474 - val_loss: 0.7166 - val_mae: 0.6744 - learning_rate: 1.0000e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.5468 - mae: 0.5477 - val_loss: 0.7166 - val_mae: 0.6744 - learning_rate: 1.0000e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5457 - mae: 0.5471 - val_loss: 0.7163 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.5463 - mae: 0.5471 - val_loss: 0.7164 - val_mae: 0.6743 - learning_rate: 1.0000e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5463 - mae: 0.5479 - val_loss: 0.7162 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5457 - mae: 0.5468 - val_loss: 0.7164 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5456 - mae: 0.5471 - val_loss: 0.7161 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5461 - mae: 0.5466 - val_loss: 0.7160 - val_mae: 0.6740 - learning_rate: 1.0000e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5470 - mae: 0.5478 - val_loss: 0.7161 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.5457 - mae: 0.5469 - val_loss: 0.7163 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5463 - mae: 0.5474 - val_loss: 0.7162 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5461 - mae: 0.5467 - val_loss: 0.7160 - val_mae: 0.6740 - learning_rate: 1.0000e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5456 - mae: 0.5472 - val_loss: 0.7160 - val_mae: 0.6740 - learning_rate: 1.0000e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5460 - mae: 0.5471 - val_loss: 0.7161 - val_mae: 0.6740 - learning_rate: 1.0000e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5462 - mae: 0.5471 - val_loss: 0.7162 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5458 - mae: 0.5473 - val_loss: 0.7162 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5465 - mae: 0.5471 - val_loss: 0.7163 - val_mae: 0.6741 - learning_rate: 1.0000e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5458 - mae: 0.5469 - val_loss: 0.7161 - val_mae: 0.6740 - learning_rate: 1.0000e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5455 - mae: 0.5470 - val_loss: 0.7165 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5450 - mae: 0.5465 - val_loss: 0.7164 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5465 - mae: 0.5474 - val_loss: 0.7164 - val_mae: 0.6742 - learning_rate: 1.0000e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5464 - mae: 0.5475 - val_loss: 0.7166 - val_mae: 0.6743 - learning_rate: 1.0000e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5469 - mae: 0.5476 - val_loss: 0.7166 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "Epoch 93/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5461 - mae: 0.5476 - val_loss: 0.7166 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "Epoch 94/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5459 - mae: 0.5470 - val_loss: 0.7166 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "Epoch 95/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5465 - mae: 0.5476 - val_loss: 0.7166 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "Epoch 96/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5457 - mae: 0.5473 - val_loss: 0.7165 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "Epoch 97/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5460 - mae: 0.5471 - val_loss: 0.7165 - val_mae: 0.6743 - learning_rate: 1.0000e-06\n",
      "\n",
      "Entrenando modelo con semilla 101 (2/5)\n",
      "Epoch 1/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 0.6235 - mae: 0.5750 - val_loss: 0.7372 - val_mae: 0.6876 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.6020 - mae: 0.5672 - val_loss: 0.7293 - val_mae: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5933 - mae: 0.5634 - val_loss: 0.7268 - val_mae: 0.6831 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5881 - mae: 0.5607 - val_loss: 0.7280 - val_mae: 0.6838 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5853 - mae: 0.5596 - val_loss: 0.7210 - val_mae: 0.6791 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5842 - mae: 0.5591 - val_loss: 0.7235 - val_mae: 0.6805 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5826 - mae: 0.5586 - val_loss: 0.7174 - val_mae: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5815 - mae: 0.5583 - val_loss: 0.7294 - val_mae: 0.6846 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5813 - mae: 0.5579 - val_loss: 0.7171 - val_mae: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5794 - mae: 0.5570 - val_loss: 0.7200 - val_mae: 0.6788 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5791 - mae: 0.5574 - val_loss: 0.7134 - val_mae: 0.6746 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5780 - mae: 0.5569 - val_loss: 0.7178 - val_mae: 0.6776 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5778 - mae: 0.5568 - val_loss: 0.7197 - val_mae: 0.6784 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5770 - mae: 0.5563 - val_loss: 0.7118 - val_mae: 0.6732 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5760 - mae: 0.5554 - val_loss: 0.7015 - val_mae: 0.6668 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5765 - mae: 0.5559 - val_loss: 0.7219 - val_mae: 0.6788 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5761 - mae: 0.5561 - val_loss: 0.7111 - val_mae: 0.6725 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5757 - mae: 0.5559 - val_loss: 0.7085 - val_mae: 0.6702 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5740 - mae: 0.5546 - val_loss: 0.7139 - val_mae: 0.6736 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5736 - mae: 0.5548 - val_loss: 0.7218 - val_mae: 0.6780 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5738 - mae: 0.5543 - val_loss: 0.7255 - val_mae: 0.6801 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5736 - mae: 0.5545 - val_loss: 0.7183 - val_mae: 0.6760 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5732 - mae: 0.5542 - val_loss: 0.7117 - val_mae: 0.6707 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5723 - mae: 0.5540 - val_loss: 0.7134 - val_mae: 0.6715 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5715 - mae: 0.5540 - val_loss: 0.7089 - val_mae: 0.6690 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5724 - mae: 0.5539 - val_loss: 0.7082 - val_mae: 0.6680 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5704 - mae: 0.5529 - val_loss: 0.6971 - val_mae: 0.6612 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5702 - mae: 0.5528 - val_loss: 0.7085 - val_mae: 0.6682 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5708 - mae: 0.5533 - val_loss: 0.7217 - val_mae: 0.6754 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5694 - mae: 0.5527 - val_loss: 0.7082 - val_mae: 0.6677 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5693 - mae: 0.5520 - val_loss: 0.7059 - val_mae: 0.6660 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5695 - mae: 0.5529 - val_loss: 0.7202 - val_mae: 0.6750 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5692 - mae: 0.5524 - val_loss: 0.7250 - val_mae: 0.6769 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5683 - mae: 0.5519 - val_loss: 0.7153 - val_mae: 0.6716 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5681 - mae: 0.5517 - val_loss: 0.7146 - val_mae: 0.6706 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5684 - mae: 0.5522 - val_loss: 0.7253 - val_mae: 0.6766 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5674 - mae: 0.5508 - val_loss: 0.7163 - val_mae: 0.6715 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5672 - mae: 0.5508 - val_loss: 0.7245 - val_mae: 0.6756 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5660 - mae: 0.5502 - val_loss: 0.7073 - val_mae: 0.6657 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5661 - mae: 0.5503 - val_loss: 0.7201 - val_mae: 0.6730 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5652 - mae: 0.5503 - val_loss: 0.7094 - val_mae: 0.6661 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5641 - mae: 0.5493 - val_loss: 0.7147 - val_mae: 0.6695 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5619 - mae: 0.5498 - val_loss: 0.7052 - val_mae: 0.6632 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5601 - mae: 0.5472 - val_loss: 0.7035 - val_mae: 0.6623 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5586 - mae: 0.5457 - val_loss: 0.7039 - val_mae: 0.6629 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5594 - mae: 0.5464 - val_loss: 0.7063 - val_mae: 0.6646 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5589 - mae: 0.5461 - val_loss: 0.7037 - val_mae: 0.6629 - learning_rate: 1.0000e-04\n",
      "\n",
      "Entrenando modelo con semilla 202 (3/5)\n",
      "Epoch 1/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 0.6171 - mae: 0.5751 - val_loss: 0.7779 - val_mae: 0.7147 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.5948 - mae: 0.5683 - val_loss: 0.7721 - val_mae: 0.7121 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5840 - mae: 0.5640 - val_loss: 0.7595 - val_mae: 0.7043 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5787 - mae: 0.5612 - val_loss: 0.7594 - val_mae: 0.7044 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5763 - mae: 0.5605 - val_loss: 0.7567 - val_mae: 0.7025 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5748 - mae: 0.5593 - val_loss: 0.7567 - val_mae: 0.7024 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5730 - mae: 0.5585 - val_loss: 0.7552 - val_mae: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5717 - mae: 0.5579 - val_loss: 0.7563 - val_mae: 0.7017 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5711 - mae: 0.5576 - val_loss: 0.7541 - val_mae: 0.7004 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5708 - mae: 0.5574 - val_loss: 0.7525 - val_mae: 0.6991 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5692 - mae: 0.5565 - val_loss: 0.7532 - val_mae: 0.6993 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5676 - mae: 0.5559 - val_loss: 0.7523 - val_mae: 0.6986 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5678 - mae: 0.5560 - val_loss: 0.7483 - val_mae: 0.6966 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5669 - mae: 0.5556 - val_loss: 0.7528 - val_mae: 0.6989 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5664 - mae: 0.5554 - val_loss: 0.7533 - val_mae: 0.6990 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5650 - mae: 0.5545 - val_loss: 0.7499 - val_mae: 0.6971 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5649 - mae: 0.5540 - val_loss: 0.7518 - val_mae: 0.6980 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5630 - mae: 0.5534 - val_loss: 0.7521 - val_mae: 0.6977 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5625 - mae: 0.5530 - val_loss: 0.7439 - val_mae: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5617 - mae: 0.5527 - val_loss: 0.7615 - val_mae: 0.7029 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5618 - mae: 0.5528 - val_loss: 0.7502 - val_mae: 0.6964 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5604 - mae: 0.5521 - val_loss: 0.7517 - val_mae: 0.6973 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5609 - mae: 0.5522 - val_loss: 0.7516 - val_mae: 0.6961 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5605 - mae: 0.5523 - val_loss: 0.7481 - val_mae: 0.6942 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5597 - mae: 0.5520 - val_loss: 0.7478 - val_mae: 0.6942 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5588 - mae: 0.5505 - val_loss: 0.7568 - val_mae: 0.6992 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5582 - mae: 0.5508 - val_loss: 0.7610 - val_mae: 0.7013 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5575 - mae: 0.5505 - val_loss: 0.7603 - val_mae: 0.7013 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5567 - mae: 0.5502 - val_loss: 0.7579 - val_mae: 0.6991 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5572 - mae: 0.5505 - val_loss: 0.7492 - val_mae: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5567 - mae: 0.5498 - val_loss: 0.7486 - val_mae: 0.6945 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5562 - mae: 0.5496 - val_loss: 0.7575 - val_mae: 0.6983 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5561 - mae: 0.5498 - val_loss: 0.7637 - val_mae: 0.7023 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5547 - mae: 0.5486 - val_loss: 0.7569 - val_mae: 0.6989 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5542 - mae: 0.5507 - val_loss: 0.7115 - val_mae: 0.6706 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5508 - mae: 0.5460 - val_loss: 0.7068 - val_mae: 0.6675 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5493 - mae: 0.5448 - val_loss: 0.7071 - val_mae: 0.6675 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5490 - mae: 0.5450 - val_loss: 0.7070 - val_mae: 0.6674 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5486 - mae: 0.5446 - val_loss: 0.7085 - val_mae: 0.6683 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5493 - mae: 0.5444 - val_loss: 0.7070 - val_mae: 0.6674 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5483 - mae: 0.5441 - val_loss: 0.7080 - val_mae: 0.6681 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5477 - mae: 0.5443 - val_loss: 0.7098 - val_mae: 0.6692 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5488 - mae: 0.5445 - val_loss: 0.7078 - val_mae: 0.6680 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.5469 - mae: 0.5435 - val_loss: 0.7084 - val_mae: 0.6683 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5470 - mae: 0.5440 - val_loss: 0.7076 - val_mae: 0.6677 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5479 - mae: 0.5443 - val_loss: 0.7074 - val_mae: 0.6675 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5479 - mae: 0.5443 - val_loss: 0.7077 - val_mae: 0.6678 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5488 - mae: 0.5443 - val_loss: 0.7095 - val_mae: 0.6689 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5476 - mae: 0.5443 - val_loss: 0.7101 - val_mae: 0.6693 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5468 - mae: 0.5436 - val_loss: 0.7083 - val_mae: 0.6681 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5479 - mae: 0.5440 - val_loss: 0.7084 - val_mae: 0.6680 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5465 - mae: 0.5433 - val_loss: 0.7083 - val_mae: 0.6679 - learning_rate: 1.0000e-05\n",
      "Epoch 53/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5469 - mae: 0.5432 - val_loss: 0.7084 - val_mae: 0.6679 - learning_rate: 1.0000e-05\n",
      "Epoch 54/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5474 - mae: 0.5436 - val_loss: 0.7086 - val_mae: 0.6681 - learning_rate: 1.0000e-05\n",
      "Epoch 55/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5474 - mae: 0.5437 - val_loss: 0.7088 - val_mae: 0.6682 - learning_rate: 1.0000e-05\n",
      "Epoch 56/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5463 - mae: 0.5430 - val_loss: 0.7087 - val_mae: 0.6682 - learning_rate: 1.0000e-05\n",
      "\n",
      "Entrenando modelo con semilla 303 (4/5)\n",
      "Epoch 1/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 0.6102 - mae: 0.5689 - val_loss: 0.8091 - val_mae: 0.7316 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.5854 - mae: 0.5613 - val_loss: 0.7984 - val_mae: 0.7266 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5760 - mae: 0.5580 - val_loss: 0.7972 - val_mae: 0.7262 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5715 - mae: 0.5563 - val_loss: 0.7964 - val_mae: 0.7262 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5691 - mae: 0.5552 - val_loss: 0.7932 - val_mae: 0.7244 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5664 - mae: 0.5540 - val_loss: 0.7886 - val_mae: 0.7213 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5656 - mae: 0.5539 - val_loss: 0.7870 - val_mae: 0.7200 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5641 - mae: 0.5528 - val_loss: 0.7900 - val_mae: 0.7219 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5624 - mae: 0.5523 - val_loss: 0.7927 - val_mae: 0.7231 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5617 - mae: 0.5520 - val_loss: 0.7905 - val_mae: 0.7218 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5598 - mae: 0.5512 - val_loss: 0.7914 - val_mae: 0.7224 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5599 - mae: 0.5511 - val_loss: 0.7970 - val_mae: 0.7254 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.5590 - mae: 0.5507 - val_loss: 0.7969 - val_mae: 0.7255 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5582 - mae: 0.5504 - val_loss: 0.7955 - val_mae: 0.7244 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5575 - mae: 0.5506 - val_loss: 0.7941 - val_mae: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5569 - mae: 0.5500 - val_loss: 0.7941 - val_mae: 0.7232 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5560 - mae: 0.5492 - val_loss: 0.7935 - val_mae: 0.7227 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5557 - mae: 0.5494 - val_loss: 0.7979 - val_mae: 0.7255 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5554 - mae: 0.5496 - val_loss: 0.8018 - val_mae: 0.7278 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5537 - mae: 0.5487 - val_loss: 0.7978 - val_mae: 0.7248 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5539 - mae: 0.5490 - val_loss: 0.8004 - val_mae: 0.7265 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5531 - mae: 0.5484 - val_loss: 0.7951 - val_mae: 0.7235 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5532 - mae: 0.5518 - val_loss: 0.7288 - val_mae: 0.6825 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5487 - mae: 0.5458 - val_loss: 0.7186 - val_mae: 0.6756 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5480 - mae: 0.5455 - val_loss: 0.7173 - val_mae: 0.6746 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5488 - mae: 0.5457 - val_loss: 0.7169 - val_mae: 0.6742 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5482 - mae: 0.5452 - val_loss: 0.7163 - val_mae: 0.6737 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5459 - mae: 0.5439 - val_loss: 0.7167 - val_mae: 0.6738 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5473 - mae: 0.5442 - val_loss: 0.7167 - val_mae: 0.6738 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5477 - mae: 0.5448 - val_loss: 0.7164 - val_mae: 0.6737 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.5468 - mae: 0.5444 - val_loss: 0.7163 - val_mae: 0.6736 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5472 - mae: 0.5444 - val_loss: 0.7161 - val_mae: 0.6734 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.5462 - mae: 0.5444 - val_loss: 0.7158 - val_mae: 0.6731 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.5463 - mae: 0.5442 - val_loss: 0.7159 - val_mae: 0.6733 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5461 - mae: 0.5444 - val_loss: 0.7157 - val_mae: 0.6731 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5455 - mae: 0.5439 - val_loss: 0.7153 - val_mae: 0.6729 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5457 - mae: 0.5442 - val_loss: 0.7163 - val_mae: 0.6734 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5460 - mae: 0.5444 - val_loss: 0.7166 - val_mae: 0.6735 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5462 - mae: 0.5445 - val_loss: 0.7162 - val_mae: 0.6733 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5461 - mae: 0.5441 - val_loss: 0.7163 - val_mae: 0.6734 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5454 - mae: 0.5436 - val_loss: 0.7158 - val_mae: 0.6731 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5455 - mae: 0.5440 - val_loss: 0.7170 - val_mae: 0.6738 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5462 - mae: 0.5443 - val_loss: 0.7155 - val_mae: 0.6729 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.5453 - mae: 0.5438 - val_loss: 0.7165 - val_mae: 0.6735 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5450 - mae: 0.5437 - val_loss: 0.7176 - val_mae: 0.6742 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5456 - mae: 0.5439 - val_loss: 0.7180 - val_mae: 0.6745 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5454 - mae: 0.5437 - val_loss: 0.7157 - val_mae: 0.6730 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5443 - mae: 0.5433 - val_loss: 0.7170 - val_mae: 0.6738 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5447 - mae: 0.5436 - val_loss: 0.7177 - val_mae: 0.6742 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5450 - mae: 0.5438 - val_loss: 0.7165 - val_mae: 0.6734 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5448 - mae: 0.5434 - val_loss: 0.7161 - val_mae: 0.6731 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5445 - mae: 0.5437 - val_loss: 0.7149 - val_mae: 0.6724 - learning_rate: 1.0000e-05\n",
      "Epoch 53/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.5447 - mae: 0.5436 - val_loss: 0.7137 - val_mae: 0.6716 - learning_rate: 1.0000e-05\n",
      "Epoch 54/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5455 - mae: 0.5444 - val_loss: 0.7130 - val_mae: 0.6711 - learning_rate: 1.0000e-05\n",
      "Epoch 55/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5437 - mae: 0.5434 - val_loss: 0.7122 - val_mae: 0.6706 - learning_rate: 1.0000e-05\n",
      "Epoch 56/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5439 - mae: 0.5432 - val_loss: 0.7115 - val_mae: 0.6702 - learning_rate: 1.0000e-05\n",
      "Epoch 57/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5444 - mae: 0.5432 - val_loss: 0.7112 - val_mae: 0.6700 - learning_rate: 1.0000e-05\n",
      "Epoch 58/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5452 - mae: 0.5432 - val_loss: 0.7111 - val_mae: 0.6699 - learning_rate: 1.0000e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5449 - mae: 0.5435 - val_loss: 0.7106 - val_mae: 0.6696 - learning_rate: 1.0000e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5447 - mae: 0.5432 - val_loss: 0.7105 - val_mae: 0.6696 - learning_rate: 1.0000e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5449 - mae: 0.5431 - val_loss: 0.7106 - val_mae: 0.6696 - learning_rate: 1.0000e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5441 - mae: 0.5428 - val_loss: 0.7107 - val_mae: 0.6697 - learning_rate: 1.0000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5447 - mae: 0.5432 - val_loss: 0.7107 - val_mae: 0.6697 - learning_rate: 1.0000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.5436 - mae: 0.5428 - val_loss: 0.7105 - val_mae: 0.6695 - learning_rate: 1.0000e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5438 - mae: 0.5429 - val_loss: 0.7103 - val_mae: 0.6694 - learning_rate: 1.0000e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5440 - mae: 0.5426 - val_loss: 0.7100 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5450 - mae: 0.5432 - val_loss: 0.7099 - val_mae: 0.6691 - learning_rate: 1.0000e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5448 - mae: 0.5433 - val_loss: 0.7100 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5453 - mae: 0.5434 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5444 - mae: 0.5429 - val_loss: 0.7098 - val_mae: 0.6691 - learning_rate: 1.0000e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5443 - mae: 0.5427 - val_loss: 0.7098 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5451 - mae: 0.5435 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5434 - mae: 0.5424 - val_loss: 0.7096 - val_mae: 0.6689 - learning_rate: 1.0000e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5442 - mae: 0.5431 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5442 - mae: 0.5428 - val_loss: 0.7098 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.5445 - mae: 0.5431 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5442 - mae: 0.5428 - val_loss: 0.7096 - val_mae: 0.6689 - learning_rate: 1.0000e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5434 - mae: 0.5427 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5441 - mae: 0.5425 - val_loss: 0.7099 - val_mae: 0.6691 - learning_rate: 1.0000e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5446 - mae: 0.5430 - val_loss: 0.7100 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5444 - mae: 0.5432 - val_loss: 0.7101 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.5434 - mae: 0.5425 - val_loss: 0.7101 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5448 - mae: 0.5433 - val_loss: 0.7102 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5442 - mae: 0.5431 - val_loss: 0.7103 - val_mae: 0.6693 - learning_rate: 1.0000e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5438 - mae: 0.5428 - val_loss: 0.7101 - val_mae: 0.6692 - learning_rate: 1.0000e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5446 - mae: 0.5431 - val_loss: 0.7098 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5442 - mae: 0.5429 - val_loss: 0.7098 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5441 - mae: 0.5430 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5442 - mae: 0.5429 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-06\n",
      "Epoch 90/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5447 - mae: 0.5436 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-06\n",
      "Epoch 91/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5437 - mae: 0.5426 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-06\n",
      "Epoch 92/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5435 - mae: 0.5428 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-06\n",
      "Epoch 93/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5442 - mae: 0.5430 - val_loss: 0.7097 - val_mae: 0.6690 - learning_rate: 1.0000e-06\n",
      "\n",
      "Entrenando modelo con semilla 404 (5/5)\n",
      "Epoch 1/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.6070 - mae: 0.5726 - val_loss: 0.7382 - val_mae: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5831 - mae: 0.5618 - val_loss: 0.7166 - val_mae: 0.6757 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5737 - mae: 0.5578 - val_loss: 0.7127 - val_mae: 0.6734 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5700 - mae: 0.5561 - val_loss: 0.7086 - val_mae: 0.6714 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.5666 - mae: 0.5545 - val_loss: 0.7091 - val_mae: 0.6719 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.5644 - mae: 0.5538 - val_loss: 0.7082 - val_mae: 0.6715 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5630 - mae: 0.5529 - val_loss: 0.7019 - val_mae: 0.6677 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5614 - mae: 0.5521 - val_loss: 0.6949 - val_mae: 0.6631 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5605 - mae: 0.5516 - val_loss: 0.6908 - val_mae: 0.6607 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5590 - mae: 0.5510 - val_loss: 0.6919 - val_mae: 0.6610 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5583 - mae: 0.5503 - val_loss: 0.6860 - val_mae: 0.6576 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5579 - mae: 0.5503 - val_loss: 0.6822 - val_mae: 0.6551 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.5572 - mae: 0.5497 - val_loss: 0.6832 - val_mae: 0.6552 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.5568 - mae: 0.5496 - val_loss: 0.6780 - val_mae: 0.6518 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5560 - mae: 0.5488 - val_loss: 0.6740 - val_mae: 0.6491 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5558 - mae: 0.5488 - val_loss: 0.6740 - val_mae: 0.6487 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5553 - mae: 0.5487 - val_loss: 0.6742 - val_mae: 0.6488 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5544 - mae: 0.5480 - val_loss: 0.6710 - val_mae: 0.6464 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5541 - mae: 0.5481 - val_loss: 0.6711 - val_mae: 0.6467 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5533 - mae: 0.5478 - val_loss: 0.6633 - val_mae: 0.6418 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5527 - mae: 0.5472 - val_loss: 0.6639 - val_mae: 0.6425 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5525 - mae: 0.5472 - val_loss: 0.6600 - val_mae: 0.6395 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5516 - mae: 0.5466 - val_loss: 0.6623 - val_mae: 0.6407 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5509 - mae: 0.5461 - val_loss: 0.6637 - val_mae: 0.6414 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5507 - mae: 0.5464 - val_loss: 0.6583 - val_mae: 0.6384 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5508 - mae: 0.5465 - val_loss: 0.6553 - val_mae: 0.6359 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5497 - mae: 0.5458 - val_loss: 0.6552 - val_mae: 0.6360 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5493 - mae: 0.5450 - val_loss: 0.6492 - val_mae: 0.6322 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5491 - mae: 0.5455 - val_loss: 0.6458 - val_mae: 0.6291 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5483 - mae: 0.5447 - val_loss: 0.6516 - val_mae: 0.6337 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5473 - mae: 0.5438 - val_loss: 0.6479 - val_mae: 0.6308 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5486 - mae: 0.5448 - val_loss: 0.6479 - val_mae: 0.6309 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.5466 - mae: 0.5436 - val_loss: 0.6468 - val_mae: 0.6299 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.5472 - mae: 0.5437 - val_loss: 0.6419 - val_mae: 0.6268 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5463 - mae: 0.5433 - val_loss: 0.6393 - val_mae: 0.6252 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5461 - mae: 0.5432 - val_loss: 0.6435 - val_mae: 0.6278 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5452 - mae: 0.5428 - val_loss: 0.6457 - val_mae: 0.6292 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5445 - mae: 0.5418 - val_loss: 0.6406 - val_mae: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5437 - mae: 0.5418 - val_loss: 0.6403 - val_mae: 0.6256 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5442 - mae: 0.5420 - val_loss: 0.6348 - val_mae: 0.6218 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5438 - mae: 0.5417 - val_loss: 0.6349 - val_mae: 0.6215 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5421 - mae: 0.5407 - val_loss: 0.6349 - val_mae: 0.6218 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5434 - mae: 0.5414 - val_loss: 0.6400 - val_mae: 0.6255 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5425 - mae: 0.5415 - val_loss: 0.6400 - val_mae: 0.6246 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5424 - mae: 0.5411 - val_loss: 0.6452 - val_mae: 0.6279 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5416 - mae: 0.5401 - val_loss: 0.6331 - val_mae: 0.6202 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5402 - mae: 0.5394 - val_loss: 0.6371 - val_mae: 0.6223 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5405 - mae: 0.5395 - val_loss: 0.6378 - val_mae: 0.6235 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5397 - mae: 0.5395 - val_loss: 0.6453 - val_mae: 0.6273 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5395 - mae: 0.5391 - val_loss: 0.6388 - val_mae: 0.6233 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5393 - mae: 0.5393 - val_loss: 0.6391 - val_mae: 0.6240 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5386 - mae: 0.5388 - val_loss: 0.6321 - val_mae: 0.6186 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5389 - mae: 0.5386 - val_loss: 0.6360 - val_mae: 0.6211 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5381 - mae: 0.5389 - val_loss: 0.6403 - val_mae: 0.6242 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5373 - mae: 0.5377 - val_loss: 0.6398 - val_mae: 0.6240 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5357 - mae: 0.5369 - val_loss: 0.6394 - val_mae: 0.6227 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5369 - mae: 0.5378 - val_loss: 0.6352 - val_mae: 0.6204 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5346 - mae: 0.5366 - val_loss: 0.6417 - val_mae: 0.6240 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5345 - mae: 0.5370 - val_loss: 0.6425 - val_mae: 0.6244 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5345 - mae: 0.5366 - val_loss: 0.6395 - val_mae: 0.6218 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5337 - mae: 0.5363 - val_loss: 0.6391 - val_mae: 0.6223 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5345 - mae: 0.5364 - val_loss: 0.6431 - val_mae: 0.6250 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5335 - mae: 0.5358 - val_loss: 0.6456 - val_mae: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5320 - mae: 0.5350 - val_loss: 0.6321 - val_mae: 0.6174 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5310 - mae: 0.5345 - val_loss: 0.6351 - val_mae: 0.6193 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5309 - mae: 0.5348 - val_loss: 0.6505 - val_mae: 0.6287 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5299 - mae: 0.5341 - val_loss: 0.6321 - val_mae: 0.6176 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5300 - mae: 0.5322 - val_loss: 0.6756 - val_mae: 0.6458 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5259 - mae: 0.5316 - val_loss: 0.6799 - val_mae: 0.6483 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5243 - mae: 0.5316 - val_loss: 0.6790 - val_mae: 0.6477 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5240 - mae: 0.5313 - val_loss: 0.6789 - val_mae: 0.6476 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5230 - mae: 0.5311 - val_loss: 0.6783 - val_mae: 0.6470 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 4. MODELO LSTM\n",
    "# ================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import random\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "\n",
    "# Configuración y semillas\n",
    "semillas = [42, 101, 202, 303, 404]  # Tus semillas\n",
    "l2_lambda = config[\"l2_lambda\"]\n",
    "optimizer_name = config[\"optimizer\"]\n",
    "epochs = config[\"epochs\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "early_stopping_patience = config[\"early_stopping_patience\"]\n",
    "\n",
    "# Función para crear modelo (con semilla como parámetro)\n",
    "def crear_modelo(semilla, window_size, n_features):\n",
    "    tf.keras.utils.set_random_seed(semilla)  # Fija semilla para TensorFlow\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(200, activation='tanh', return_sequences=True, \n",
    "             input_shape=(window_size, n_features),\n",
    "             kernel_regularizer=l2(l2_lambda) if l2_lambda > 0 else None),\n",
    "        Dropout(0.2, seed=semilla),\n",
    "        LSTM(32, activation='tanh'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Configurar optimizer con semilla\n",
    "    if optimizer_name.lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif optimizer_name.lower() == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=0.001)\n",
    "    else:\n",
    "        optimizer = optimizer_name\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Entrenamiento con semillerio\n",
    "def entrenar_con_semillerio(X_train, y_train, X_test, y_test):\n",
    "    modelos = []\n",
    "    historiales = []\n",
    "    window_size = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=early_stopping_patience, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=15)\n",
    "    ]\n",
    "    \n",
    "    for i, semilla in enumerate(semillas):\n",
    "        print(f\"\\nEntrenando modelo con semilla {semilla} ({i+1}/{len(semillas)})\")\n",
    "        \n",
    "        model = crear_modelo(semilla, window_size, n_features)\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        modelos.append(model)\n",
    "        historiales.append(history)\n",
    "    \n",
    "    return modelos, historiales\n",
    "\n",
    "\n",
    "\n",
    "modelos, historiales = entrenar_con_semillerio(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================================\n",
    "# # 5. PREDICCIÓN t+2\n",
    "# # ================================\n",
    "\n",
    "# def predecir_t2(product_id, df_features_full):\n",
    "#     \"\"\"\n",
    "#     product_id: ID del producto a predecir.\n",
    "#     df_features_full: dataframe con las features ya procesadas.\n",
    "#     \"\"\"\n",
    "#     df_prod = df_features_full[df_features_full[\"product_id\"] == product_id].copy()\n",
    "#     scaler = scalers[product_id]\n",
    "\n",
    "#     ultimos = df_prod[feature_cols].iloc[-window_size:]\n",
    "#     ultimos_scaled = scaler.transform(ultimos)\n",
    "\n",
    "#     X_new = ultimos_scaled.reshape(1, window_size, len(feature_cols))\n",
    "#     y_pred_scaled = model.predict(X_new)\n",
    "\n",
    "#     # Inversión del escalado solo sobre la primera columna (tn)\n",
    "#     tn_mean = scaler.center_[0]\n",
    "#     tn_std = scaler.scale_[0]\n",
    "\n",
    "#     y_pred = y_pred_scaled[0][0] * tn_std + tn_mean\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8495f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================================\n",
    "# # 5. PREDICCIÓN t+2\n",
    "# # ================================\n",
    "\n",
    "def predecir_todos_t2_semillerio(df_features_full, modelos, scalers, feature_cols, window_size):\n",
    "    \"\"\"\n",
    "    Predice tn en t+2 para todos los productos usando un ensemble de modelos con semillerio.\n",
    "\n",
    "    Args:\n",
    "        df_features_full (pd.DataFrame): dataframe completo con features\n",
    "        modelos (list): lista de modelos LSTM entrenados con diferentes semillas\n",
    "        scalers (dict): diccionario con los StandardScaler por producto\n",
    "        feature_cols (list): lista de columnas de features\n",
    "        window_size (int): tamaño de la ventana temporal\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe con columnas [\"product_id\", \"tn_t2_pred\"]\n",
    "    \"\"\"\n",
    "    productos = df_features_full[\"product_id\"].unique()\n",
    "    resultados = []\n",
    "\n",
    "    for pid in productos:\n",
    "        df_prod = df_features_full[df_features_full[\"product_id\"] == pid]\n",
    "        \n",
    "        if len(df_prod) < window_size:\n",
    "            continue  # no hay suficientes datos\n",
    "\n",
    "        try:\n",
    "            # Preparar datos\n",
    "            ultimos = df_prod[feature_cols].iloc[-window_size:]\n",
    "            scaler = scalers[pid]\n",
    "            ultimos_scaled = scaler.transform(ultimos)\n",
    "            X_new = ultimos_scaled.reshape(1, window_size, len(feature_cols))\n",
    "            \n",
    "            # Predecir con todos los modelos y promediar\n",
    "            predicciones = []\n",
    "            for model in modelos:\n",
    "                y_pred_scaled = model.predict(X_new, verbose=0)\n",
    "                tn_mean = scaler.center_[0]\n",
    "                tn_std = scaler.scale_[0]\n",
    "                y_pred = y_pred_scaled[0][0] * tn_std + tn_mean\n",
    "                predicciones.append(y_pred)\n",
    "            \n",
    "            y_pred_final = np.mean(predicciones)\n",
    "            \n",
    "            # Opcional: eliminar outliers extremos antes de promediar\n",
    "            # y_pred_final = np.mean(np.clip(predicciones, \n",
    "            #                           np.percentile(predicciones, 10),\n",
    "            #                           np.percentile(predicciones, 90)))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al predecir producto {pid}: {e}\")\n",
    "            y_pred_final = np.mean(df_prod[\"tn\"])  # Valor por defecto si falla\n",
    "            \n",
    "        # Asegurar predicción positiva\n",
    "        y_pred_final = max(0, y_pred_final)\n",
    "        resultados.append({\"product_id\": pid, \"tn_t2_pred\": y_pred_final})\n",
    "\n",
    "    return pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "925e4b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000195579C77E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Error al predecir producto 20127: np.int64(20127)\n",
      "Error al predecir producto 20210: np.int64(20210)\n",
      "Error al predecir producto 20686: np.int64(20686)\n",
      "Error al predecir producto 20703: np.int64(20703)\n",
      "Error al predecir producto 20962: np.int64(20962)\n",
      "Error al predecir producto 20975: np.int64(20975)\n",
      "Error al predecir producto 20995: np.int64(20995)\n",
      "Error al predecir producto 21087: np.int64(21087)\n",
      "Error al predecir producto 21214: np.int64(21214)\n",
      "   product_id   tn_t2_pred\n",
      "0       20001  1368.557567\n",
      "1       20002  1061.426158\n",
      "2       20003   798.040597\n",
      "3       20004   597.680743\n",
      "4       20005   572.593556\n"
     ]
    }
   ],
   "source": [
    "df_preds_t2 = predecir_todos_t2_semillerio(\n",
    "    df_features,\n",
    "    modelos,\n",
    "    scalers,\n",
    "    feature_cols,\n",
    "    window_size\n",
    ")\n",
    "\n",
    "print(df_preds_t2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a4591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al predecir producto 20127: np.int64(20127)\n",
      "Error al predecir producto 20210: np.int64(20210)\n",
      "Error al predecir producto 20686: np.int64(20686)\n",
      "Error al predecir producto 20703: np.int64(20703)\n",
      "Error al predecir producto 20962: np.int64(20962)\n",
      "Error al predecir producto 20975: np.int64(20975)\n",
      "Error al predecir producto 20995: np.int64(20995)\n",
      "Error al predecir producto 21087: np.int64(21087)\n",
      "Error al predecir producto 21214: np.int64(21214)\n",
      "   product_id   tn_t2_pred\n",
      "0       20001  1386.858321\n",
      "1       20002  1049.577596\n",
      "2       20003   805.068777\n",
      "3       20004   594.459138\n",
      "4       20005   567.989714\n"
     ]
    }
   ],
   "source": [
    "# df_preds_t2 = predecir_todos_t2(\n",
    "#     df_features_full=df_features,\n",
    "#     model=model,\n",
    "#     scalers=scalers,\n",
    "#     feature_cols=feature_cols,\n",
    "#     window_size=window_size\n",
    "# )\n",
    "\n",
    "# print(df_preds_t2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac38ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn_t2_pred",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "43e8612e-c7ba-4528-98cc-2b9c3c9c3e46",
       "rows": [
        [
         "0",
         "20001",
         "1368.5575674877643"
        ],
        [
         "1",
         "20002",
         "1061.4261583114098"
        ],
        [
         "2",
         "20003",
         "798.0405966352357"
        ],
        [
         "3",
         "20004",
         "597.6807432474684"
        ],
        [
         "4",
         "20005",
         "572.5935562758511"
        ],
        [
         "5",
         "20006",
         "538.1403510970442"
        ],
        [
         "6",
         "20007",
         "492.81371199044116"
        ],
        [
         "7",
         "20008",
         "473.08302866442966"
        ],
        [
         "8",
         "20009",
         "455.85752784530666"
        ],
        [
         "9",
         "20010",
         "420.55204603860494"
        ],
        [
         "10",
         "20011",
         "388.9815815878943"
        ],
        [
         "11",
         "20012",
         "416.6072952274919"
        ],
        [
         "12",
         "20013",
         "410.8653413148544"
        ],
        [
         "13",
         "20014",
         "423.44222665426224"
        ],
        [
         "14",
         "20015",
         "385.4234111572755"
        ],
        [
         "15",
         "20016",
         "345.88316439703357"
        ],
        [
         "16",
         "20017",
         "317.5545266764011"
        ],
        [
         "17",
         "20018",
         "322.4717887833582"
        ],
        [
         "18",
         "20019",
         "335.0761069189646"
        ],
        [
         "19",
         "20020",
         "281.21134799574156"
        ],
        [
         "20",
         "20021",
         "274.5400187762305"
        ],
        [
         "21",
         "20022",
         "261.8915003458308"
        ],
        [
         "22",
         "20023",
         "264.61695275242465"
        ],
        [
         "23",
         "20024",
         "259.9492895747059"
        ],
        [
         "24",
         "20025",
         "230.5608851242313"
        ],
        [
         "25",
         "20026",
         "240.2866545706127"
        ],
        [
         "26",
         "20027",
         "226.2185096902712"
        ],
        [
         "27",
         "20028",
         "236.272300647534"
        ],
        [
         "28",
         "20029",
         "222.86730854925912"
        ],
        [
         "29",
         "20030",
         "190.79549511038545"
        ],
        [
         "30",
         "20031",
         "196.02299821455213"
        ],
        [
         "31",
         "20032",
         "581.1088880322587"
        ],
        [
         "32",
         "20033",
         "196.57220101041304"
        ],
        [
         "33",
         "20035",
         "180.36941180236096"
        ],
        [
         "34",
         "20037",
         "109.88892196390643"
        ],
        [
         "35",
         "20038",
         "173.19582382282408"
        ],
        [
         "36",
         "20039",
         "159.449647352282"
        ],
        [
         "37",
         "20041",
         "154.01604685459859"
        ],
        [
         "38",
         "20042",
         "157.8302103755908"
        ],
        [
         "39",
         "20043",
         "172.62264677087396"
        ],
        [
         "40",
         "20044",
         "166.77546454990596"
        ],
        [
         "41",
         "20045",
         "151.39781992693307"
        ],
        [
         "42",
         "20046",
         "148.64084461866247"
        ],
        [
         "43",
         "20047",
         "159.46793797498944"
        ],
        [
         "44",
         "20048",
         "164.94098011231716"
        ],
        [
         "45",
         "20049",
         "205.41855530011907"
        ],
        [
         "46",
         "20050",
         "146.9040351620601"
        ],
        [
         "47",
         "20051",
         "159.67906114632322"
        ],
        [
         "48",
         "20052",
         "134.1872979676638"
        ],
        [
         "49",
         "20053",
         "154.97755866776643"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 898
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn_t2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1368.557567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1061.426158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>798.040597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>597.680743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>572.593556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.053078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.055428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.059385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>21271</td>\n",
       "      <td>0.013538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.020050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id   tn_t2_pred\n",
       "0         20001  1368.557567\n",
       "1         20002  1061.426158\n",
       "2         20003   798.040597\n",
       "3         20004   597.680743\n",
       "4         20005   572.593556\n",
       "..          ...          ...\n",
       "893       21265     0.053078\n",
       "894       21266     0.055428\n",
       "895       21267     0.059385\n",
       "896       21271     0.013538\n",
       "897       21276     0.020050\n",
       "\n",
       "[898 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1d8260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "periodo",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "tn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tn_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tn_diff1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rolling_mean3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rolling_std3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rolling_max3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rolling_min3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rolling_max6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rolling_min6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tn_t2_pred",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "265e59f0-01bc-4305-9873-2a6b75098405",
       "rows": [
        [
         "0",
         "20001",
         "2019-12-01 00:00:00",
         "1504.68856",
         "1397.37231",
         "107.31625000000008",
         "36",
         "1539.6278133333333",
         "132.676441405275",
         "1660.00561",
         "1397.37231",
         "1678.99318",
         "1109.93769",
         "1368.5575674877643"
        ],
        [
         "1",
         "20002",
         "2019-12-01 00:00:00",
         "1087.30855",
         "1423.5773900000002",
         "-336.2688400000002",
         "36",
         "1497.76715",
         "449.29204448121067",
         "1979.53635",
         "1090.18771",
         "1979.53635",
         "813.78215",
         "1061.4261583114098"
        ],
        [
         "2",
         "20003",
         "2019-12-01 00:00:00",
         "892.5012899999999",
         "948.29393",
         "-55.79264000000012",
         "36",
         "999.1438466666665",
         "71.86972934623559",
         "1081.36645",
         "948.29393",
         "1081.36645",
         "635.59563",
         "798.0405966352357"
        ],
        [
         "3",
         "20004",
         "2019-12-01 00:00:00",
         "637.90002",
         "723.94206",
         "-86.04203999999993",
         "36",
         "858.2699299999999",
         "181.4580300012345",
         "1064.69633",
         "723.94206",
         "1064.69633",
         "482.13372",
         "597.6807432474684"
        ],
        [
         "4",
         "20005",
         "2019-12-01 00:00:00",
         "593.24443",
         "606.91173",
         "-13.667300000000068",
         "36",
         "827.7408533333333",
         "200.02822474173158",
         "996.78275",
         "606.91173",
         "996.78275",
         "536.668",
         "572.5935562758511"
        ],
        [
         "5",
         "20006",
         "2019-12-01 00:00:00",
         "417.23228",
         "399.6142",
         "17.61808000000002",
         "36",
         "445.96516999999994",
         "71.51398387044313",
         "528.3263",
         "399.6142",
         "528.3263",
         "262.73593",
         "538.1403510970442"
        ],
        [
         "6",
         "20007",
         "2019-12-01 00:00:00",
         "390.43432",
         "357.85913",
         "32.57519000000002",
         "36",
         "390.9856366666667",
         "47.45377016586924",
         "445.34884",
         "357.85913",
         "573.37257",
         "307.82899",
         "492.81371199044116"
        ],
        [
         "7",
         "20008",
         "2019-12-01 00:00:00",
         "195.36854",
         "396.49833",
         "-201.12979",
         "36",
         "393.2779100000001",
         "61.16788488222487",
         "452.77197",
         "330.56343",
         "567.42091",
         "233.00983",
         "473.08302866442966"
        ],
        [
         "8",
         "20009",
         "2019-12-01 00:00:00",
         "495.03574",
         "711.89025",
         "-216.85451000000006",
         "36",
         "608.8330866666666",
         "89.25756476873117",
         "711.89025",
         "556.15182",
         "716.07987",
         "520.41758",
         "455.85752784530666"
        ],
        [
         "9",
         "20010",
         "2019-12-01 00:00:00",
         "359.59998",
         "470.96658",
         "-111.3666",
         "36",
         "481.57788",
         "39.15638777173009",
         "524.94628",
         "448.82078",
         "600.2506",
         "199.86233",
         "420.55204603860494"
        ],
        [
         "10",
         "20011",
         "2019-12-01 00:00:00",
         "392.3829",
         "294.15204",
         "98.23086",
         "36",
         "372.95622000000003",
         "69.17998126435937",
         "423.68508",
         "294.15204",
         "451.71126",
         "287.89488",
         "388.9815815878943"
        ],
        [
         "11",
         "20012",
         "2019-12-01 00:00:00",
         "173.13004",
         "357.11018",
         "-183.98014",
         "36",
         "323.34447",
         "37.93285686386383",
         "357.11018",
         "282.29947",
         "427.69487",
         "258.41742",
         "416.6072952274919"
        ],
        [
         "12",
         "20013",
         "2019-12-01 00:00:00",
         "318.09141",
         "336.1995",
         "-18.108090000000004",
         "36",
         "449.92857000000004",
         "100.60380857965013",
         "527.29677",
         "336.1995",
         "585.41301",
         "192.57147",
         "410.8653413148544"
        ],
        [
         "13",
         "20014",
         "2019-12-01 00:00:00",
         "272.02812",
         "415.85544",
         "-143.82732",
         "36",
         "477.1676",
         "53.26234934800361",
         "512.00604",
         "415.85544",
         "523.3519200000001",
         "262.11276",
         "423.44222665426224"
        ],
        [
         "14",
         "20015",
         "2019-12-01 00:00:00",
         "297.27663",
         "322.45923",
         "-25.18259999999998",
         "36",
         "400.01029666666665",
         "75.17942153774364",
         "472.56925",
         "322.45923",
         "474.26299",
         "277.54758",
         "385.4234111572755"
        ],
        [
         "15",
         "20016",
         "2019-12-01 00:00:00",
         "273.20202",
         "302.11272",
         "-28.91070000000002",
         "36",
         "310.74498",
         "46.930083560756295",
         "361.39194",
         "268.73028",
         "361.39194",
         "184.25862",
         "345.88316439703357"
        ],
        [
         "16",
         "20017",
         "2019-12-01 00:00:00",
         "216.90773",
         "216.83455",
         "0.07317999999997937",
         "36",
         "258.8637800000001",
         "42.674060619087925",
         "302.15469",
         "216.83455",
         "302.15469",
         "165.1092",
         "317.5545266764011"
        ],
        [
         "17",
         "20018",
         "2019-12-01 00:00:00",
         "141.6357",
         "254.22485",
         "-112.58914999999999",
         "36",
         "255.05087333333327",
         "22.39226453951249",
         "277.84472",
         "233.08305",
         "288.46796",
         "127.56209",
         "322.4717887833582"
        ],
        [
         "18",
         "20019",
         "2019-12-01 00:00:00",
         "351.54708",
         "375.38656",
         "-23.83947999999998",
         "36",
         "393.50645333333324",
         "55.32479221727031",
         "455.61906",
         "349.51374",
         "455.61906",
         "231.82421",
         "335.0761069189646"
        ],
        [
         "19",
         "20020",
         "2019-12-01 00:00:00",
         "266.06358",
         "320.50638",
         "-54.44279999999998",
         "36",
         "285.8361033333333",
         "41.94675574379269",
         "320.50638",
         "239.20917",
         "334.15196",
         "235.55749",
         "281.21134799574156"
        ],
        [
         "20",
         "20021",
         "2019-12-01 00:00:00",
         "203.76721",
         "284.14722",
         "-80.38001",
         "36",
         "282.83973",
         "35.813699714733694",
         "317.98178",
         "246.39019",
         "379.40454",
         "187.75422",
         "274.5400187762305"
        ],
        [
         "21",
         "20022",
         "2019-12-01 00:00:00",
         "210.8346",
         "346.19018",
         "-135.35558",
         "36",
         "274.7996",
         "95.70176575563248",
         "346.19018",
         "166.05387000000002",
         "366.85959",
         "166.05387000000002",
         "261.8915003458308"
        ],
        [
         "22",
         "20023",
         "2019-12-01 00:00:00",
         "181.13277",
         "276.31695",
         "-95.18418000000003",
         "36",
         "342.9407800000001",
         "58.579909998188874",
         "386.37963",
         "276.31695",
         "386.37963",
         "252.34755",
         "264.61695275242465"
        ],
        [
         "23",
         "20024",
         "2019-12-01 00:00:00",
         "270.45018",
         "158.4765",
         "111.97368",
         "36",
         "213.02736000000002",
         "60.923454857054296",
         "278.77122",
         "158.4765",
         "278.77122",
         "158.4765",
         "259.9492895747059"
        ],
        [
         "24",
         "20025",
         "2019-12-01 00:00:00",
         "241.83432",
         "243.78354",
         "-1.9492199999999968",
         "36",
         "230.18814",
         "79.69508676564445",
         "302.211",
         "144.56988",
         "302.211",
         "144.56988",
         "230.5608851242313"
        ],
        [
         "25",
         "20026",
         "2019-12-01 00:00:00",
         "235.10419",
         "310.41326",
         "-75.30906999999999",
         "36",
         "298.00460666666663",
         "83.00638461870894",
         "374.10811",
         "209.49245",
         "374.10811",
         "119.35544",
         "240.2866545706127"
        ],
        [
         "26",
         "20027",
         "2019-12-01 00:00:00",
         "155.25876",
         "280.99034",
         "-125.73158000000001",
         "36",
         "246.33545999999998",
         "34.129893935717",
         "280.99034",
         "212.75597",
         "280.99034",
         "210.70695",
         "226.2185096902712"
        ],
        [
         "27",
         "20028",
         "2019-12-01 00:00:00",
         "109.92618",
         "320.29452",
         "-210.36834",
         "36",
         "224.95746",
         "124.89980642591712",
         "320.29452",
         "83.57076",
         "320.29452",
         "61.6707",
         "236.272300647534"
        ],
        [
         "28",
         "20029",
         "2019-12-01 00:00:00",
         "150.64869000000002",
         "160.46681",
         "-9.818119999999993",
         "36",
         "165.94220333333337",
         "29.126638008524427",
         "197.41796",
         "139.94184",
         "197.41796",
         "91.49965",
         "222.86730854925912"
        ],
        [
         "29",
         "20030",
         "2019-12-01 00:00:00",
         "102.7572",
         "96.5328",
         "6.224400000000003",
         "36",
         "112.85820000000005",
         "37.60301026620065",
         "155.8648",
         "86.177",
         "156.9386",
         "86.177",
         "190.79549511038545"
        ],
        [
         "30",
         "20031",
         "2019-12-01 00:00:00",
         "139.91577",
         "349.59721",
         "-209.68144",
         "36",
         "210.14736333333337",
         "123.64895583190035",
         "349.59721",
         "113.88248",
         "349.59721",
         "113.88248",
         "196.02299821455213"
        ],
        [
         "31",
         "20032",
         "2019-12-01 00:00:00",
         "527.79811",
         "906.69823",
         "-378.90012",
         "11",
         "762.58901",
         "138.75173374447868",
         "906.69823",
         "629.90072",
         "906.69823",
         "605.54931",
         "581.1088880322587"
        ],
        [
         "32",
         "20033",
         "2019-12-01 00:00:00",
         "96.76212",
         "184.6026",
         "-87.84048",
         "36",
         "213.92644000000004",
         "35.71351163566496",
         "253.6989",
         "184.6026",
         "257.59188",
         "160.32744",
         "196.57220101041304"
        ],
        [
         "33",
         "20035",
         "2019-12-01 00:00:00",
         "179.97912",
         "189.03836",
         "-9.059240000000017",
         "36",
         "176.59832333333335",
         "34.44451277102412",
         "203.09464",
         "137.66197",
         "219.22125",
         "122.06823",
         "180.36941180236096"
        ],
        [
         "34",
         "20037",
         "2019-12-01 00:00:00",
         "63.37274",
         "93.49887",
         "-30.126129999999996",
         "36",
         "128.41358333333332",
         "33.82393133244196",
         "161.02945",
         "93.49887",
         "265.50803",
         "93.49887",
         "109.88892196390643"
        ],
        [
         "35",
         "20038",
         "2019-12-01 00:00:00",
         "157.68477",
         "135.39051",
         "22.29425999999998",
         "36",
         "164.48139999999995",
         "28.80691344106938",
         "192.99568",
         "135.39051",
         "201.90643",
         "116.57316",
         "173.19582382282408"
        ],
        [
         "36",
         "20039",
         "2019-12-01 00:00:00",
         "128.40394",
         "114.01793",
         "14.386009999999999",
         "36",
         "165.42128000000002",
         "46.2960322470241",
         "203.83493",
         "114.01793",
         "203.83493",
         "105.77768",
         "159.449647352282"
        ],
        [
         "37",
         "20041",
         "2019-12-01 00:00:00",
         "113.11379",
         "97.96554",
         "15.14824999999999",
         "36",
         "154.89228",
         "66.35277260794967",
         "227.76511",
         "97.96554",
         "227.76511",
         "97.96554",
         "154.01604685459859"
        ],
        [
         "38",
         "20042",
         "2019-12-01 00:00:00",
         "124.20086",
         "204.14113",
         "-79.94027",
         "36",
         "223.19168333333334",
         "23.745168137539782",
         "249.79444",
         "204.14113",
         "249.79444",
         "119.0272",
         "157.8302103755908"
        ],
        [
         "39",
         "20043",
         "2019-12-01 00:00:00",
         "93.77222",
         "152.42573",
         "-58.65350999999998",
         "36",
         "157.57996",
         "4.701515533346142",
         "161.63344999999998",
         "152.42573",
         "161.63344999999998",
         "79.39276",
         "172.62264677087396"
        ],
        [
         "40",
         "20044",
         "2019-12-01 00:00:00",
         "59.61747",
         "228.48682",
         "-168.86935",
         "36",
         "211.15558333333334",
         "15.350150099026916",
         "228.48682",
         "199.27309",
         "228.48682",
         "67.96227",
         "166.77546454990596"
        ],
        [
         "41",
         "20045",
         "2019-12-01 00:00:00",
         "149.89961",
         "137.49552",
         "12.404089999999997",
         "36",
         "159.30449000000002",
         "49.91355032443296",
         "216.41113",
         "124.00682",
         "216.41113",
         "106.41326",
         "151.39781992693307"
        ],
        [
         "42",
         "20046",
         "2019-12-01 00:00:00",
         "149.9563",
         "145.50198",
         "4.454319999999996",
         "36",
         "198.23221",
         "50.3039677099918",
         "245.69546",
         "145.50198",
         "245.69546",
         "91.65451",
         "148.64084461866247"
        ],
        [
         "43",
         "20047",
         "2019-12-01 00:00:00",
         "71.49763",
         "251.43491",
         "-179.93728",
         "36",
         "182.32697666666664",
         "67.0106543983368",
         "251.43491",
         "117.63171",
         "251.43491",
         "113.47343",
         "159.46793797498944"
        ],
        [
         "44",
         "20048",
         "2019-12-01 00:00:00",
         "58.89241",
         "133.17067",
         "-74.27826",
         "36",
         "176.90997666666667",
         "47.231858801252415",
         "226.99316",
         "133.17067",
         "226.99316",
         "103.20842",
         "164.94098011231716"
        ],
        [
         "45",
         "20049",
         "2019-12-01 00:00:00",
         "124.84836",
         "153.36048",
         "-28.512119999999996",
         "29",
         "211.57864000000004",
         "54.19016011278804",
         "260.5512",
         "153.36048",
         "260.5512",
         "153.36048",
         "205.41855530011907"
        ],
        [
         "46",
         "20050",
         "2019-12-01 00:00:00",
         "117.02742",
         "145.10495",
         "-28.077529999999996",
         "36",
         "138.59953333333334",
         "6.864831336837771",
         "145.10495",
         "131.42438",
         "151.46476",
         "109.82896",
         "146.9040351620601"
        ],
        [
         "47",
         "20051",
         "2019-12-01 00:00:00",
         "132.46038",
         "105.18797",
         "27.27240999999998",
         "36",
         "136.62474333333333",
         "33.92014914308202",
         "172.57611",
         "105.18797",
         "175.49517",
         "105.18797",
         "159.67906114632322"
        ],
        [
         "48",
         "20052",
         "2019-12-01 00:00:00",
         "95.51068",
         "79.25908",
         "16.251599999999996",
         "36",
         "133.27769666666669",
         "47.62072852971537",
         "169.18788",
         "79.25908",
         "169.18788",
         "79.25908",
         "134.1872979676638"
        ],
        [
         "49",
         "20053",
         "2019-12-01 00:00:00",
         "146.36584",
         "174.10464",
         "-27.738799999999998",
         "36",
         "151.63951999999998",
         "22.58843359555506",
         "174.10464",
         "128.92976",
         "197.59135",
         "101.27047",
         "154.97755866776643"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 880
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_lag1</th>\n",
       "      <th>tn_diff1</th>\n",
       "      <th>size</th>\n",
       "      <th>rolling_mean3</th>\n",
       "      <th>rolling_std3</th>\n",
       "      <th>rolling_max3</th>\n",
       "      <th>rolling_min3</th>\n",
       "      <th>rolling_max6</th>\n",
       "      <th>rolling_min6</th>\n",
       "      <th>tn_t2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>1504.68856</td>\n",
       "      <td>1397.37231</td>\n",
       "      <td>107.31625</td>\n",
       "      <td>36</td>\n",
       "      <td>1539.627813</td>\n",
       "      <td>132.676441</td>\n",
       "      <td>1660.00561</td>\n",
       "      <td>1397.37231</td>\n",
       "      <td>1678.99318</td>\n",
       "      <td>1109.93769</td>\n",
       "      <td>1368.557567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>1087.30855</td>\n",
       "      <td>1423.57739</td>\n",
       "      <td>-336.26884</td>\n",
       "      <td>36</td>\n",
       "      <td>1497.767150</td>\n",
       "      <td>449.292044</td>\n",
       "      <td>1979.53635</td>\n",
       "      <td>1090.18771</td>\n",
       "      <td>1979.53635</td>\n",
       "      <td>813.78215</td>\n",
       "      <td>1061.426158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>892.50129</td>\n",
       "      <td>948.29393</td>\n",
       "      <td>-55.79264</td>\n",
       "      <td>36</td>\n",
       "      <td>999.143847</td>\n",
       "      <td>71.869729</td>\n",
       "      <td>1081.36645</td>\n",
       "      <td>948.29393</td>\n",
       "      <td>1081.36645</td>\n",
       "      <td>635.59563</td>\n",
       "      <td>798.040597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>637.90002</td>\n",
       "      <td>723.94206</td>\n",
       "      <td>-86.04204</td>\n",
       "      <td>36</td>\n",
       "      <td>858.269930</td>\n",
       "      <td>181.458030</td>\n",
       "      <td>1064.69633</td>\n",
       "      <td>723.94206</td>\n",
       "      <td>1064.69633</td>\n",
       "      <td>482.13372</td>\n",
       "      <td>597.680743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>593.24443</td>\n",
       "      <td>606.91173</td>\n",
       "      <td>-13.66730</td>\n",
       "      <td>36</td>\n",
       "      <td>827.740853</td>\n",
       "      <td>200.028225</td>\n",
       "      <td>996.78275</td>\n",
       "      <td>606.91173</td>\n",
       "      <td>996.78275</td>\n",
       "      <td>536.66800</td>\n",
       "      <td>572.593556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>21265</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.05007</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>-0.01593</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064093</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.10921</td>\n",
       "      <td>0.01707</td>\n",
       "      <td>0.10921</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.053078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>21266</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.05121</td>\n",
       "      <td>0.06713</td>\n",
       "      <td>-0.01592</td>\n",
       "      <td>10</td>\n",
       "      <td>0.071293</td>\n",
       "      <td>0.045079</td>\n",
       "      <td>0.11831</td>\n",
       "      <td>0.02844</td>\n",
       "      <td>0.11831</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.055428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>21267</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.01569</td>\n",
       "      <td>0.04052</td>\n",
       "      <td>-0.02483</td>\n",
       "      <td>10</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.09676</td>\n",
       "      <td>0.01830</td>\n",
       "      <td>0.09676</td>\n",
       "      <td>0.01830</td>\n",
       "      <td>0.059385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>21271</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.00298</td>\n",
       "      <td>0.01301</td>\n",
       "      <td>-0.01003</td>\n",
       "      <td>30</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.02933</td>\n",
       "      <td>0.01301</td>\n",
       "      <td>0.02933</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.013538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.00892</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>-0.02449</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>0.01856</td>\n",
       "      <td>0.04086</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.020050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>880 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id    periodo          tn     tn_lag1   tn_diff1  size  \\\n",
       "0         20001 2019-12-01  1504.68856  1397.37231  107.31625    36   \n",
       "1         20002 2019-12-01  1087.30855  1423.57739 -336.26884    36   \n",
       "2         20003 2019-12-01   892.50129   948.29393  -55.79264    36   \n",
       "3         20004 2019-12-01   637.90002   723.94206  -86.04204    36   \n",
       "4         20005 2019-12-01   593.24443   606.91173  -13.66730    36   \n",
       "..          ...        ...         ...         ...        ...   ...   \n",
       "875       21265 2019-12-01     0.05007     0.06600   -0.01593    10   \n",
       "876       21266 2019-12-01     0.05121     0.06713   -0.01592    10   \n",
       "877       21267 2019-12-01     0.01569     0.04052   -0.02483    10   \n",
       "878       21271 2019-12-01     0.00298     0.01301   -0.01003    30   \n",
       "879       21276 2019-12-01     0.00892     0.03341   -0.02449    10   \n",
       "\n",
       "     rolling_mean3  rolling_std3  rolling_max3  rolling_min3  rolling_max6  \\\n",
       "0      1539.627813    132.676441    1660.00561    1397.37231    1678.99318   \n",
       "1      1497.767150    449.292044    1979.53635    1090.18771    1979.53635   \n",
       "2       999.143847     71.869729    1081.36645     948.29393    1081.36645   \n",
       "3       858.269930    181.458030    1064.69633     723.94206    1064.69633   \n",
       "4       827.740853    200.028225     996.78275     606.91173     996.78275   \n",
       "..             ...           ...           ...           ...           ...   \n",
       "875       0.064093      0.046100       0.10921       0.01707       0.10921   \n",
       "876       0.071293      0.045079       0.11831       0.02844       0.11831   \n",
       "877       0.051860      0.040441       0.09676       0.01830       0.09676   \n",
       "878       0.022290      0.008387       0.02933       0.01301       0.02933   \n",
       "879       0.024253      0.008008       0.03341       0.01856       0.04086   \n",
       "\n",
       "     rolling_min6   tn_t2_pred  \n",
       "0      1109.93769  1368.557567  \n",
       "1       813.78215  1061.426158  \n",
       "2       635.59563   798.040597  \n",
       "3       482.13372   597.680743  \n",
       "4       536.66800   572.593556  \n",
       "..            ...          ...  \n",
       "875       0.01593     0.053078  \n",
       "876       0.01480     0.055428  \n",
       "877       0.01830     0.059385  \n",
       "878       0.00445     0.013538  \n",
       "879       0.00223     0.020050  \n",
       "\n",
       "[880 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_test.merge(df_preds_t2, on=\"product_id\", how=\"left\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de28d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_copy = df_final.copy()\n",
    "df_final_copy = df_final_copy[['product_id', 'tn_t2_pred']].rename(columns={'tn_t2_pred': 'tn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f9491f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1f7494ff-53c5-4af0-b9e5-9e6ec9013329",
       "rows": [
        [
         "0",
         "20001"
        ],
        [
         "1",
         "20002"
        ],
        [
         "2",
         "20003"
        ],
        [
         "3",
         "20004"
        ],
        [
         "4",
         "20005"
        ],
        [
         "5",
         "20006"
        ],
        [
         "6",
         "20007"
        ],
        [
         "7",
         "20008"
        ],
        [
         "8",
         "20009"
        ],
        [
         "9",
         "20010"
        ],
        [
         "10",
         "20011"
        ],
        [
         "11",
         "20012"
        ],
        [
         "12",
         "20013"
        ],
        [
         "13",
         "20014"
        ],
        [
         "14",
         "20015"
        ],
        [
         "15",
         "20016"
        ],
        [
         "16",
         "20017"
        ],
        [
         "17",
         "20018"
        ],
        [
         "18",
         "20019"
        ],
        [
         "19",
         "20020"
        ],
        [
         "20",
         "20021"
        ],
        [
         "21",
         "20022"
        ],
        [
         "22",
         "20023"
        ],
        [
         "23",
         "20024"
        ],
        [
         "24",
         "20025"
        ],
        [
         "25",
         "20026"
        ],
        [
         "26",
         "20027"
        ],
        [
         "27",
         "20028"
        ],
        [
         "28",
         "20029"
        ],
        [
         "29",
         "20030"
        ],
        [
         "30",
         "20031"
        ],
        [
         "31",
         "20032"
        ],
        [
         "32",
         "20033"
        ],
        [
         "33",
         "20035"
        ],
        [
         "34",
         "20037"
        ],
        [
         "35",
         "20038"
        ],
        [
         "36",
         "20039"
        ],
        [
         "37",
         "20041"
        ],
        [
         "38",
         "20042"
        ],
        [
         "39",
         "20043"
        ],
        [
         "40",
         "20044"
        ],
        [
         "41",
         "20045"
        ],
        [
         "42",
         "20046"
        ],
        [
         "43",
         "20047"
        ],
        [
         "44",
         "20049"
        ],
        [
         "45",
         "20050"
        ],
        [
         "46",
         "20051"
        ],
        [
         "47",
         "20052"
        ],
        [
         "48",
         "20053"
        ],
        [
         "49",
         "20054"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 780
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id\n",
       "0         20001\n",
       "1         20002\n",
       "2         20003\n",
       "3         20004\n",
       "4         20005\n",
       "..          ...\n",
       "775       21263\n",
       "776       21265\n",
       "777       21266\n",
       "778       21267\n",
       "779       21276\n",
       "\n",
       "[780 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos = pd.read_csv(\"../../data/raw/product_id_apredecir201912.csv\", sep=',', encoding='utf-8')\n",
    "productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ae2ad5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f3991f25-49c8-41f8-9b17-c730ddb4712b",
       "rows": [
        [
         "0",
         "20001",
         "1368.5575674877643"
        ],
        [
         "1",
         "20002",
         "1061.4261583114098"
        ],
        [
         "2",
         "20003",
         "798.0405966352357"
        ],
        [
         "3",
         "20004",
         "597.6807432474684"
        ],
        [
         "4",
         "20005",
         "572.5935562758511"
        ],
        [
         "5",
         "20006",
         "538.1403510970442"
        ],
        [
         "6",
         "20007",
         "492.81371199044116"
        ],
        [
         "7",
         "20008",
         "473.08302866442966"
        ],
        [
         "8",
         "20009",
         "455.85752784530666"
        ],
        [
         "9",
         "20010",
         "420.55204603860494"
        ],
        [
         "10",
         "20011",
         "388.9815815878943"
        ],
        [
         "11",
         "20012",
         "416.6072952274919"
        ],
        [
         "12",
         "20013",
         "410.8653413148544"
        ],
        [
         "13",
         "20014",
         "423.44222665426224"
        ],
        [
         "14",
         "20015",
         "385.4234111572755"
        ],
        [
         "15",
         "20016",
         "345.88316439703357"
        ],
        [
         "16",
         "20017",
         "317.5545266764011"
        ],
        [
         "17",
         "20018",
         "322.4717887833582"
        ],
        [
         "18",
         "20019",
         "335.0761069189646"
        ],
        [
         "19",
         "20020",
         "281.21134799574156"
        ],
        [
         "20",
         "20021",
         "274.5400187762305"
        ],
        [
         "21",
         "20022",
         "261.8915003458308"
        ],
        [
         "22",
         "20023",
         "264.61695275242465"
        ],
        [
         "23",
         "20024",
         "259.9492895747059"
        ],
        [
         "24",
         "20025",
         "230.5608851242313"
        ],
        [
         "25",
         "20026",
         "240.2866545706127"
        ],
        [
         "26",
         "20027",
         "226.2185096902712"
        ],
        [
         "27",
         "20028",
         "236.272300647534"
        ],
        [
         "28",
         "20029",
         "222.86730854925912"
        ],
        [
         "29",
         "20030",
         "190.79549511038545"
        ],
        [
         "30",
         "20031",
         "196.02299821455213"
        ],
        [
         "31",
         "20032",
         "581.1088880322587"
        ],
        [
         "32",
         "20033",
         "196.57220101041304"
        ],
        [
         "33",
         "20035",
         "180.36941180236096"
        ],
        [
         "34",
         "20037",
         "109.88892196390643"
        ],
        [
         "35",
         "20038",
         "173.19582382282408"
        ],
        [
         "36",
         "20039",
         "159.449647352282"
        ],
        [
         "37",
         "20041",
         "154.01604685459859"
        ],
        [
         "38",
         "20042",
         "157.8302103755908"
        ],
        [
         "39",
         "20043",
         "172.62264677087396"
        ],
        [
         "40",
         "20044",
         "166.77546454990596"
        ],
        [
         "41",
         "20045",
         "151.39781992693307"
        ],
        [
         "42",
         "20046",
         "148.64084461866247"
        ],
        [
         "43",
         "20047",
         "159.46793797498944"
        ],
        [
         "45",
         "20049",
         "205.41855530011907"
        ],
        [
         "46",
         "20050",
         "146.9040351620601"
        ],
        [
         "47",
         "20051",
         "159.67906114632322"
        ],
        [
         "48",
         "20052",
         "134.1872979676638"
        ],
        [
         "49",
         "20053",
         "154.97755866776643"
        ],
        [
         "50",
         "20054",
         "146.33583602542532"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 780
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1368.557567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1061.426158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>798.040597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>597.680743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>572.593556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>21263</td>\n",
       "      <td>0.021371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.053078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.055428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.059385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.020050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id           tn\n",
       "0         20001  1368.557567\n",
       "1         20002  1061.426158\n",
       "2         20003   798.040597\n",
       "3         20004   597.680743\n",
       "4         20005   572.593556\n",
       "..          ...          ...\n",
       "873       21263     0.021371\n",
       "875       21265     0.053078\n",
       "876       21266     0.055428\n",
       "877       21267     0.059385\n",
       "879       21276     0.020050\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_copy = df_final_copy[df_final_copy[\"product_id\"].isin(productos[\"product_id\"].unique())].copy()\n",
    "df_final_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd36585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_copy.to_csv(\"./outputs/predicciones_lstm_kaggle.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ba72dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2617732191017372)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerador = (df_final[\"tn\"]- df_final[\"tn_t2_pred\"]).abs().sum()\n",
    "denominador = df_final[\"tn\"].sum()\n",
    "porcentaje_error = (numerador / denominador)\n",
    "porcentaje_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "83438dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_final.plot(kind=\"scatter\", x=\"tn\", y=\"tn_t2_pred\", title=\"Predicciones vs TN\")\n",
    "plt.plot([0, 1400], [0, 1400], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8efe03d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": {
          "bdata": "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",
          "dtype": "i2"
         },
         "hovertemplate": "<b>TN Real</b>: %{x}<br><b>TN Predicho</b>: %{y}<br><b>Product ID</b>: %{customdata}<br><extra></extra>",
         "marker": {
          "opacity": 0.7,
          "size": 8
         },
         "mode": "markers",
         "name": "Datos",
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "tUp2SgHCfUB/FRgbaw96QCJhQADJsXRApS3tKemqlEC06gv6l42BQJiFpUgX9W5AFRrGgzOIeUCKHZLdM158QKvgdrPl/2VAeJFGIIIvZUA2UNy0TouIQLt15c/ybXhAmp18wXvpWkDsNN47+KNzQHSqoUt5A2BA4VKHtkkQd0AkAFbBx3tkQOSsrZUmB2dAaQwREiAJZ0AQBvC2KTlWQJCguF/E3lhAiEaI7ajLaUD8UgRMAUZwQDpFj/cUnmZAAXqMT46JbEAsJLRQjIKBQGYIB1bOtVZApJSM/eO+UkBGOD6DJTlbQGQXn5bSFHdAL1wXMgJJakD5a7SgSRBsQDjbvECXJlhAPxEVMKLJYUAIzSL19Y+AQEM5Uo2wZU9ApJ+4LEWeVUDFdQ0tf3lTQJLi9znGC3xA/t8DFmJaW0B3W7ubdVReQPZ1axsKImNAtmz+7lXAU0CgCdvF7QNVQCC5CZxczEhAtLdtR8rkSUB7oDVlTpBTQBU+LWECxFpA3GgkxZhueUBCt3ZL4zFvQMyMhufInlJAbKydLCtRkEAx8JVKqF1mQIidzpZIrElAfPcvBg7/WUA6GfTCK4NaQEzD0OifoUdAMLZDDMC6gUBjtuYlqIxzQFR0JJf/DWpAOheZra9oUkArwtFxCHFfQHtU+H9tNHZAC4tQtKzXUUAatI+22uJZQJh1WbdRkUhAwkbwb+VFYkAGgZc6zQNVQHauDdFlaVFA21AxUwDoUEBFNeW+0ndiQPgttD3xHG5AoUoBmhZLNkCR3opZlVlMQKjjOYw65V5AUYjvdKWlYEDOqlbETBFCQJSMJyW6Ek9A3BG1Do9hVkDG7JyNdI9QQFKIppVljlFA0CIWOiAdUUDpdP6xQCNhQJ4k56x1UWJAPPdDh1YvVEAs2nIh8JhjQE87/DVZi1RAw0TaJvl9RUCsbhqCNAxLQKfiIxhicU5Ae2XJJ0S8UEDYx0+mOxNZQEsccK38419AKQrkkJnDXEBM4K43IfxMQI42kOUifEFAud/NUPONNECKAobp2thbQLjROCJHzkxANiRIv7skSUB5WBs1f/A8QC1gKIHvKUtAPUmyUlRNTkAhyqeNae9hQIEUuvQh+1FAOk6SxiYvVEA98jVQ/GdiQC19GhlF0DdA30+fJ5TGQ0C87RjxHxtTQKTcb2iPlVRAEeZPwZrMR0CKcXvW6PpCQHBfA55b4jFAeO59VmooRkD6J40T9KM0QDh/qmR9RERAnbrK5XrWQECH3Mp9jzdQQC7I8+UIFkRAvvtbyhP1MED6LM8P/kNGQCVKqsWUV1NAbGqJ7L4tbEBEKiiam200QOvFphZIo0BAroETwSQLREDT9mOPm6AzQFa92ZtCukNAR+al4P+cQ0DyUnYmNClMQCzzF33wp0NAjOg/ofCBXkDFO1rDWCRcQHzLAbIiPDhAibWBIE8uOUA0orDA+tpCQBnF3X1BHlJAxTg9COKCPUAZi+IzOOlVQE+v0HMZ2TFABFHH9SNLRUAYCSOoPJcqQCFBYQE29ytAwmzL6L2FYEAnDv7wgFpVQMvbgQpoqDlAK9HsjIkDXUDIgOxgNkUrQBr6EjMb2zJANSnVTCfDQkBYUUMzfGlSQG/kedxlvi5AjZm2C1FYQkBIbU7FNaU3QEgR6+cEtlBAlzTOas8dJ0BW5Uhe+Qs1QI6l3xP89SxAuqDNzzgcQEA1Pe+uMKhXQL4YZmIZtyZA63MnoHbqQEAK/2PmJso0QPWzzuUo3FJA9i2q5+uIWUCe6u0n+EVGQGVw1p3nWktAb5kLB9lWNUCesKjf6uswQN9gA8/UMU1Al27kkpwBVUCA/F/GGm41QIh0UdEPVE5AACJ/rdRyOEAcTvbX/VlCQK36nRlfHTBAIuAQqv/1K0BApGgR0JssQJgGQLFmjDJAqysg/iQ4OED27j+ISOBAQFs4bJcX0TxA5LpGvkeTY0AaHMUTexYtQEGiQwUqAkNAgFS8Jui3LUDvrGTNxs4xQFSkvhFOYDpAJEUQ82NiMUDuCBt7xoUoQNBEKCeNTSVAM3JG8MQEFUDy0gXMBtYrQN1saKcdQUlApuIO/NJPcEAYmgsBOLI/QNb/ObWlsTBAWOwex1SLNUAPr8djYGVMQM9JXzWLAi1AAxo7loa8K0BmTixEH7U5QMTrl+WTVUFAs7BQbcDCMEAsQ1pDf18yQFNXhtOSbzxAGLyLxUVbUUB9kTqfDgYyQG71FXhYyFlA7l8zfTJBQECWCUuIZncwQHkGPMPiFClABK3Avw7ULEBGmafTI5UfQFIFR15+1ypAXfk1rRt8NEDnBYDT5Dw1QHgL0NyOOiRAoAIgTpqhL0AT/oAhByokQGE4tIbOElJAHJkXz+foL0Bn3oXJLs1hQN4kovp98S5A0jWTP5cRLEA45UoJoWEyQC6yfU/jxxdA1vq6+IVlM0CBeEuCvCc5QBmQg1OxMERAmqwRw4rEMEAGaapsNU0wQB7EYoqkOjxAHhFnnVQ4J0DlvlIIgKYyQP6aIIeGnyVAGCGcK6CwH0BVb1UoZxErQFBOjL2AqilAFh6hjTM6MEDfQ4BUee4yQAihUjGkyUFAryVoNO/mOUAwXrU6py1QQAITYAPqxltATx7Gie86RUDGxMcBksVCQJmBSgmG3x5A01lKKOV+ZEBGmY04ZUcpQPJGmrv6QyRA/Z9/G+/LGkAIyLcHVjNZQGuwcQZiQ1VAB1rppA9DKEDnkV9s10EtQKBFPfxX4TBAqp+XdQJuIEDBBH0hX4QiQDT004IKcDZA0xMxs/ujNEA9LOxVrM8pQF04/GDk9ypATV3Z4Ua+H0C6FDH8ssItQE96t4leVTBAvHQn7cvVKUA0d6XxuJUsQIGtSn94oShAtr4qEBHHIkDrLZievNQxQOvKshfLzzRA5e2ozs3NMUAvuYE7+FoxQIrvqrHLODlA2A3b8RrrOUDfvmoT1CIjQOOrNSMAUEhAE9U7tZU8UUCamXFNGT4yQFYOZvWwMzNAtkXk60HSJUBdOFicoogyQPnr4f1dXy9AZiw4EEq9IUDiGWqeW4AmQF4/4neyqVRAriqWdxWFNEBV+/Re/0wcQIRkLzyFEyVAQolG8ziEOkBxPWlLNGNEQFK4LkHG9jxAFvac+jJnIUBBq4QzJB9VQBIZblHbQyJABK0ATqUVGECrmpvIP1MwQATnjHNDri1AI2wINwJYOkDhI8rfGMspQL+YOy6eSmJAaESDExL0VECTALXZpWosQJB3uO+k4WVAHbGGu1pnFUD3x2MRcucwQHIbbX5H3zJAYjdEaPjUKUA3hrp43FNjQEYgjp0rjCtA9pd1IiShJkCDnkkpTqYSQPAue/ivazBAumsZDIuNOUB8uGyv1EAUQJ/gIv+diihALt3kg4p3J0DfNz5vURtMQGv4AEtI0ilASwLU8J/OMEBcAzCmV/tAQGwE4lwswyZA0XTm0QTcNkDmdCNhuEQxQDUHWMeqwTpApvK+8xzSG0DhC/Bf7k4jQEvgNk/oIBZAEqAEx7JAKkBIszbXZD8uQMmrjpXabC5Ao3on1/HEK0A2VD09yHVJQKLRnZNLFylAkTPUOfovO0Cdv7FnpglLQPyXIW7+EVhAQN7/p5GDJECOx0762OBwQMA+59bvliFASD4cD9XnQUAsSPtEQUs5QHbIN26KWTdAmG6e/tCKEUBgNyxEbN0QQE5PYFUJ2m1Aeo0dtGTyLkBUNaGos74RQOROwT0GIxJApkQSpjLdFEATSUTFfoEjQHRZtE0d/CBAEHAAGMhtEUBE3Sf8nuolQMumOmWutjVAehlRkmcrUUC/8XlhouclQMgZZU4EpDpAcGQtLrSjVEDe7xAOSAMVQL2pCKuzWw1AsKwiznoULEAEHJHmDuQ0QJPG4JVERhBAyUgxNm/3EUDGFoP9wI0uQFFJTVORnRNADfgMaae3KUDNklC6fDglQN+JMm/jhRlAJaPZ0GjQUUDFWnwTCEIcQBohBNVNZi5AuAYqhhdqIkDpfc9n/B8QQPrQk/LF8zFAGNR3U6zKM0AQQF5+V1IpQOkrojRFukdAOou4OOxWWEBfgNV1LwwzQHemkLCf1CtAxSB0oSGLGUBXBNeiFtEjQDoeM+VH0BdADYmjHz6mMEBIPaTbD5gSQKziWdMvQ0lA17vvTDhxJkBwgTwuAZAvQMXEReckVCpAIxCvJ8FuF0AMB4wEv9kxQEF9y5wu/yhAPwYIwj5fMEC2EHz9jQkkQKtWsscYMyVA9b5THTNvHEBR35J5zWsVQLqDwM31NQdA2snA+uS+JkCRuEhsaMcuQBFACuCCUCBAtOBtBZWCB0CuzjEge1UoQNhkrYEC7idAoAfDCvl/H0BY4pkpFn4kQAouFldrbCJADeVKcLYvI0DVYBoGR08JQII5Ku2XdBhA7ggzc3zpIEAWaiXxj2ggQEZCp/bBABNAPNr4D4tVIkDbvxLXf+csQL2M0tMqlhhAJ3IB53NAJkC9Hb/2en8tQIY41k+MHxNA7Q1smDO+B0A+rt1Ga+I+QKDDRLtirwVAEohpb5P+NEAGntuM2IcHQGcPlr4RATBAp2jk5q14NEALmEt3DLcxQOS9aqu8BwpAmvDLbeysA0AvHIjFLrcMQPKAuoBvnRNAo1jyz6ZuNkBDF3TUFn5HQG7Ar27JLzRA+wV75oejJkCmoMsMiuoJQCqRlGVYSghAVaQynNPdA0AfgEw8+XoRQFiHr+zKMjZAH0YoYkE7AkAAHeo4UychQM5O1ukPURhAoL6laVqIA0C0VAZIk/MxQCow5IqxghlArDThPGdYJEDW3SDdfBMPQCQoRv2DCxhA9BBNkGaJBUD6J7hYUVMPQMrggLnD8x5Av3eYKgPvXUDbFsV998QWQECH+fICrAxAr1/w6pifOkDkoGTN3EQBQARzzqo8nwRASuqUgACCEUB+jLmr08gDQG54eqPrJ/0/lfHvMy7sCkDkLOy51s0EQCKJPmzuxxBAr/yb6cajLkDw9BSaQDABQGzPjGofgxJA6crH1MaZDkChSnwSuD44QEp7Y12qaSJA+3mh3kh1HkAe/kpphGMQQNf10vuYORZAOiNKr40GIUDz/VwLBVk1QMAOfEt14QdAikYXWjzc+T+CHNRelM4AQDvHZPLymyxAjzbYh2rKQEDjcC4xYssbQB4uOdT6AAVA4UXYWNJvE0BeaE76AFcWQMjvHf9KRAhAG0K19K4Y/T9ukHGOm40LQM2ZO7PD8ypADk/PJwytHUBFTKdg7eorQLqgkKnKkC5AFOiz2LPOE0AfgKDKUNdMQBHpH4QnkBtATIlfF2hjFUBXPjcaYXcTQME5I85lWgRAUSz3MEoyCEDLC+46GkAhQLx5+oYvNyFAUpvA92gUHUDHv+VXwQMyQHYyWHEigwBA0uju7YwOB0ALnb+mTRgWQFndytiCUCRAAK4O/bMxDUBCssD8GQIjQHA9ekRfLwJAYi1uGWtOEkBMyIf32qb3P3r8khva2fc/eAtYVlUtKkBsJq8E5coEQODIvB6Qffw/lniIrO6AAED/ldVQRoL6P1SMs/C+XxpAZGKjknzfDUBSmziHtML1P9xtF4ICLgFA0ldQDOT/FEA3cZLZpiEaQKxRT0yoW/o/5Nqop2UnAkA0mPbVw1ELQNjTzsbAwRpAGT7S+vUADUA4Vsj7M0U0QDWAWfuMQgFAwlFyLpnmDkCa5p3KjJsKQMyXw4FxnyRAGTkLxQcpGkB3LYHD1lkRQCwJuMlpJCxAYDdMcucNDkBieoJCyxn0P4fE8XuMHuU/aFx4MLC1AkCaLy9T9TrqPzkQ0ormNyBAn6vdNnAlFkBOSmHWWRP7Px/5g98/+wNA7rYrex+c9D9RiICZ76/xP7j3sCRUtvw/dHtrMZfNEEBoPyJ4/vgrQEjhepbLj/g/TMNwpIGQ+j+lCBatR5YtQEF4tOHEnN0/eEDR+3SWB0CoqWWfxUX7P2odtUUAx/8/Cym/RELCDEBQg0mCIQ/+Px9oBQ2lyxBAqjDReHznF0DdkyGE+HsHQPwd+sW8aA9ASDOGLT7xGkC2LarX6TsDQFPt/TjocSxAgxc9TydfEUBe9JVjE+8BQLgBDwedlANAxzPoBZx4C0AKuiVVczYkQNRIeZUyUiVA9nq3frS5CUDKMpy33Z4RQFzcFh01JAhAE36AIjh4KkCYrtxmt7ZAQFysqOCauP0/qs8VpmexHUDz/TSBeEgmQG404Gg6/fI/LQS5TBES8z8B+0hHQUHtP59ZuhkkcxZAb+sO/KiDBUCRfpm/+dEQQE65QvyKbvY/hpTnVpcQIkB+9gMnDIH4P3WT/PsNqBBAcr9D+Z0ZAEAjTxKi4wgaQCY7Jq80qQxArJjYKjHA7j+m/ATE/NQeQKt9Oqc3Re4/vJaQEO3d/D85l6KzpLMCQEVHMNxx3SlA98yiWhhWMkCgpli1vCwYQA3gbfYRVRdAlufB1Za68T8AAEAHQfcBQHNGFDdbcANAstebSP3iFkC5/H8xI+klQEXr6Hh0+/k/d74PG46c8T9JnYC0HB7mPwrX+6VgUARAF1sQUqKr7z8KEXDFNOgMQBdIcP2eyuk/Itv5PWKr7T+Or/1PqQcuQADLCvmodglA9BqjgVGcH0CSy3+cKLgJQI5YC5u+HPI/+gqCy8gKF0BEu1q5SNAjQP/s23vrowJA8mPMFWIf7T/6g4pqCRAgQMS2beCsBiBA7pRuKzmJCUBa2BOfg3jpP1DfUsHKlgRAnNwvbyBn5j+BPVDa4q8xQHb9Qm/Vw+8/dVkMeR2y7D/m0PaXnYUnQMmTZOOQWfo//s8BEVSi/z+skPLTS7EAQD5ccuQwB/Q/PKDceHUlHkCPcFpVSb4EQHSTmOkoRuk/1lEV1yIO/T+rJnBWQ5YfQKbC2Olkbv8/nOGmvw/G8D+wrLSUA0DrPyaqpSZxIw9AgSaDK1Y9QkD21qCDWosAQPSrfXw+8B5A76fG9ho28z8rAATPK+8ZQJBrY19NlPU/Fvvblo3ICUA8TtFBehDtP8mOTWYKnPg/EVhZ55KQAUCA1AbkfYwKQHU3n+PEFRNABg092Nrp9D8gRiS9JXwQQJqoXtvpgts/4gElz/1I4z/BWyAkNBbxP1zh3eCHqOc/eCgKhx1bEkAg6n7vJAwKQGcnsQHl8StAKL3H8DVrHkDxext00PQHQIUIOKjWsOs/ZOlDBefjGkAkLuGEM8YyQCf3OwPjc+o/Xi7izdVb8j9cDQnhAaDtP9VDFKjjCvI/+HD5kxw+G0AWGHK2a5z1Px6n6J6E9PM/dR+sXzNPAEBAatuxsisLQMC3af8MROE/OEXHsk1O6T+4zGnChc3lP6WD9ZTAyds/JnALwMAvIkAOLco7UGwOQH9ltf8/nAFAiClxLucUC0Dkg143UtPdP5BJ60wrpyhAKGaZyRIaFEDvOLUxg6kjQFvrS3bQqwlAbA5Q6j9U6T9ibAHgoKchQH0deLcF4fI/Cyn/ounk5T/HDPSJqLgAQM9OBl1PCsM/Qj7oVZuz6j95XV97BcACQFFmg6yniQtAmIFqHw6DBEAAP6Ma7TzqP8oQh3Vmcvg/L/qK6VPb5j+WJhUrPaoWQL5Nv39PoOo/2SoBmWG55z9OlyUarWT1P2Ji04g7/9g/2j15vOVH2z93MhhuXrzxP9r+1cOZq/g/esfxWNbiMkAdVY2+slXYP3qvGrSdZd8/WpnwRttt2z+zdpv9XFvlP3KnCOBTHC5A7ZnxJZpFIkCF8MheKcv+P4JRf5hgPzFAKGFm7ikF+z+H/vFddGz2P+HRxquNCOU/fQWJNf5tFkDwOEXyAdHvP/bp+IgMFfo/5lfzfpZQ+T/ZIBPHXz7SP5sDBB/bzd8/mbuWcr8WEkAv/32I3P37P034BWS16ANA4ITxo8EmDEA34Ld6IxUcQFr1uVSryOc/lj503a/I5j+zJBKx6ssGQMAOROUwMgNAjHqIuqly/j9pm5t+B9/sP7H+z05BZss/jPO3IsVK9j/iBuyd6H8lQFzEtybVudE/Xp0ju+Vz4j9amfw7k67zP6C+pZWFOPU/AiuHFtlO2j8hWQBvMD/9PyQcTs2AAixAeGL20U597D/Ac++x8fKMP627+W+65vQ/vR0htGmc0z8RAYdh8ifuPypcZW07Svs/yqFF/uOK6D/TGBPSoEj+P3pwd+KW//A/uXVPU3FeB0ARiNe+wV/EP15GxeKitBFALWDCeOVl7j+62rqdn4kcQIcWWaZfUfE/lGof7y8D2D+36Y/j7Mr1P9tQscjz0OE/n6tNhrTM4T+l2qeYCkPlP3hF8FlHLsc/hIFniEeg1D+HmBJ1FXXPPwrXV7M2SApAthCUMLa8BEBwZB5fCXjvPyjyJOmaCe0/d2IW8x995T+lClZ0f+YaQCc2LzKPQfM/B9NQQFWxAECmfpO8Ci08QMWsFwGHIMs/kJvhKZZf/D8qV3jKGjPCP+p4zMp/6SdAW1+keVqMwj8rpIwRiH4XQCo6AhhdqPk/F4Ick+qyxT8koS2DreTFPzCBe3lM+fw/h3JiV5TQAUAXYB/pLxDxP6omSGrF6vg/nkF/d7v0IEA7I0oLgpzYP2A9edW/ezhAQgkzgQkE2j8sgv89GADNPw0Vwz76NfM/ox4YcftWBUCM8zd5tecHQDuX4o77vLw/4LTguQE9sz+Aslnr4ewHQN3qCczLC9M/kApjLMC7zj+FmfZvq4zWPyr7PkQg6TJAbp4qd3AN3j9Bn7A7NyTyP7ugvi+iVsw/RpSy76a9AkDxRiaaSbT3P5xt7vkHT+w/+DEGQ6e2/j/KN9u5bmfWP0QX1EcIqLE/l8XECJKl9z9au+3W1XPBP170FRC4rPA/iIpxhCX0AkDZmUJDvrXAP+LuLM0mROQ/uyJ4+xmgwj+Ztn/B+F2sP75SlpVUtfY/Z2HNyfbZEkDoMH/wSqP0P/TDGHA1jfk/QIc5v2KOxD9TOgh+YQ3iP/j8MMVxB/c/GOyGYQoY2j8QkgUiDFbVP6Xap5FTftc/U+2T52O8vD9vRzgNhGq6P4umMyKqGfA/X7AbMi83pz8YTMOkSsurP/Z/7gZzP/0/WYtPeVGxwT9au0XMjdY0QOEtkDAcs5Q/WVEDDJ7s4D+sOYCXiSDkP+LRxlGoOJg/WMAEGtjT2D9j83Hc8A+aPzLmrtk06aI/qTXNq57kjz8qqRNgO+abPycUIoN4m80/NFUwhoo6yj8/6BmhnIPdP5M16oGIhZA/2CWqj4xPlD8ep8Jk8gAfQOz/HGYwbIw/Q8U4/3FVkj/5uDaUmreNP2h5HmjB0KM/3L+y0rMFkD/uycM+cnr1PyDvVQFJT8E/twY2iWIeqT+ppM69S6WqPwvvckFYkoo/vB3hdNNVsz8=",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "red",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "y = x",
         "type": "scatter",
         "x": [
          0,
          1400
         ],
         "y": [
          0,
          1400
         ]
        }
       ],
       "layout": {
        "height": 600,
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Predicciones vs TN"
        },
        "width": 600,
        "xaxis": {
         "range": [
          0,
          50
         ],
         "scaleanchor": "y",
         "scaleratio": 1,
         "title": {
          "text": "TN Real"
         }
        },
        "yaxis": {
         "range": [
          0,
          50
         ],
         "scaleanchor": "x",
         "scaleratio": 1,
         "title": {
          "text": "TN Predicho"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Crear el gráfico de dispersión\n",
    "fig = go.Figure()\n",
    "\n",
    "# Añadir los puntos de dispersión con el product_id en el hover\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_final[\"tn\"],\n",
    "    y=df_final[\"tn_t2_pred\"],\n",
    "    mode='markers',\n",
    "    name='Datos',\n",
    "    customdata=df_final[\"product_id\"],  # Pasamos el product_id como dato adicional\n",
    "    hovertemplate=(\n",
    "        \"<b>TN Real</b>: %{x}<br>\"\n",
    "        \"<b>TN Predicho</b>: %{y}<br>\"\n",
    "        \"<b>Product ID</b>: %{customdata}<br>\"\n",
    "        \"<extra></extra>\"  # Elimina información adicional automática\n",
    "    ),\n",
    "    marker=dict(size=8, opacity=0.7)  # Opcional: ajustar tamaño y transparencia\n",
    "))\n",
    "\n",
    "# Añadir la línea de referencia y=x\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1400],\n",
    "    y=[0, 1400],\n",
    "    mode='lines',\n",
    "    name='y = x',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "# Configurar el diseño del gráfico para que sea cuadrado\n",
    "fig.update_layout(\n",
    "    title='Predicciones vs TN',\n",
    "    xaxis_title='TN Real',\n",
    "    yaxis_title='TN Predicho',\n",
    "    showlegend=True,\n",
    "    # Forzar misma escala en ejes X e Y\n",
    "    xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    # Tamaño cuadrado (opcional)\n",
    "    width=600,\n",
    "    height=600,\n",
    "    # Rango fijo para ambos ejes (opcional)\n",
    "    xaxis_range=[0, 50],\n",
    "    yaxis_range=[0, 50]\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "84871a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32015.00363455506 | 25987.52668\n"
     ]
    }
   ],
   "source": [
    "print(df_final[\"tn_t2_pred\"].sum(),\"|\",df_final[\"tn\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4750dc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tn_t2_pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "error_relativo",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9464ed77-a1aa-47aa-b31f-eea149f9e1bc",
       "rows": [
        [
         "7",
         "20008",
         "195.36854",
         "476.1253151531958",
         "280.7567751531958",
         "1.4370623599541452"
        ],
        [
         "11",
         "20012",
         "173.13004",
         "416.9636488858013",
         "243.8336088858013",
         "1.4083841769215861"
        ],
        [
         "17",
         "20018",
         "141.63569999999999",
         "331.11157250545705",
         "189.47587250545706",
         "1.3377691676989423"
        ],
        [
         "0",
         "20001",
         "1504.68856",
         "1322.72769899932",
         "181.9608610006801",
         "0.12092925130013622"
        ],
        [
         "5",
         "20006",
         "417.23228",
         "561.6992073946953",
         "144.46692739469535",
         "0.3462506002524429"
        ],
        [
         "27",
         "20028",
         "109.92618",
         "247.65909225777136",
         "137.73291225777137",
         "1.2529582330412226"
        ],
        [
         "13",
         "20014",
         "272.02812",
         "408.5125768411975",
         "136.48445684119747",
         "0.5017292213804863"
        ],
        [
         "12",
         "20013",
         "318.09141",
         "453.88766247822116",
         "135.79625247822116",
         "0.4269095241466004"
        ],
        [
         "44",
         "20048",
         "58.89241",
         "175.99678967684062",
         "117.10437967684062",
         "1.9884460438423326"
        ],
        [
         "40",
         "20044",
         "59.617470000000004",
         "169.48463453085765",
         "109.86716453085765",
         "1.8428686177199005"
        ],
        [
         "2",
         "20003",
         "892.5012899999999",
         "785.4134309017161",
         "107.08785909828384",
         "0.11998622332331178"
        ],
        [
         "8",
         "20009",
         "495.03574",
         "390.8717802966382",
         "104.1639597033618",
         "0.21041704928892974"
        ],
        [
         "74",
         "20080",
         "8.84426",
         "107.64817845506187",
         "98.80391845506186",
         "11.171530286882323"
        ],
        [
         "16",
         "20017",
         "216.90773",
         "314.24810396956923",
         "97.34037396956924",
         "0.4487639696822665"
        ],
        [
         "66",
         "20072",
         "32.2686",
         "128.10855657172544",
         "95.83995657172545",
         "2.9700686293091567"
        ],
        [
         "15",
         "20016",
         "273.20202",
         "369.0179963384708",
         "95.81597633847082",
         "0.35071474339198083"
        ],
        [
         "43",
         "20047",
         "71.49763",
         "163.86813418194754",
         "92.37050418194754",
         "1.2919379870626135"
        ],
        [
         "39",
         "20043",
         "93.77222",
         "184.22346004410713",
         "90.45124004410712",
         "0.9645846077239839"
        ],
        [
         "32",
         "20033",
         "96.76212",
         "184.2851648648241",
         "87.52304486482412",
         "0.9045176445578509"
        ],
        [
         "92",
         "20100",
         "1.3792",
         "88.89317105712712",
         "87.51397105712712",
         "63.45270523283579"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_t2_pred</th>\n",
       "      <th>error</th>\n",
       "      <th>error_relativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20008</td>\n",
       "      <td>195.36854</td>\n",
       "      <td>476.125315</td>\n",
       "      <td>280.756775</td>\n",
       "      <td>1.437062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20012</td>\n",
       "      <td>173.13004</td>\n",
       "      <td>416.963649</td>\n",
       "      <td>243.833609</td>\n",
       "      <td>1.408384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20018</td>\n",
       "      <td>141.63570</td>\n",
       "      <td>331.111573</td>\n",
       "      <td>189.475873</td>\n",
       "      <td>1.337769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1504.68856</td>\n",
       "      <td>1322.727699</td>\n",
       "      <td>181.960861</td>\n",
       "      <td>0.120929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20006</td>\n",
       "      <td>417.23228</td>\n",
       "      <td>561.699207</td>\n",
       "      <td>144.466927</td>\n",
       "      <td>0.346251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20028</td>\n",
       "      <td>109.92618</td>\n",
       "      <td>247.659092</td>\n",
       "      <td>137.732912</td>\n",
       "      <td>1.252958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20014</td>\n",
       "      <td>272.02812</td>\n",
       "      <td>408.512577</td>\n",
       "      <td>136.484457</td>\n",
       "      <td>0.501729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20013</td>\n",
       "      <td>318.09141</td>\n",
       "      <td>453.887662</td>\n",
       "      <td>135.796252</td>\n",
       "      <td>0.426910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20048</td>\n",
       "      <td>58.89241</td>\n",
       "      <td>175.996790</td>\n",
       "      <td>117.104380</td>\n",
       "      <td>1.988446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20044</td>\n",
       "      <td>59.61747</td>\n",
       "      <td>169.484635</td>\n",
       "      <td>109.867165</td>\n",
       "      <td>1.842869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>892.50129</td>\n",
       "      <td>785.413431</td>\n",
       "      <td>107.087859</td>\n",
       "      <td>0.119986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20009</td>\n",
       "      <td>495.03574</td>\n",
       "      <td>390.871780</td>\n",
       "      <td>104.163960</td>\n",
       "      <td>0.210417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>20080</td>\n",
       "      <td>8.84426</td>\n",
       "      <td>107.648178</td>\n",
       "      <td>98.803918</td>\n",
       "      <td>11.171530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20017</td>\n",
       "      <td>216.90773</td>\n",
       "      <td>314.248104</td>\n",
       "      <td>97.340374</td>\n",
       "      <td>0.448764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>20072</td>\n",
       "      <td>32.26860</td>\n",
       "      <td>128.108557</td>\n",
       "      <td>95.839957</td>\n",
       "      <td>2.970069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20016</td>\n",
       "      <td>273.20202</td>\n",
       "      <td>369.017996</td>\n",
       "      <td>95.815976</td>\n",
       "      <td>0.350715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20047</td>\n",
       "      <td>71.49763</td>\n",
       "      <td>163.868134</td>\n",
       "      <td>92.370504</td>\n",
       "      <td>1.291938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20043</td>\n",
       "      <td>93.77222</td>\n",
       "      <td>184.223460</td>\n",
       "      <td>90.451240</td>\n",
       "      <td>0.964585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20033</td>\n",
       "      <td>96.76212</td>\n",
       "      <td>184.285165</td>\n",
       "      <td>87.523045</td>\n",
       "      <td>0.904518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>20100</td>\n",
       "      <td>1.37920</td>\n",
       "      <td>88.893171</td>\n",
       "      <td>87.513971</td>\n",
       "      <td>63.452705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id          tn   tn_t2_pred       error  error_relativo\n",
       "7        20008   195.36854   476.125315  280.756775        1.437062\n",
       "11       20012   173.13004   416.963649  243.833609        1.408384\n",
       "17       20018   141.63570   331.111573  189.475873        1.337769\n",
       "0        20001  1504.68856  1322.727699  181.960861        0.120929\n",
       "5        20006   417.23228   561.699207  144.466927        0.346251\n",
       "27       20028   109.92618   247.659092  137.732912        1.252958\n",
       "13       20014   272.02812   408.512577  136.484457        0.501729\n",
       "12       20013   318.09141   453.887662  135.796252        0.426910\n",
       "44       20048    58.89241   175.996790  117.104380        1.988446\n",
       "40       20044    59.61747   169.484635  109.867165        1.842869\n",
       "2        20003   892.50129   785.413431  107.087859        0.119986\n",
       "8        20009   495.03574   390.871780  104.163960        0.210417\n",
       "74       20080     8.84426   107.648178   98.803918       11.171530\n",
       "16       20017   216.90773   314.248104   97.340374        0.448764\n",
       "66       20072    32.26860   128.108557   95.839957        2.970069\n",
       "15       20016   273.20202   369.017996   95.815976        0.350715\n",
       "43       20047    71.49763   163.868134   92.370504        1.291938\n",
       "39       20043    93.77222   184.223460   90.451240        0.964585\n",
       "32       20033    96.76212   184.285165   87.523045        0.904518\n",
       "92       20100     1.37920    88.893171   87.513971       63.452705"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[\"error\"] = (df_final[\"tn\"] - df_final[\"tn_t2_pred\"]).abs()\n",
    "df_final[\"error_relativo\"] = df_final[\"error\"] / df_final[\"tn\"]\n",
    "df_final.sort_values(by=\"error\", ascending=False, inplace=True)\n",
    "df_final[[\"product_id\" ,\"tn\", \"tn_t2_pred\", \"error\", \"error_relativo\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f3a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellin = pd.read_csv(\"../datasets/sell-in.txt.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "44148a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_11172\\804960764.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prod = 20008\n",
    "prod_s = sellin[sellin[\"product_id\"] == prod]\n",
    "prod_s[\"periodo\"] = pd.to_datetime(prod_s[\"periodo\"], format='%Y%m')\n",
    "prod_s = prod_s.groupby(\"periodo\").agg({\"tn\": \"sum\"}).reset_index()\n",
    "#prod_s.plot(kind=\"line\", x=\"periodo\", y=\"tn\", title=\"TN por periodo para producto 20002\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.gca()\n",
    "prod_s.plot(kind=\"line\", x=\"periodo\", y=\"tn\", title=f\"TN por periodo para producto {prod}\", ax=ax)\n",
    "#plt.axhline(y=813.82, color='red', linestyle='--', label='predict')\n",
    "prediccion = df_final[df_final[\"product_id\"] == prod][\"tn_t2_pred\"].values[0]\n",
    "plt.scatter(prod_s[\"periodo\"].iloc[-1], prediccion, color='red', label='prediccion')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99387317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Procesando datos...\n",
      "Filtrando productos...\n",
      "Preparando datos de entrenamiento...\n",
      "Preparando datos para predicción...\n",
      "Entrenando modelos...\n",
      "\n",
      "Entrenando modelo con semilla 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\.conda\\envs\\py311lab3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - loss: 0.6083 - mae: 0.5790 - val_loss: 0.6874 - val_mae: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.5812 - mae: 0.5653 - val_loss: 0.6742 - val_mae: 0.5577 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5725 - mae: 0.5614 - val_loss: 0.6697 - val_mae: 0.5565 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5674 - mae: 0.5593 - val_loss: 0.6673 - val_mae: 0.5557 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5645 - mae: 0.5580 - val_loss: 0.6688 - val_mae: 0.5560 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5623 - mae: 0.5571 - val_loss: 0.6701 - val_mae: 0.5563 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5598 - mae: 0.5561 - val_loss: 0.6714 - val_mae: 0.5558 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5588 - mae: 0.5553 - val_loss: 0.6723 - val_mae: 0.5567 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5570 - mae: 0.5547 - val_loss: 0.6730 - val_mae: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5548 - mae: 0.5535 - val_loss: 0.6734 - val_mae: 0.5569 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5539 - mae: 0.5528 - val_loss: 0.6741 - val_mae: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5522 - mae: 0.5520 - val_loss: 0.6732 - val_mae: 0.5570 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5523 - mae: 0.5523 - val_loss: 0.6751 - val_mae: 0.5587 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5509 - mae: 0.5513 - val_loss: 0.6735 - val_mae: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5509 - mae: 0.5517 - val_loss: 0.6741 - val_mae: 0.5582 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.5500 - mae: 0.5514 - val_loss: 0.6748 - val_mae: 0.5578 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5488 - mae: 0.5501 - val_loss: 0.6755 - val_mae: 0.5587 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5484 - mae: 0.5504 - val_loss: 0.6771 - val_mae: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5479 - mae: 0.5501 - val_loss: 0.6763 - val_mae: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5456 - mae: 0.5496 - val_loss: 0.6758 - val_mae: 0.5547 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5447 - mae: 0.5477 - val_loss: 0.6762 - val_mae: 0.5545 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5435 - mae: 0.5475 - val_loss: 0.6764 - val_mae: 0.5546 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5436 - mae: 0.5479 - val_loss: 0.6766 - val_mae: 0.5548 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5432 - mae: 0.5473 - val_loss: 0.6764 - val_mae: 0.5546 - learning_rate: 1.0000e-04\n",
      "\n",
      "Entrenando modelo con semilla 101\n",
      "Epoch 1/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 0.6110 - mae: 0.5777 - val_loss: 0.6881 - val_mae: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5854 - mae: 0.5682 - val_loss: 0.6821 - val_mae: 0.5605 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5768 - mae: 0.5652 - val_loss: 0.6790 - val_mae: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5715 - mae: 0.5629 - val_loss: 0.6773 - val_mae: 0.5610 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5692 - mae: 0.5620 - val_loss: 0.6771 - val_mae: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5659 - mae: 0.5606 - val_loss: 0.6775 - val_mae: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5630 - mae: 0.5593 - val_loss: 0.6785 - val_mae: 0.5638 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5624 - mae: 0.5593 - val_loss: 0.6781 - val_mae: 0.5631 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5608 - mae: 0.5585 - val_loss: 0.6793 - val_mae: 0.5641 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5591 - mae: 0.5579 - val_loss: 0.6796 - val_mae: 0.5636 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5588 - mae: 0.5576 - val_loss: 0.6798 - val_mae: 0.5637 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5578 - mae: 0.5568 - val_loss: 0.6799 - val_mae: 0.5641 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5556 - mae: 0.5560 - val_loss: 0.6806 - val_mae: 0.5640 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.5557 - mae: 0.5560 - val_loss: 0.6816 - val_mae: 0.5654 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.5556 - mae: 0.5561 - val_loss: 0.6818 - val_mae: 0.5650 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5541 - mae: 0.5553 - val_loss: 0.6806 - val_mae: 0.5644 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5527 - mae: 0.5545 - val_loss: 0.6813 - val_mae: 0.5645 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5528 - mae: 0.5540 - val_loss: 0.6822 - val_mae: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5519 - mae: 0.5543 - val_loss: 0.6831 - val_mae: 0.5648 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5520 - mae: 0.5541 - val_loss: 0.6827 - val_mae: 0.5648 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5489 - mae: 0.5544 - val_loss: 0.6799 - val_mae: 0.5589 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5464 - mae: 0.5507 - val_loss: 0.6800 - val_mae: 0.5583 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5455 - mae: 0.5506 - val_loss: 0.6802 - val_mae: 0.5584 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5456 - mae: 0.5506 - val_loss: 0.6803 - val_mae: 0.5584 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5460 - mae: 0.5506 - val_loss: 0.6802 - val_mae: 0.5584 - learning_rate: 1.0000e-04\n",
      "\n",
      "Entrenando modelo con semilla 202\n",
      "Epoch 1/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 0.6244 - mae: 0.5808 - val_loss: 0.6956 - val_mae: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.6024 - mae: 0.5721 - val_loss: 0.6852 - val_mae: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5916 - mae: 0.5670 - val_loss: 0.6789 - val_mae: 0.5597 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5870 - mae: 0.5646 - val_loss: 0.6776 - val_mae: 0.5594 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5832 - mae: 0.5631 - val_loss: 0.6791 - val_mae: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5824 - mae: 0.5627 - val_loss: 0.6764 - val_mae: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.5794 - mae: 0.5612 - val_loss: 0.6777 - val_mae: 0.5596 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5787 - mae: 0.5607 - val_loss: 0.6776 - val_mae: 0.5600 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5776 - mae: 0.5602 - val_loss: 0.6775 - val_mae: 0.5598 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.5755 - mae: 0.5588 - val_loss: 0.6768 - val_mae: 0.5592 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5745 - mae: 0.5584 - val_loss: 0.6808 - val_mae: 0.5613 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5746 - mae: 0.5586 - val_loss: 0.6801 - val_mae: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5736 - mae: 0.5577 - val_loss: 0.6819 - val_mae: 0.5612 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.5728 - mae: 0.5575 - val_loss: 0.6834 - val_mae: 0.5617 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5725 - mae: 0.5575 - val_loss: 0.6855 - val_mae: 0.5634 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.5714 - mae: 0.5572 - val_loss: 0.6849 - val_mae: 0.5621 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5705 - mae: 0.5563 - val_loss: 0.6854 - val_mae: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5702 - mae: 0.5564 - val_loss: 0.6875 - val_mae: 0.5634 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5704 - mae: 0.5561 - val_loss: 0.6886 - val_mae: 0.5638 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5699 - mae: 0.5561 - val_loss: 0.6900 - val_mae: 0.5642 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.5685 - mae: 0.5557 - val_loss: 0.6908 - val_mae: 0.5643 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.5726 - mae: 0.5595 - val_loss: 0.6822 - val_mae: 0.5572 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5644 - mae: 0.5536 - val_loss: 0.6816 - val_mae: 0.5566 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5633 - mae: 0.5529 - val_loss: 0.6816 - val_mae: 0.5565 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5632 - mae: 0.5528 - val_loss: 0.6816 - val_mae: 0.5564 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.5632 - mae: 0.5523 - val_loss: 0.6817 - val_mae: 0.5563 - learning_rate: 1.0000e-04\n",
      "\n",
      "Entrenando modelo con semilla 303\n",
      "Epoch 1/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - loss: 0.5918 - mae: 0.5677 - val_loss: 0.6953 - val_mae: 0.5619 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.5712 - mae: 0.5602 - val_loss: 0.6866 - val_mae: 0.5613 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5610 - mae: 0.5558 - val_loss: 0.6801 - val_mae: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5559 - mae: 0.5535 - val_loss: 0.6777 - val_mae: 0.5610 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.5537 - mae: 0.5529 - val_loss: 0.6745 - val_mae: 0.5602 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5508 - mae: 0.5514 - val_loss: 0.6744 - val_mae: 0.5602 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5491 - mae: 0.5503 - val_loss: 0.6731 - val_mae: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.5480 - mae: 0.5498 - val_loss: 0.6746 - val_mae: 0.5602 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5465 - mae: 0.5490 - val_loss: 0.6765 - val_mae: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.5465 - mae: 0.5493 - val_loss: 0.6773 - val_mae: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5453 - mae: 0.5485 - val_loss: 0.6773 - val_mae: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5446 - mae: 0.5484 - val_loss: 0.6789 - val_mae: 0.5619 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5439 - mae: 0.5481 - val_loss: 0.6779 - val_mae: 0.5616 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5427 - mae: 0.5477 - val_loss: 0.6799 - val_mae: 0.5619 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.5427 - mae: 0.5477 - val_loss: 0.6805 - val_mae: 0.5617 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5419 - mae: 0.5477 - val_loss: 0.6810 - val_mae: 0.5618 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5409 - mae: 0.5467 - val_loss: 0.6827 - val_mae: 0.5616 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5406 - mae: 0.5463 - val_loss: 0.6836 - val_mae: 0.5616 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5397 - mae: 0.5459 - val_loss: 0.6819 - val_mae: 0.5613 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5397 - mae: 0.5464 - val_loss: 0.6854 - val_mae: 0.5622 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5399 - mae: 0.5458 - val_loss: 0.6849 - val_mae: 0.5609 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.5385 - mae: 0.5456 - val_loss: 0.6865 - val_mae: 0.5616 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5371 - mae: 0.5461 - val_loss: 0.6808 - val_mae: 0.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.5346 - mae: 0.5438 - val_loss: 0.6808 - val_mae: 0.5581 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.5343 - mae: 0.5436 - val_loss: 0.6810 - val_mae: 0.5581 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.5343 - mae: 0.5435 - val_loss: 0.6813 - val_mae: 0.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.5338 - mae: 0.5430 - val_loss: 0.6813 - val_mae: 0.5582 - learning_rate: 1.0000e-04\n",
      "\n",
      "Entrenando modelo con semilla 404\n",
      "Epoch 1/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - loss: 0.6269 - mae: 0.5834 - val_loss: 0.6996 - val_mae: 0.5617 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.6045 - mae: 0.5744 - val_loss: 0.6871 - val_mae: 0.5577 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5947 - mae: 0.5705 - val_loss: 0.6780 - val_mae: 0.5542 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.5897 - mae: 0.5685 - val_loss: 0.6734 - val_mae: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5855 - mae: 0.5671 - val_loss: 0.6709 - val_mae: 0.5519 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5833 - mae: 0.5660 - val_loss: 0.6699 - val_mae: 0.5515 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5821 - mae: 0.5654 - val_loss: 0.6689 - val_mae: 0.5514 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5807 - mae: 0.5646 - val_loss: 0.6681 - val_mae: 0.5514 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.5782 - mae: 0.5637 - val_loss: 0.6687 - val_mae: 0.5509 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5770 - mae: 0.5631 - val_loss: 0.6697 - val_mae: 0.5516 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5769 - mae: 0.5633 - val_loss: 0.6699 - val_mae: 0.5511 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.5759 - mae: 0.5623 - val_loss: 0.6701 - val_mae: 0.5520 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5749 - mae: 0.5622 - val_loss: 0.6699 - val_mae: 0.5517 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.5738 - mae: 0.5618 - val_loss: 0.6709 - val_mae: 0.5515 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5729 - mae: 0.5613 - val_loss: 0.6716 - val_mae: 0.5520 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5717 - mae: 0.5605 - val_loss: 0.6733 - val_mae: 0.5523 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.5720 - mae: 0.5608 - val_loss: 0.6725 - val_mae: 0.5520 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.5711 - mae: 0.5605 - val_loss: 0.6743 - val_mae: 0.5525 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5708 - mae: 0.5604 - val_loss: 0.6748 - val_mae: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.5686 - mae: 0.5598 - val_loss: 0.6761 - val_mae: 0.5538 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.5700 - mae: 0.5601 - val_loss: 0.6758 - val_mae: 0.5536 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5692 - mae: 0.5593 - val_loss: 0.6760 - val_mae: 0.5525 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.5689 - mae: 0.5594 - val_loss: 0.6759 - val_mae: 0.5540 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.5659 - mae: 0.5576 - val_loss: 0.6749 - val_mae: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.5637 - mae: 0.5557 - val_loss: 0.6747 - val_mae: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.5630 - mae: 0.5553 - val_loss: 0.6749 - val_mae: 0.5520 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.5637 - mae: 0.5557 - val_loss: 0.6748 - val_mae: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.5639 - mae: 0.5555 - val_loss: 0.6750 - val_mae: 0.5520 - learning_rate: 1.0000e-04\n",
      "\n",
      "Realizando predicciones...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001955282D120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Resultados:\n",
      "MAE: 128.02\n",
      "MAPE: 8.51%\n",
      "\n",
      "Ejemplo de predicciones:\n",
      "   product_id periodo_real  prediccion_t+2          tn       error\n",
      "0       20001   2019-12-01     1376.673116  1504.68856  128.015444\n",
      "\n",
      "Proceso completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "# Configuración\n",
    "config = {\n",
    "    \"lstm_units_1\": 64,\n",
    "    \"lstm_units_2\": 32,\n",
    "    \"dense_units\": 16,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 150,\n",
    "    \"batch_size\": 250,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"learning_rate\": None,\n",
    "    \"l2_lambda\": 0.001,\n",
    "    \"optimizer\": \"rmsprop\",\n",
    "    \"scaler_name\": \"robust\",\n",
    "    \"window_size\": 3,\n",
    "    \"feature_cols\": ['tn', 'tn_lag1', 'tn_diff1', 'rolling_mean3', \n",
    "                   'rolling_std3', 'rolling_max3', 'rolling_min3',\n",
    "                   'rolling_max6', 'rolling_min6', \"size\"],\n",
    "}\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos...\")\n",
    "df = pd.read_csv(\"../entregable/datasets/periodo_x_producto_con_target_transformado_con_feature_engineering_201912.csv\", \n",
    "                 sep=',', encoding='utf-8')\n",
    "df[\"periodo\"] = pd.to_datetime(df[\"periodo\"], format=\"%Y%m\")\n",
    "\n",
    "# Agregación mensual por producto\n",
    "print(\"Procesando datos...\")\n",
    "df = df.groupby([\"product_id\", \"periodo\"]).agg({\"tn\": \"sum\"}).sort_values([\"product_id\", \"periodo\"]).reset_index()\n",
    "\n",
    "# Función para crear features\n",
    "def agregar_features(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([\"product_id\", \"periodo\"])\n",
    "    \n",
    "    df[\"tn_lag1\"] = df.groupby(\"product_id\")[\"tn\"].shift(1)\n",
    "    df[\"tn_diff1\"] = df[\"tn\"] - df[\"tn_lag1\"]\n",
    "    df[\"size\"] = df.groupby(\"product_id\")[\"tn\"].transform(\"size\")\n",
    "    \n",
    "    df[\"rolling_mean3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).mean())\n",
    "    df[\"rolling_std3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).std())\n",
    "    df[\"rolling_max3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).max())\n",
    "    df[\"rolling_min3\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(3).min())\n",
    "    df[\"rolling_max6\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(6).max())\n",
    "    df[\"rolling_min6\"] = df.groupby(\"product_id\")[\"tn\"].transform(lambda x: x.shift(1).rolling(6).min())\n",
    "\n",
    "    return df\n",
    "\n",
    "df_features = agregar_features(df).fillna(0)\n",
    "\n",
    "# Filtrar productos con suficiente historial\n",
    "print(\"Filtrando productos...\")\n",
    "ultimo_mes = pd.to_datetime(\"201910\", format=\"%Y%m\")  # Octubre 2019\n",
    "ultimos_3_meses = pd.date_range(end=ultimo_mes - pd.DateOffset(months=1), periods=3, freq='MS')\n",
    "df_filtrado = df_features[df_features[\"periodo\"].isin(ultimos_3_meses)]\n",
    "conteo_por_producto = df_filtrado[df_filtrado[\"tn\"] > 0].groupby(\"product_id\").size()\n",
    "productos_validos = conteo_por_producto[conteo_por_producto >= 3].index\n",
    "df_features = df_features[df_features[\"product_id\"].isin(productos_validos)].copy()\n",
    "\n",
    "# Definir períodos\n",
    "fecha_inicio_train = pd.to_datetime(\"201901\", format=\"%Y%m\")\n",
    "fecha_fin_train = pd.to_datetime(\"201910\", format=\"%Y%m\")\n",
    "fecha_prediccion = pd.to_datetime(\"201912\", format=\"%Y%m\")\n",
    "\n",
    "# Preparar datos de entrenamiento\n",
    "print(\"Preparando datos de entrenamiento...\")\n",
    "window_size = config[\"window_size\"]\n",
    "scaler_name = config[\"scaler_name\"]\n",
    "feature_cols = config[\"feature_cols\"]\n",
    "scalers = {}\n",
    "\n",
    "X_train, y_train = [], []\n",
    "periodos_train = []\n",
    "\n",
    "for producto in productos_validos:\n",
    "    df_prod = df_features[(df_features[\"product_id\"] == producto) & \n",
    "                         (df_features[\"periodo\"] <= fecha_fin_train)].copy()\n",
    "    \n",
    "    if len(df_prod) < window_size + 2:\n",
    "        continue\n",
    "        \n",
    "    scaler = StandardScaler() if scaler_name == \"standard\" else RobustScaler()\n",
    "    scaled_features = scaler.fit_transform(df_prod[feature_cols])\n",
    "    scalers[producto] = scaler\n",
    "    \n",
    "    for i in range(window_size, len(df_prod) - 2):\n",
    "        periodo_target = df_prod.iloc[i + 2][\"periodo\"]\n",
    "        if periodo_target <= fecha_fin_train:\n",
    "            X_train.append(scaled_features[i - window_size:i])\n",
    "            y_train.append(scaled_features[i + 2][0])\n",
    "            periodos_train.append(periodo_target)\n",
    "\n",
    "if len(X_train) == 0:\n",
    "    raise ValueError(\"No hay suficientes datos para entrenamiento. Revisa los filtros.\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "# Preparar datos para predicción\n",
    "print(\"Preparando datos para predicción...\")\n",
    "X_predict = []\n",
    "productos_predict = []\n",
    "\n",
    "for producto in productos_validos:\n",
    "    df_prod = df_features[df_features[\"product_id\"] == producto].copy()\n",
    "    \n",
    "    # Encontrar índice de octubre 2019\n",
    "    idx_octubre = df_prod[df_prod[\"periodo\"] == fecha_fin_train].index\n",
    "    if len(idx_octubre) == 0:\n",
    "        continue\n",
    "    \n",
    "    idx_octubre = idx_octubre[0]\n",
    "    \n",
    "    # Verificar que tenga suficiente historia antes de octubre\n",
    "    if idx_octubre < window_size - 1:\n",
    "        continue\n",
    "    \n",
    "    # Obtener ventana temporal (agosto, septiembre, octubre 2019)\n",
    "    ventana = df_prod.iloc[idx_octubre - window_size + 1:idx_octubre + 1]\n",
    "    if len(ventana) != window_size:\n",
    "        continue\n",
    "    \n",
    "    # Escalar datos\n",
    "    scaler = scalers.get(producto)\n",
    "    if scaler is None:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        ultimos = ventana[feature_cols]\n",
    "        ultimos_scaled = scaler.transform(ultimos)\n",
    "        X_predict.append(ultimos_scaled)\n",
    "        productos_predict.append(producto)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando producto {producto}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if len(X_predict) == 0:\n",
    "    raise ValueError(\"No hay productos válidos para predicción.\")\n",
    "    \n",
    "X_predict = np.array(X_predict)\n",
    "\n",
    "# Crear modelo\n",
    "def crear_modelo(semilla, window_size, n_features):\n",
    "    tf.keras.utils.set_random_seed(semilla)\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(200, activation='tanh', return_sequences=True, \n",
    "             input_shape=(window_size, n_features),\n",
    "             kernel_regularizer=l2(config[\"l2_lambda\"]) if config[\"l2_lambda\"] > 0 else None),\n",
    "        Dropout(0.2, seed=semilla),\n",
    "        LSTM(32, activation='tanh'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    if config[\"optimizer\"].lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "    elif config[\"optimizer\"].lower() == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=0.001)\n",
    "    else:\n",
    "        optimizer = config[\"optimizer\"]\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Entrenando modelos...\")\n",
    "semillas = [42, 101, 202, 303, 404]\n",
    "modelos = []\n",
    "\n",
    "for semilla in semillas:\n",
    "    print(f\"\\nEntrenando modelo con semilla {semilla}\")\n",
    "    model = crear_modelo(semilla, X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=config[\"epochs\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=config[\"early_stopping_patience\"], restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.1, patience=15)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    modelos.append(model)\n",
    "\n",
    "# Predicción\n",
    "print(\"\\nRealizando predicciones...\")\n",
    "predicciones = []\n",
    "\n",
    "for i, producto in enumerate(productos_predict):\n",
    "    scaler = scalers[producto]\n",
    "    preds_producto = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        y_pred_scaled = modelo.predict(X_predict[i:i+1], verbose=0)\n",
    "        tn_mean = scaler.center_[0]\n",
    "        tn_std = scaler.scale_[0]\n",
    "        y_pred = y_pred_scaled[0][0] * tn_std + tn_mean\n",
    "        preds_producto.append(max(0, y_pred))  # Asegurar valor positivo\n",
    "    \n",
    "    # Promedio de las predicciones de todos los modelos\n",
    "    prediccion_final = np.mean(preds_producto)\n",
    "    \n",
    "    predicciones.append({\n",
    "        \"product_id\": producto,\n",
    "        \"periodo_real\": fecha_prediccion,\n",
    "        \"prediccion_t+2\": prediccion_final\n",
    "    })\n",
    "\n",
    "df_predicciones = pd.DataFrame(predicciones)\n",
    "\n",
    "# Obtener valores reales para comparación\n",
    "df_real = df_features[df_features[\"periodo\"] == fecha_prediccion][[\"product_id\", \"tn\"]]\n",
    "df_resultados = df_predicciones.merge(df_real, on=\"product_id\", how=\"left\")\n",
    "\n",
    "# Calcular métricas\n",
    "if not df_resultados.empty:\n",
    "    df_resultados[\"error\"] = abs(df_resultados[\"tn\"] - df_resultados[\"prediccion_t+2\"])\n",
    "    mae = df_resultados[\"error\"].mean()\n",
    "    mape = (df_resultados[\"error\"] / df_resultados[\"tn\"]).mean() * 100\n",
    "    \n",
    "    print(\"\\nResultados:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(\"\\nEjemplo de predicciones:\")\n",
    "    print(df_resultados.head())\n",
    "else:\n",
    "    print(\"\\nNo hay datos reales para comparación en el período predicho.\")\n",
    "\n",
    "print(\"\\nProceso completado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9dd7028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "periodo_real",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "prediccion_t+2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "error",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a44540ba-06c2-4254-a471-bd74bc88fedc",
       "rows": [
        [
         "0",
         "20001",
         "2019-12-01 00:00:00",
         "1376.6731162323638",
         "1504.68856",
         "128.01544376763627"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo_real</th>\n",
       "      <th>prediccion_t+2</th>\n",
       "      <th>tn</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>1376.673116</td>\n",
       "      <td>1504.68856</td>\n",
       "      <td>128.015444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id periodo_real  prediccion_t+2          tn       error\n",
       "0       20001   2019-12-01     1376.673116  1504.68856  128.015444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
