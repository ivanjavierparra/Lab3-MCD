{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbae8eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import gc\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.common import space\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from typing import List, Dict\n",
    "sys.path.append('./scripts')  \n",
    "import preprocesamiento\n",
    "import feature_engineering\n",
    "import model_autogluon\n",
    "importlib.reload(preprocesamiento)\n",
    "importlib.reload(model_autogluon)\n",
    "importlib.reload(feature_engineering)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14763c97",
   "metadata": {},
   "source": [
    "# Experimento 6: \n",
    "- Autogluon: Solo redes neuronales + optimizacion de hiperparametros\n",
    "    - DeepAR: Red recurrente especializada para series temporales\n",
    "    - TemporalFusionTransformer: Arquitectura transformer adaptada\n",
    "    - SimpleFeedForward: Red neuronal feedforward básica\n",
    "\n",
    "- Target: mes+2\n",
    "\n",
    "- Optimización Avanzada:\n",
    "    - Búsqueda bayesiana inteligente (bayesopt)\n",
    "    - 30 combinaciones diferentes de hiperparámetros\n",
    "    - Rangos lógicos para parámetros clave\n",
    "\n",
    "- Validación Robusta:\n",
    "    - 5 ventanas de validación cruzada\n",
    "    - Exclusión de modelos no neuronales\n",
    "\n",
    "- Control del Proceso:\n",
    "    - Logs detallados (verbosity=2)\n",
    "    - Límite de tiempo opcional (3600 segundos)\n",
    "\n",
    "- Kaggle =  0.277\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab761cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/periodo_x_producto_con_target.csv\", sep=',', encoding='utf-8')\n",
    "dfg = df.groupby(['periodo', 'product_id']).agg({'target': 'sum'}).reset_index()\n",
    "dfg['timestamp'] = pd.to_datetime(dfg['periodo'].astype(str), format='%Y%m')\n",
    "dfg.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "\n",
    "# Filtrar productos\n",
    "productos_ok = pd.read_csv('../../data/raw/product_id_apredecir201912.csv', sep=',')\n",
    "dfg = dfg[dfg['item_id'].isin(productos_ok['product_id'].unique())]\n",
    "\n",
    "# Convertir a TimeSeriesDataFrame\n",
    "data = TimeSeriesDataFrame.from_data_frame(\n",
    "    dfg,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405c77e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frequency 'M' stored as 'ME'\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'c:\\Users\\Usuario\\Documents\\Universidad\\austral\\2025\\Lab3\\Lab3-MCD\\notebooks\\entregable\\AutogluonModels\\ag-20250629_134010'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          4\n",
      "GPU Count:          0\n",
      "Memory Avail:       2.46 GB / 15.89 GB (15.5%)\n",
      "Disk Space Avail:   413.67 GB / 893.49 GB (46.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAPE,\n",
      " 'excluded_model_types': ['ARIMA', 'ETS', 'Theta'],\n",
      " 'freq': 'ME',\n",
      " 'hyperparameters': {'DeepAR': {},\n",
      "                     'SimpleFeedForward': {},\n",
      "                     'TemporalFusionTransformer': {}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 5,\n",
      " 'prediction_length': 1,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'MS' has been resampled to frequency 'ME'.\n",
      "Provided train_data has 22375 rows, 780 time series. Median time series length is 36 (min=4, max=36). \n",
      "\tRemoving 105 short time series from train_data. Only series with length >= 10 will be used for training.\n",
      "\tAfter filtering, train_data has 21646 rows, 675 time series. Median time series length is 36 (min=10, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['periodo']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-06-29 10:40:16\n",
      "Excluded model types: ['ARIMA', 'ETS', 'Theta']\n",
      "Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'SimpleFeedForward']\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\tnan           = Validation score (-MAPE)\n",
      "\t2552.70 s     = Training runtime\n",
      "\t1.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. \n",
      "\tnan           = Validation score (-MAPE)\n",
      "\t756.39  s     = Training runtime\n",
      "\t0.85    s     = Validation (prediction) runtime\n",
      "Training timeseries model SimpleFeedForward. \n",
      "\tnan           = Validation score (-MAPE)\n",
      "\t236.81  s     = Training runtime\n",
      "\t2.02    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tWarning: Exception caused ensemble to fail during training... Skipping this model.\n",
      "\t'a' cannot be empty unless no samples are taken\n",
      "Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'SimpleFeedForward']\n",
      "Total runtime: 3552.09 s\n",
      "Best model: TemporalFusionTransformer\n",
      "Best model score: nan\n",
      "data with frequency 'MS' has been resampled to frequency 'ME'.\n",
      "Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desempeño del modelo: {'MAPE': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'MS' has been resampled to frequency 'ME'.\n",
      "Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones generadas:\n",
      "                           mean         0.1         0.2          0.3  \\\n",
      "item_id timestamp                                                      \n",
      "20001   2020-01-31  1341.511475  823.683533  925.015564  1085.486206   \n",
      "20002   2020-01-31  1015.737305  534.233826  632.800842   789.344604   \n",
      "20003   2020-01-31   814.567871  409.315521  488.814697   613.297180   \n",
      "20004   2020-01-31   618.369019  299.359558  364.609222   461.017120   \n",
      "20005   2020-01-31   577.933289  270.242493  335.133575   425.597534   \n",
      "\n",
      "                            0.4          0.5          0.6          0.7  \\\n",
      "item_id timestamp                                                        \n",
      "20001   2020-01-31  1214.482422  1341.511475  1464.198853  1623.361328   \n",
      "20002   2020-01-31   906.329956  1015.737305  1130.787842  1293.329468   \n",
      "20003   2020-01-31   712.641174   814.567871   908.631897  1035.952637   \n",
      "20004   2020-01-31   538.686951   618.369019   691.794373   791.926880   \n",
      "20005   2020-01-31   499.880157   577.933289   648.736572   743.375427   \n",
      "\n",
      "                            0.8          0.9  \n",
      "item_id timestamp                             \n",
      "20001   2020-01-31  1817.171265  1987.480835  \n",
      "20002   2020-01-31  1469.710083  1626.574951  \n",
      "20003   2020-01-31  1188.012695  1324.846191  \n",
      "20004   2020-01-31   911.070190  1019.771729  \n",
      "20005   2020-01-31   858.381592   965.774536  \n"
     ]
    }
   ],
   "source": [
    "# 2. Configurar y entrenar el predictor solo con modelos neuronales\n",
    "predictor = TimeSeriesPredictor(\n",
    "    target='target',\n",
    "    prediction_length=1,  # Predecir un paso adelante (mes+2)\n",
    "    freq=\"M\",\n",
    "    eval_metric=\"MAPE\"\n",
    ").fit(\n",
    "    train_data=data,\n",
    "    # Especificamos solo modelos neuronales\n",
    "    hyperparameters={\n",
    "        'DeepAR': {},\n",
    "        'TemporalFusionTransformer': {},\n",
    "        'SimpleFeedForward': {}\n",
    "    },\n",
    "    # Excluimos modelos no neuronales\n",
    "    excluded_model_types=['ARIMA', 'ETS', 'Theta'],\n",
    "    num_val_windows=5,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# 3. Evaluar y hacer predicciones\n",
    "performance = predictor.evaluate(data)\n",
    "print(f\"\\nDesempeño del modelo: {performance}\")\n",
    "\n",
    "predictions = predictor.predict(data)\n",
    "print(\"\\nPredicciones generadas:\")\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda649ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_copy = predictions.copy()\n",
    "predictions_copy = predictions_copy.reset_index()\n",
    "predictions_copy.rename(columns={'mean': 'tn', 'item_id': 'product_id'}, inplace=True)\n",
    "predictions_copy = predictions_copy[['product_id','tn']]\n",
    "output_path = \"./outputs/predicciones_exp_06v4_autogluon_v1_original.csv\"\n",
    "predictions_copy.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fea53",
   "metadata": {},
   "source": [
    "##### Opcion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f692fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250629_184335\"\n",
      "Frequency 'M' stored as 'ME'\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'c:\\Users\\Usuario\\Documents\\Universidad\\austral\\2025\\Lab3\\Lab3-MCD\\notebooks\\entregable\\AutogluonModels\\ag-20250629_184335'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          4\n",
      "GPU Count:          0\n",
      "Memory Avail:       2.07 GB / 15.89 GB (13.0%)\n",
      "Disk Space Avail:   413.59 GB / 893.49 GB (46.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAPE,\n",
      " 'excluded_model_types': ['ARIMA', 'ETS', 'Theta'],\n",
      " 'freq': 'ME',\n",
      " 'hyperparameters': {'DeepAR': {},\n",
      "                     'SimpleFeedForward': {},\n",
      "                     'TemporalFusionTransformer': {}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 5,\n",
      " 'prediction_length': 1,\n",
      " 'quantile_levels': [0.1, 0.5, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'ME'.\n",
      "Provided train_data has 20815 rows, 780 time series. Median time series length is 34 (min=2, max=34). \n",
      "\tRemoving 124 short time series from train_data. Only series with length >= 10 will be used for training.\n",
      "\tAfter filtering, train_data has 20140 rows, 656 time series. Median time series length is 34 (min=12, max=34). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-06-29 15:43:38\n",
      "Excluded model types: ['ARIMA', 'ETS', 'Theta']\n",
      "Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'SimpleFeedForward']\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\t-0.6139       = Validation score (-MAPE)\n",
      "\t2299.46 s     = Training runtime\n",
      "\t1.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. \n",
      "\t-0.5685       = Validation score (-MAPE)\n",
      "\t1096.75 s     = Training runtime\n",
      "\t2.28    s     = Validation (prediction) runtime\n",
      "Training timeseries model SimpleFeedForward. \n",
      "\t-0.6427       = Validation score (-MAPE)\n",
      "\t234.45  s     = Training runtime\n",
      "\t0.52    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'DeepAR': 0.76, 'TemporalFusionTransformer': 0.24}\n",
      "\t-0.5636       = Validation score (-MAPE)\n",
      "\t1.10    s     = Training runtime\n",
      "\t3.30    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'SimpleFeedForward', 'WeightedEnsemble']\n",
      "Total runtime: 3636.42 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.5636\n",
      "data with frequency 'IRREG' has been resampled to frequency 'ME'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "data with frequency 'IRREG' has been resampled to frequency 'ME'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.common import space\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Carga y transforma los datos para predecir ventas en mes+2.\"\"\"\n",
    "    # Leer datos crudos\n",
    "    df = pd.read_csv(\"./datasets/periodo_x_producto_con_target.csv\", sep=',', encoding='utf-8')\n",
    "    df['cat1'].fillna(\"Ninguno\", inplace=True)\n",
    "    df['cat2'].fillna(\"Ninguno\", inplace=True)\n",
    "    df['cat3'].fillna(\"Ninguno\", inplace=True)\n",
    "    df['brand'].fillna(\"Ninguno\", inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Convertir periodo a datetime y renombrar columnas\n",
    "    df['timestamp'] = pd.to_datetime(df['periodo'].astype(str), format='%Y%m')\n",
    "    df.rename(columns={\n",
    "        'tn': 'current_sales',  # Covariable: Ventas actuales\n",
    "        'product_id': 'item_id'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Filtrar productos relevantes\n",
    "    productos_ok = pd.read_csv('../../data/raw/product_id_apredecir201912.csv', sep=',')\n",
    "    df = df[df['item_id'].isin(productos_ok['product_id'].unique())]\n",
    "    \n",
    "    # Eliminar filas donde target es NA (las últimas 2 de cada serie)\n",
    "    df = df.dropna(subset=['target'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_neural_config():\n",
    "    \"\"\"Define hiperparámetros para modelos neuronales.\"\"\"\n",
    "    return {\n",
    "        'DeepAR': {\n",
    "            'epochs': space.Int(30, 100),\n",
    "            'num_cells': space.Categorical([64, 128, 256]),\n",
    "            'context_length': space.Int(12, 24),\n",
    "            'dropout_rate': space.Real(0.1, 0.3),\n",
    "            'learning_rate': space.Real(1e-4, 1e-2, log=True)\n",
    "        },\n",
    "        'TemporalFusionTransformer': {\n",
    "            'epochs': space.Int(20, 50),\n",
    "            'hidden_dim': space.Categorical([64, 128]),\n",
    "            'dropout': space.Real(0.1, 0.3),\n",
    "            'attention_head_size': space.Int(2, 4)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def train_model(data):\n",
    "    \"\"\"Entrena el predictor con optimización avanzada.\"\"\"\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        target='target',\n",
    "        prediction_length=1,\n",
    "        freq=\"M\",\n",
    "        eval_metric=\"MAPE\",\n",
    "        quantile_levels=[0.1, 0.5, 0.9]\n",
    "    )\n",
    "    \n",
    "    predictor.fit(\n",
    "        train_data=data,\n",
    "        hyperparameters={\n",
    "        'DeepAR': {},\n",
    "        'TemporalFusionTransformer': {},\n",
    "        'SimpleFeedForward': {}\n",
    "        },\n",
    "        # Excluimos modelos no neuronales\n",
    "        excluded_model_types=['ARIMA', 'ETS', 'Theta'],\n",
    "        # hyperparameter_tune_kwargs={\n",
    "        #     'num_trials': 30,\n",
    "        #     'scheduler': 'local',\n",
    "        #     'searcher': 'bayes'\n",
    "        # },\n",
    "        num_val_windows=5,\n",
    "        verbosity=2\n",
    "    )\n",
    "    return predictor\n",
    "\n",
    "def main_v2():\n",
    "    # Cargar y preparar datos\n",
    "    df = load_and_prepare_data()\n",
    "    \n",
    "    # Preparar covariables conocidas\n",
    "    covariates = df[['item_id', 'timestamp', 'current_sales']].copy()\n",
    "    \n",
    "    # Convertir a TimeSeriesDataFrame\n",
    "    data = TimeSeriesDataFrame.from_data_frame(\n",
    "        df[['item_id', 'timestamp', 'target']],\n",
    "        id_column=\"item_id\",\n",
    "        timestamp_column=\"timestamp\"\n",
    "    )\n",
    "    \n",
    "    # Añadir covariables manualmente\n",
    "    # data.static_features = df[['cat1', 'cat2', 'cat3', 'brand']]\n",
    "    data.past_covariates = covariates\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    predictor = train_model(data)\n",
    "    \n",
    "    # Evaluar\n",
    "    performance = predictor.evaluate(data)\n",
    "    print(f\"\\n🔍 Resultados de evaluación:\")\n",
    "    print(f\"MAPE: {performance['MAPE']:.2%}\")\n",
    "    \n",
    "    \n",
    "    # Predecir (necesitarías proporcionar futuras covariables en producción)\n",
    "    predictions = predictor.predict(data)\n",
    "    print(\"\\n🔮 Predicciones para mes+2:\")\n",
    "    print(predictions.head())\n",
    "    \n",
    "    # Guardar modelo\n",
    "    # predictor.save(\"autogluon_mes+2_model\")\n",
    "    print(\"\\n💾 Modelo guardado en 'autogluon_mes+2_model'\")\n",
    "\n",
    "#### Main execution\n",
    "main_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dafc4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'MS' has been resampled to frequency 'ME'.\n",
      "Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer\n"
     ]
    }
   ],
   "source": [
    "# Predecir (necesitarías proporcionar futuras covariables en producción)\n",
    "predictions = predictor.predict(data)\n",
    "print(\"\\n🔮 Predicciones para mes+2:\")\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ad43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1341.511475</td>\n",
       "      <td>823.683533</td>\n",
       "      <td>925.015564</td>\n",
       "      <td>1085.486206</td>\n",
       "      <td>1214.482422</td>\n",
       "      <td>1341.511475</td>\n",
       "      <td>1464.198853</td>\n",
       "      <td>1623.361328</td>\n",
       "      <td>1817.171265</td>\n",
       "      <td>1987.480835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1015.737305</td>\n",
       "      <td>534.233826</td>\n",
       "      <td>632.800842</td>\n",
       "      <td>789.344604</td>\n",
       "      <td>906.329956</td>\n",
       "      <td>1015.737305</td>\n",
       "      <td>1130.787842</td>\n",
       "      <td>1293.329468</td>\n",
       "      <td>1469.710083</td>\n",
       "      <td>1626.574951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>814.567871</td>\n",
       "      <td>409.315521</td>\n",
       "      <td>488.814697</td>\n",
       "      <td>613.297180</td>\n",
       "      <td>712.641174</td>\n",
       "      <td>814.567871</td>\n",
       "      <td>908.631897</td>\n",
       "      <td>1035.952637</td>\n",
       "      <td>1188.012695</td>\n",
       "      <td>1324.846191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>618.369019</td>\n",
       "      <td>299.359558</td>\n",
       "      <td>364.609222</td>\n",
       "      <td>461.017120</td>\n",
       "      <td>538.686951</td>\n",
       "      <td>618.369019</td>\n",
       "      <td>691.794373</td>\n",
       "      <td>791.926880</td>\n",
       "      <td>911.070190</td>\n",
       "      <td>1019.771729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>577.933289</td>\n",
       "      <td>270.242493</td>\n",
       "      <td>335.133575</td>\n",
       "      <td>425.597534</td>\n",
       "      <td>499.880157</td>\n",
       "      <td>577.933289</td>\n",
       "      <td>648.736572</td>\n",
       "      <td>743.375427</td>\n",
       "      <td>858.381592</td>\n",
       "      <td>965.774536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20962</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1.781170</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>1.001992</td>\n",
       "      <td>1.667561</td>\n",
       "      <td>1.781170</td>\n",
       "      <td>2.223029</td>\n",
       "      <td>2.749121</td>\n",
       "      <td>3.341600</td>\n",
       "      <td>3.908631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20975</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1.547632</td>\n",
       "      <td>0.082958</td>\n",
       "      <td>0.610555</td>\n",
       "      <td>0.866282</td>\n",
       "      <td>1.448722</td>\n",
       "      <td>1.547632</td>\n",
       "      <td>1.932698</td>\n",
       "      <td>2.391508</td>\n",
       "      <td>2.909231</td>\n",
       "      <td>3.405061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1.488675</td>\n",
       "      <td>0.061618</td>\n",
       "      <td>0.575264</td>\n",
       "      <td>0.824913</td>\n",
       "      <td>1.393176</td>\n",
       "      <td>1.488675</td>\n",
       "      <td>1.861265</td>\n",
       "      <td>2.305810</td>\n",
       "      <td>2.809428</td>\n",
       "      <td>3.292396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>0.860489</td>\n",
       "      <td>0.063840</td>\n",
       "      <td>0.351255</td>\n",
       "      <td>0.489944</td>\n",
       "      <td>0.805902</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>1.072377</td>\n",
       "      <td>1.324167</td>\n",
       "      <td>1.606382</td>\n",
       "      <td>1.876020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21214</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>0.386403</td>\n",
       "      <td>-0.033819</td>\n",
       "      <td>0.116823</td>\n",
       "      <td>0.191662</td>\n",
       "      <td>0.360662</td>\n",
       "      <td>0.386403</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.613642</td>\n",
       "      <td>0.759267</td>\n",
       "      <td>0.899979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean         0.1         0.2          0.3  \\\n",
       "item_id timestamp                                                      \n",
       "20001   2020-01-31  1341.511475  823.683533  925.015564  1085.486206   \n",
       "20002   2020-01-31  1015.737305  534.233826  632.800842   789.344604   \n",
       "20003   2020-01-31   814.567871  409.315521  488.814697   613.297180   \n",
       "20004   2020-01-31   618.369019  299.359558  364.609222   461.017120   \n",
       "20005   2020-01-31   577.933289  270.242493  335.133575   425.597534   \n",
       "...                         ...         ...         ...          ...   \n",
       "20962   2020-01-31     1.781170    0.106227    0.709827     1.001992   \n",
       "20975   2020-01-31     1.547632    0.082958    0.610555     0.866282   \n",
       "20995   2020-01-31     1.488675    0.061618    0.575264     0.824913   \n",
       "21087   2020-01-31     0.860489    0.063840    0.351255     0.489944   \n",
       "21214   2020-01-31     0.386403   -0.033819    0.116823     0.191662   \n",
       "\n",
       "                            0.4          0.5          0.6          0.7  \\\n",
       "item_id timestamp                                                        \n",
       "20001   2020-01-31  1214.482422  1341.511475  1464.198853  1623.361328   \n",
       "20002   2020-01-31   906.329956  1015.737305  1130.787842  1293.329468   \n",
       "20003   2020-01-31   712.641174   814.567871   908.631897  1035.952637   \n",
       "20004   2020-01-31   538.686951   618.369019   691.794373   791.926880   \n",
       "20005   2020-01-31   499.880157   577.933289   648.736572   743.375427   \n",
       "...                         ...          ...          ...          ...   \n",
       "20962   2020-01-31     1.667561     1.781170     2.223029     2.749121   \n",
       "20975   2020-01-31     1.448722     1.547632     1.932698     2.391508   \n",
       "20995   2020-01-31     1.393176     1.488675     1.861265     2.305810   \n",
       "21087   2020-01-31     0.805902     0.860489     1.072377     1.324167   \n",
       "21214   2020-01-31     0.360662     0.386403     0.489858     0.613642   \n",
       "\n",
       "                            0.8          0.9  \n",
       "item_id timestamp                             \n",
       "20001   2020-01-31  1817.171265  1987.480835  \n",
       "20002   2020-01-31  1469.710083  1626.574951  \n",
       "20003   2020-01-31  1188.012695  1324.846191  \n",
       "20004   2020-01-31   911.070190  1019.771729  \n",
       "20005   2020-01-31   858.381592   965.774536  \n",
       "...                         ...          ...  \n",
       "20962   2020-01-31     3.341600     3.908631  \n",
       "20975   2020-01-31     2.909231     3.405061  \n",
       "20995   2020-01-31     2.809428     3.292396  \n",
       "21087   2020-01-31     1.606382     1.876020  \n",
       "21214   2020-01-31     0.759267     0.899979  \n",
       "\n",
       "[780 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_copy = predictions.copy()\n",
    "predictions_copy = predictions_copy.reset_index()\n",
    "predictions_copy.rename(columns={'mean': 'tn', 'item_id': 'product_id'}, inplace=True)\n",
    "predictions_copy = predictions_copy[['product_id','tn']]\n",
    "output_path = \"./outputs/predicciones_exp_06v4_autogluon_v1_original.csv\"\n",
    "predictions_copy.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
