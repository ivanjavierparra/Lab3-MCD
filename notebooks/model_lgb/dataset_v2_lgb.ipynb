{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f58daed",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1751ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7054b",
   "metadata": {},
   "source": [
    "Cargamos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9682af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellin = pd.read_csv(\"datasets/sell-in.csv\", sep='\\t')\n",
    "productos = pd.read_csv(\"datasets/tb_productos.csv\", sep='\\t')\n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "634afbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell-In: 2945818 filas y 7 columnas\n",
      "Productos: 1262 filas y 6 columnas\n",
      "Stocks: 13691 filas y 3 columnas\n"
     ]
    }
   ],
   "source": [
    "# Verificación inicial\n",
    "print(f\"Sell-In: {sellin.shape[0]} filas y {sellin.shape[1]} columnas\")\n",
    "print(f\"Productos: {productos.shape[0]} filas y {productos.shape[1]} columnas\")\n",
    "print(f\"Stocks: {stocks.shape[0]} filas y {stocks.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4e1219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas-Productos-Stocks: 2988650 filas y 13 columnas\n"
     ]
    }
   ],
   "source": [
    "# 3. MERGE INICIAL\n",
    "df = sellin.merge(productos, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(f\"Ventas-Productos-Stocks: {df.shape[0]} filas y {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37326e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 6)\n"
     ]
    }
   ],
   "source": [
    "productos_clean = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "print(productos_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65964baa",
   "metadata": {},
   "source": [
    "Hacemos el merge final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c6237db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2945818, 7)\n",
      "(2945818, 13)\n"
     ]
    }
   ],
   "source": [
    "df = sellin.merge(productos_clean, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(sellin.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae27b9",
   "metadata": {},
   "source": [
    "# Dataset: <periodo, producto>\n",
    "\n",
    "Tomamos con agregacion periodo y product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd0b4a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31522, 5)\n",
      "(31522, 10)\n",
      "(31522, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31522, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos periodo a datetime\n",
    "df[\"periodo_dt\"] = pd.to_datetime(df[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "# Determinar vida útil de cada producto (primer y último periodo)\n",
    "vida_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Expandimos cada producto con todos los periodos de su vida útil\n",
    "periodos_producto = []\n",
    "for _, row in vida_producto.iterrows():\n",
    "    periodos = pd.date_range(start=row[\"min\"], end=row[\"max\"], freq=\"MS\")\n",
    "    for p in periodos:\n",
    "        periodos_producto.append((p, row[\"product_id\"]))\n",
    "\n",
    "df_producto_periodo = pd.DataFrame(periodos_producto, columns=[\"periodo_dt\", \"product_id\"])\n",
    "\n",
    "\n",
    "\n",
    "# Agregar columna periodo en formato AAAAMM\n",
    "df_producto_periodo[\"periodo\"] = df_producto_periodo[\"periodo_dt\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "\n",
    "df_producto_periodo.drop(columns=['periodo_dt'],inplace=True)\n",
    "# Ordenar por periodo_dt (ascendente) y luego por product_id\n",
    "df_producto_periodo = df_producto_periodo.sort_values(by=[\"product_id\", \"periodo\"], ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "toneladas_vendidas = df.copy()\n",
    "# Agregar los datos por periodo y product_id para obtener la serie temporal\n",
    "# Sumamos tn, cust_request_qty y cust_request_tn por periodo y product_id\n",
    "toneladas_vendidas = df.groupby(['periodo', 'product_id']).agg({\n",
    "    'tn': 'sum',\n",
    "    'cust_request_qty': 'sum',\n",
    "    'cust_request_tn': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Paso 5: Unir con las toneladas efectivamente vendidas (tn)\n",
    "df_merge = df_producto_periodo.merge(toneladas_vendidas[[\"periodo\", \"product_id\", \"tn\",\"cust_request_qty\", \"cust_request_tn\"]],\n",
    "                             on=[\"periodo\", \"product_id\"],\n",
    "                             how=\"left\")\n",
    "\n",
    "print(df_merge.shape)\n",
    "df_merge[\"tn\"] = df_merge[\"tn\"].fillna(0)\n",
    "\n",
    "\n",
    "df_merge = df_merge.merge(productos_clean[['product_id', 'cat1', 'cat2', 'cat3','brand','sku_size']], on='product_id', how='left')\n",
    "print(df_merge.shape)\n",
    "df_merge = df_merge.merge(stocks[['product_id', 'periodo', 'stock_final']], on=['product_id', 'periodo'], how='left')\n",
    "print(df_merge.shape)\n",
    "\n",
    "\n",
    "\n",
    "# precios cuidados\n",
    "# Hacemos el merge por product_id y periodo\n",
    "df_precios = df[['product_id', 'periodo_dt', 'plan_precios_cuidados']].drop_duplicates()\n",
    "periodos_producto = []\n",
    "for _, row in vida_producto.iterrows():\n",
    "    product_id = row['product_id']\n",
    "    min_fecha = row['min']\n",
    "    max_fecha = row['max']\n",
    "    periodos = pd.date_range(start=min_fecha, end=max_fecha, freq='MS')\n",
    "    for p in periodos:\n",
    "        periodos_producto.append((product_id, p))\n",
    "\n",
    "df_periodos = pd.DataFrame(periodos_producto, columns=['product_id', 'periodo_dt'])\n",
    "df_final = df_periodos.merge(df_precios, on=['product_id', 'periodo_dt'], how='left')\n",
    "df_final[\"periodo\"] = df_final[\"periodo_dt\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "df_final.drop(columns=['periodo_dt'],inplace=True)\n",
    "\n",
    "df_merge = df_merge.merge(df_final[['product_id', 'periodo', 'plan_precios_cuidados']], on=['product_id', 'periodo'], how='left')\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8df09",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iparra\\AppData\\Local\\Temp\\ipykernel_24808\\2903603023.py:90: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ts['stock_growth'] = ts.groupby('product_id')['stock_final'].pct_change() #  calcula el cambio porcentual entre el valor actual y el valor anterior en la columna stock_final para cada grupo.\n"
     ]
    }
   ],
   "source": [
    "ts = df_merge.copy()\n",
    "\n",
    "# Convertir el periodo a formato datetime\n",
    "ts['periodo_dt'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "\n",
    "# Convertir las columnas de categoría a tipo 'category' para que las detecte LGBM\n",
    "ts['cat1'] = ts['cat1'].astype('category')\n",
    "ts['cat2'] = ts['cat2'].astype('category')\n",
    "ts['cat3'] = ts['cat3'].astype('category')\n",
    "ts['brand'] = ts['brand'].astype('category')\n",
    "ts['sku_size'] = ts['sku_size'].astype('category')\n",
    "\n",
    "# Crear características adicionales\n",
    "ts['crisis'] = (ts['periodo_dt'].dt.year == 2019) & (ts['periodo_dt'].dt.month == 8)\n",
    "ts['quarter'] = ts['periodo_dt'].dt.quarter\n",
    "ts['month'] = ts['periodo_dt'].dt.month\n",
    "ts['year'] = ts['periodo_dt'].dt.year\n",
    "ts['season'] = ts['periodo_dt'].apply(lambda x: 1 if x.month in [6, 7, 8] else 0)\n",
    "ts['tn_diff'] = ts.groupby('product_id')['tn'].diff()\n",
    "ts['rolling_mean'] = ts.groupby('product_id')['tn'].rolling(window=3).mean().reset_index(level=0, drop=True)\n",
    "ts['interaction'] = ts['year'] * ts['month']\n",
    "\n",
    "# Normalización por producto\n",
    "# ts['tn_norm'] = ts.groupby('product_id')['tn'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Agregar lags a los datos\n",
    "for lag in range(1, 13):\n",
    "    ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Identificar el primer y último periodo de ventas para cada producto\n",
    "ts['first_sale'] = ts.groupby('product_id')['periodo_dt'].transform('min')\n",
    "ts['last_sale'] = ts.groupby('product_id')['periodo_dt'].transform('max')\n",
    "\n",
    "# Calcular el tiempo desde la primera venta para cada registro\n",
    "ts['months_since_launch'] = (ts['periodo_dt'] - ts['first_sale']).dt.days // 30  # en meses\n",
    "\n",
    "# Crear una categoría de madurez basada en el tiempo desde la primera venta\n",
    "conditions = [\n",
    "    (ts['months_since_launch'] < 6),\n",
    "    (ts['months_since_launch'] >= 6) & (ts['months_since_launch'] < 18),\n",
    "    (ts['months_since_launch'] >= 18) & (ts['months_since_launch'] < 30),\n",
    "    (ts['months_since_launch'] >= 30)\n",
    "]\n",
    "choices = ['new', 'growth', 'mature', 'decline']\n",
    "ts['grado_de_madurez'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "# One-Hot Encode the grado_de_madurez feature\n",
    "ts = pd.get_dummies(ts, columns=['grado_de_madurez'], drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PESOS para el LGB: podria cambiarlo: por cantidad de ventas.\n",
    "# Paso 1: Calcular la suma total por producto\n",
    "participacion = ts.groupby('product_id')['tn'].sum()\n",
    "# Paso 2: Calcular el total global\n",
    "total_global = participacion.sum()\n",
    "# Paso 3: Calcular la proporción por producto\n",
    "participacion = participacion / total_global\n",
    "participacion.name = 'participacion_tn'\n",
    "# Paso 4: Merge con el DataFrame original\n",
    "ts = ts.merge(participacion, on='product_id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Agrupar por categorias y ver estadisticas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stock de prodctos: velocidad de rotacion\n",
    "ts['stock_ratio'] = ts['tn'] / ts['stock_final']\n",
    "ts['stock_ratio'] = ts.apply(\n",
    "    lambda x: x['tn'] / x['stock_final'] if x['stock_final'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "ts['stock_ratio'] = ts['stock_ratio'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crecimiento del stock entre periodos\n",
    "# Útil para detectar si el producto está acumulando inventario o escaseando.\n",
    "ts['stock_growth'] = ts.groupby('product_id')['stock_final'].pct_change() #  calcula el cambio porcentual entre el valor actual y el valor anterior en la columna stock_final para cada grupo. \n",
    "ts['stock_growth'] = ts['stock_growth'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Relación stock actual vs. promedio histórico\n",
    "# Promedio histórico del stock por producto\n",
    "avg_stock = ts.groupby('product_id')['stock_final'].transform('mean')\n",
    "ts['stock_vs_avg'] = ts['stock_final'] / avg_stock\n",
    "ts['stock_vs_avg'] = ts['stock_vs_avg'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Stock lagueado (ej: t-1, t-2)\n",
    "# Ideal para que LightGBM aprenda con información de meses previos.\n",
    "ts['stock_lag1'] = ts.groupby('product_id')['stock_final'].shift(1)\n",
    "ts['stock_lag1'] = ts['stock_lag1'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "ts['stock_lag2'] = ts.groupby('product_id')['stock_final'].shift(2)\n",
    "ts['stock_lag2'] = ts['stock_lag2'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "\n",
    "# Categorizar el nivel de stock\n",
    "# Podés discretizar la variable si pensás que LightGBM puede beneficiarse de eso.\n",
    "ts['stock_level'] = pd.qcut(ts['stock_final'], q=4, labels=['Muy bajo', 'Bajo', 'Medio', 'Alto'])\n",
    "# ts['stock_level'] = ts['stock_level'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "ts['stock_level'] = ts['stock_level'].cat.codes\n",
    "\n",
    "######## EL STOCK SE PUEDE RECONSTRUIR EN BASE A LAS TONELADAS VENDIDAS ########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Clustering de productos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Porcentaje vendido al top 13 de clientes: Nueva columna que, para cada combinación periodo-producto, indique qué porcentaje de toneladas fue vendido a los top 13 clientes.\n",
    "# Paso 1: Identificar los top 13 clientes\n",
    "df_copy = df.copy() \n",
    "top_13 = (df_copy.groupby('customer_id')['tn'].sum()\n",
    "          .sort_values(ascending=False)\n",
    "          .head(13)\n",
    "          .index)\n",
    "# Paso 2: Calcular toneladas por periodo-producto para top13\n",
    "df_copy['is_top13'] = df_copy['customer_id'].isin(top_13)\n",
    "agregado_total = df_copy.groupby(['periodo', 'product_id'])['tn'].sum()\n",
    "agregado_top13 = df_copy[df_copy['is_top13']].groupby(['periodo', 'product_id'])['tn'].sum()\n",
    "# Paso 3: Crear DataFrame de proporción\n",
    "df_prop = (agregado_top13 / agregado_total).reset_index(name='porcentaje_top13')\n",
    "# Paso 4: Merge con tu dataset original\n",
    "ts = ts.merge(df_prop, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Numero de clientes distintos por producto y mes: Esto indica cuán diversificada es la demanda por producto en cada periodo.\n",
    "clientes_distintos = df.groupby(['periodo', 'product_id'])['customer_id'].nunique().reset_index(name='n_clientes')\n",
    "ts = ts.merge(clientes_distintos, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Concentración (índice de Herfindahl): Podés calcular el índice de concentración por producto y mes. \n",
    "# El índice de Herfindahl es la suma de los cuadrados de las participaciones de los clientes:\n",
    "# Calcular la participación de cada cliente por periodo-producto\n",
    "participaciones = df.groupby(['periodo', 'product_id', 'customer_id'])['tn'].sum()\n",
    "# Calcular el índice de Herfindahl-Hirschman\n",
    "participaciones_pct = participaciones.groupby(['periodo', 'product_id']).apply(\n",
    "    lambda x: ((x / x.sum())**2).sum()\n",
    ").reset_index(name='hh_index')\n",
    "# Merge con tu dataframe agregado por periodo y producto\n",
    "ts = ts.merge(participaciones_pct, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tasa de repetición de clientes\n",
    "# % de clientes que ya compraron el producto en el período anterior\n",
    "# Paso 1: Agrupar y obtener clientes únicos por período y producto\n",
    "clientes_por_periodo = df.groupby(['periodo', 'product_id'])['customer_id'].unique().reset_index()\n",
    "# Paso 2: Ordenar\n",
    "clientes_por_periodo = clientes_por_periodo.sort_values(['product_id', 'periodo'])\n",
    "# Paso 3: Shift preservando la estructura (usando transform)\n",
    "clientes_por_periodo['clientes_prev'] = (\n",
    "    clientes_por_periodo.groupby('product_id')['customer_id']\n",
    "    .transform(lambda x: x.shift(1))\n",
    ")\n",
    "# Paso 4: Función corregida para tasa de repetición\n",
    "def tasa_repeticion(row):\n",
    "    clientes_actuales = set(row['customer_id']) if isinstance(row['customer_id'], np.ndarray) else set()\n",
    "    clientes_anteriores = set(row['clientes_prev']) if isinstance(row['clientes_prev'], np.ndarray) else set()\n",
    "    \n",
    "    if not clientes_actuales:\n",
    "        return 0.0\n",
    "    \n",
    "    repetidos = clientes_actuales & clientes_anteriores\n",
    "    return len(repetidos) / len(clientes_actuales)\n",
    "clientes_por_periodo['tasa_repeticion'] = clientes_por_periodo.apply(tasa_repeticion, axis=1)\n",
    "# Resultado\n",
    "resultado = clientes_por_periodo[['periodo', 'product_id', 'tasa_repeticion']]\n",
    "ts = ts.merge(resultado, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Clientes nuevos para ese producto\n",
    "# Construir un historial de compras por cliente-producto\n",
    "df_copy = df.copy()\n",
    "df_copy['first_purchase'] = df_copy.groupby(['customer_id', 'product_id'])['periodo'].transform('min')\n",
    "# Cliente nuevo = primera compra de ese producto en ese mes\n",
    "df_copy['cliente_nuevo'] = (df_copy['periodo'] == df_copy['first_purchase']).astype(int)\n",
    "# Agregar a nivel periodo-producto\n",
    "clientes_nuevos = df_copy.groupby(['periodo', 'product_id'])['cliente_nuevo'].sum().reset_index()\n",
    "# Merge con el DataFrame original\n",
    "ts = ts.merge(clientes_nuevos, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Promedio histórico de toneladas por cliente (en un mes): promedio de compra\n",
    "promedio_tn_cliente = (\n",
    "    df.groupby(['product_id', 'customer_id'])['tn']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby('product_id')['tn']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tn': 'prom_tn_cliente'})\n",
    ")\n",
    "ts = ts.merge(promedio_tn_cliente, on='product_id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Varianza de las toneladas por cliente (en un mes): dispersión en tamaño de compra\n",
    "var_tn_cliente = (\n",
    "    df.groupby(['periodo', 'product_id'])['tn']\n",
    "    .std()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tn': 'std_tn_cliente'})\n",
    ")\n",
    "ts = ts.merge(var_tn_cliente, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Coeficiente de Gini de participación de clientes: desigualdad en la distribución de compras\n",
    "def gini(array):\n",
    "    array = np.sort(np.array(array))\n",
    "    n = len(array)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    cumx = np.cumsum(array, dtype=float)\n",
    "    return (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "\n",
    "gini_por_producto = (\n",
    "    df.groupby(['periodo', 'product_id'])['tn']\n",
    "    .apply(gini)\n",
    "    .reset_index()\n",
    "    .rename(columns={'tn': 'gini_clientes'})\n",
    ")\n",
    "ts = ts.merge(gini_por_producto, on=['periodo', 'product_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prediccion: SARIMA, PMDARIMA, STATSFORECAST, PROPHET, DARTS\n",
    "\n",
    "# clientes: ocasionales, esporadicos, regulares, frecuentes\n",
    "\n",
    "\n",
    "\n",
    "# Eventos politicos\n",
    "\n",
    "\n",
    "ts['periodo_dt'] = ts['periodo_dt'].dt.year * 100 + ts['periodo_dt'].dt.month\n",
    "ts['first_sale'] = ts['first_sale'].dt.year * 100 + ts['first_sale'].dt.month\n",
    "ts['last_sale'] = ts['last_sale'].dt.year * 100 + ts['last_sale'].dt.month\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ee8be",
   "metadata": {},
   "source": [
    "Defino el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351edfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "ts['tn_target'] = ts['tn'].shift(-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecffa2",
   "metadata": {},
   "source": [
    "Entrenamiento con lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f75dc319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8623\n",
      "[LightGBM] [Info] Number of data points in the train set: 29652, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 42.165901\n",
      "Modelo LightGBM entrenado con éxito.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from scipy.stats import uniform\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# quito 201911 y 201912\n",
    "dt_kgl = ts[ts[\"periodo\"].isin([201912])]\n",
    "ts = ts.drop(ts[ts[\"periodo\"].isin([201911,201912])].index,axis=0)\n",
    "\n",
    "for col in ['cat1', 'cat2', 'cat3', 'brand','sku_size']:\n",
    "    if col in ts.columns:\n",
    "        ts[col] = ts[col].astype('category')\n",
    "\n",
    "\n",
    "feature_columns = [col for col in ts.columns if col not in ['periodo_dt', 'tn_target']]\n",
    "\n",
    "\n",
    "X = ts[feature_columns]\n",
    "y = ts['tn_target']\n",
    "\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor(random_state=12345)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lgb_reg.fit(X, y)\n",
    "\n",
    "print(\"Modelo LightGBM entrenado con éxito.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd52c1",
   "metadata": {},
   "source": [
    "Armamos dataset de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9e16a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in ts.columns if col not in ['periodo_dt', 'tn_target']]\n",
    "X_kgl = dt_kgl[feature_columns]\n",
    "\n",
    "productos_a_predecir = pd.read_csv(\"datasets/product_id_apredecir201912.csv\")\n",
    "# Filtrar filas\n",
    "productos_filtrados = productos_a_predecir['product_id'].unique()\n",
    "X_kgl = X_kgl[X_kgl['product_id'].isin(productos_filtrados)]\n",
    "\n",
    "X_kgl['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46b806",
   "metadata": {},
   "source": [
    "Predecimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa4e1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_reg.predict(X_kgl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d09f5",
   "metadata": {},
   "source": [
    "<!-- Guardamos la prediccion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16e4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20001</td>\n",
       "      <td>1284.479988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>20002</td>\n",
       "      <td>1350.981234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>20003</td>\n",
       "      <td>742.383889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>20004</td>\n",
       "      <td>673.925562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>20005</td>\n",
       "      <td>590.792058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31344</th>\n",
       "      <td>21263</td>\n",
       "      <td>-0.442789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31384</th>\n",
       "      <td>21265</td>\n",
       "      <td>-0.612402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31394</th>\n",
       "      <td>21266</td>\n",
       "      <td>-0.593370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31404</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.034758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31482</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.291611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id           tn\n",
       "35          20001  1284.479988\n",
       "71          20002  1350.981234\n",
       "107         20003   742.383889\n",
       "143         20004   673.925562\n",
       "179         20005   590.792058\n",
       "...           ...          ...\n",
       "31344       21263    -0.442789\n",
       "31384       21265    -0.612402\n",
       "31394       21266    -0.593370\n",
       "31404       21267     0.034758\n",
       "31482       21276     0.291611\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"product_id\": X_kgl[\"product_id\"],  \"tn\": y_pred})\n",
    "result.to_csv(\"./kaggle/06-lgb.csv\", index=False, sep=',')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
