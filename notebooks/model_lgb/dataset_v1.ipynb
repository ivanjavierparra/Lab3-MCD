{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd95e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc9449e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellin = pd.read_csv(\"datasets/sell-in.csv\", sep='\\t')\n",
    "productos = pd.read_csv(\"datasets/tb_productos.csv\", sep='\\t')\n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d347f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell-In: 2945818 filas y 7 columnas\n",
      "Productos: 1262 filas y 6 columnas\n",
      "Stocks: 13691 filas y 3 columnas\n"
     ]
    }
   ],
   "source": [
    "# Verificación inicial\n",
    "print(f\"Sell-In: {sellin.shape[0]} filas y {sellin.shape[1]} columnas\")\n",
    "print(f\"Productos: {productos.shape[0]} filas y {productos.shape[1]} columnas\")\n",
    "print(f\"Stocks: {stocks.shape[0]} filas y {stocks.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6596c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas-Productos-Stocks: 2988650 filas y 13 columnas\n"
     ]
    }
   ],
   "source": [
    "# 3. MERGE INICIAL\n",
    "df = sellin.merge(productos, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(f\"Ventas-Productos-Stocks: {df.shape[0]} filas y {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2905a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 6)\n"
     ]
    }
   ],
   "source": [
    "productos_clean = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "print(productos_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bc7cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2945818, 7)\n",
      "(2945818, 13)\n"
     ]
    }
   ],
   "source": [
    "df = sellin.merge(productos_clean, on=\"product_id\", how=\"left\")\n",
    "df = df.merge(stocks, on=[\"product_id\", \"periodo\"], how=\"left\")\n",
    "print(sellin.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5852715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['periodo_dt'] = pd.to_datetime(df['periodo'].astype(str), format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "64ddd67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  product_id  customer_id        tn\n",
      "0   201701       20001        10234   0.33579\n",
      "1   201701       20001        10032  12.31230\n",
      "2   201701       20001        10217   0.00000\n",
      "3   201701       20001        10125   0.08954\n",
      "4   201701       20001        10012   6.97324\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que df ya contiene las columnas: periodo, customer_id, product_id, tn\n",
    "df[\"periodo_dt\"] = pd.to_datetime(df[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "# Paso 1: Rango total de periodos\n",
    "todos_los_periodos = pd.date_range(start=df[\"periodo_dt\"].min(), end=df[\"periodo_dt\"].max(), freq=\"MS\")\n",
    "\n",
    "# Paso 2: Todos los clientes únicos\n",
    "todos_los_clientes = df[\"customer_id\"].unique()\n",
    "\n",
    "# Paso 3: Determinar vida útil de cada producto\n",
    "vida_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Paso 4: Generar combinaciones (periodo, producto) considerando restricciones\n",
    "combinaciones_producto_periodo = []\n",
    "fecha_limite_nuevos = pd.to_datetime(\"2017-03\", format=\"%Y-%m\")\n",
    "\n",
    "# Los productos de 35 y 36 meeses de vida son considerados \"vitales\"\n",
    "productos_vitales = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "mask = (productos_vitales['min'] == '2017-01-01') & ((productos_vitales['max'] == '2019-12-01'))\n",
    "productos_vitales = productos_vitales[mask]['product_id'].unique()  \n",
    "\n",
    "for _, row in vida_producto.iterrows():\n",
    "    producto = row[\"product_id\"]\n",
    "    min_fecha = row[\"min\"]\n",
    "    max_fecha = row[\"max\"]\n",
    "    periodos_validos = pd.date_range(start=min_fecha, end=max_fecha, freq=\"MS\")\n",
    "    es_nuevo = min_fecha >= fecha_limite_nuevos  # solo si el producto es nuevo a partir de 2017-02\n",
    "    \n",
    "    for p in periodos_validos:\n",
    "        if producto in productos_vitales:\n",
    "            combinaciones_producto_periodo.append((p, producto))\n",
    "            continue\n",
    "        # Excluir primeros 3 meses si es nuevo (a partir de 2017-02)\n",
    "        if es_nuevo and (p < min_fecha + pd.DateOffset(months=3)):\n",
    "            continue\n",
    "        # Excluir últimos 3 meses del producto\n",
    "        if p > max_fecha - pd.DateOffset(months=3):\n",
    "            continue\n",
    "        combinaciones_producto_periodo.append((p, producto))\n",
    "\n",
    "df_producto_periodo = pd.DataFrame(combinaciones_producto_periodo, columns=[\"periodo_dt\", \"product_id\"])\n",
    "\n",
    "# Paso 5: Generar combinaciones de todos los clientes con (periodo, producto)\n",
    "combinaciones = []\n",
    "for _, row in df_producto_periodo.iterrows():\n",
    "    periodo = row[\"periodo_dt\"]\n",
    "    producto = row[\"product_id\"]\n",
    "    for cliente in todos_los_clientes:\n",
    "        # if producto in df[df[\"customer_id\"] == cliente][\"product_id\"].unique(): ###### <------ ESTO TARDA 3 AÑOS\n",
    "        combinaciones.append((periodo, producto, cliente)) \n",
    "\n",
    "df_completo = pd.DataFrame(combinaciones, columns=[\"periodo_dt\", \"product_id\", \"customer_id\"])\n",
    "\n",
    "# Paso 6: Unir con toneladas efectivas\n",
    "df_merge = df_completo.merge(df[[\"periodo_dt\", \"product_id\", \"customer_id\", \"tn\"]],\n",
    "                             on=[\"periodo_dt\", \"product_id\", \"customer_id\"],\n",
    "                             how=\"left\")\n",
    "df_merge[\"tn\"] = df_merge[\"tn\"].fillna(0)\n",
    "\n",
    "# Paso 7: Recuperar periodo AAAAMM si lo necesitás\n",
    "df_merge[\"periodo\"] = df_merge[\"periodo_dt\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "\n",
    "# Resultado final\n",
    "df_final = df_merge[[\"periodo\", \"product_id\", \"customer_id\", \"tn\"]]\n",
    "\n",
    "# Vista previa\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c193f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_final[df_final['periodo']==201912]\n",
    "a['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6658fca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18818634, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  periodo_dt  product_id  customer_id        tn cat1         cat2     cat3  \\\n",
      "0 2017-01-01       20001        10234   0.33579   HC  ROPA LAVADO  Liquido   \n",
      "1 2017-01-01       20001        10032  12.31230   HC  ROPA LAVADO  Liquido   \n",
      "2 2017-01-01       20001        10217   0.00000   HC  ROPA LAVADO  Liquido   \n",
      "3 2017-01-01       20001        10125   0.08954   HC  ROPA LAVADO  Liquido   \n",
      "4 2017-01-01       20001        10012   6.97324   HC  ROPA LAVADO  Liquido   \n",
      "\n",
      "   brand  sku_size  stock_final  periodo  \n",
      "0  ARIEL    3000.0          NaN   201701  \n",
      "1  ARIEL    3000.0          NaN   201701  \n",
      "2  ARIEL    3000.0          NaN   201701  \n",
      "3  ARIEL    3000.0          NaN   201701  \n",
      "4  ARIEL    3000.0          NaN   201701  \n"
     ]
    }
   ],
   "source": [
    "# # 📅 Convertir periodos a datetime\n",
    "# sellin['periodo_dt'] = pd.to_datetime(sellin['periodo'].astype(str), format='%Y%m')\n",
    "# stocks['periodo_dt'] = pd.to_datetime(stocks['periodo'].astype(str), format='%Y%m')\n",
    "\n",
    "# # 🛠 Preparar vida útil productos desde sellin\n",
    "# vida_producto = sellin.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "# fecha_limite_nuevos = pd.to_datetime(\"2017-03\", format=\"%Y-%m\")\n",
    "\n",
    "# # Identificar productos vitales (35-36 meses)\n",
    "# productos_vitales = vida_producto[\n",
    "#     (vida_producto['min'] == pd.to_datetime('2017-01-01')) &\n",
    "#     (vida_producto['max'] == pd.to_datetime('2019-12-01'))\n",
    "# ]['product_id'].unique()\n",
    "\n",
    "# # Generar combinaciones periodo-producto según reglas\n",
    "# combinaciones_producto_periodo = []\n",
    "# for _, row in vida_producto.iterrows():\n",
    "#     producto = row[\"product_id\"]\n",
    "#     min_fecha = row[\"min\"]\n",
    "#     max_fecha = row[\"max\"]\n",
    "#     periodos_validos = pd.date_range(start=min_fecha, end=max_fecha, freq=\"MS\")\n",
    "#     es_nuevo = min_fecha >= fecha_limite_nuevos\n",
    "    \n",
    "#     for p in periodos_validos:\n",
    "#         if producto in productos_vitales:\n",
    "#             combinaciones_producto_periodo.append((p, producto))\n",
    "#             continue\n",
    "#         if es_nuevo and (p < min_fecha + pd.DateOffset(months=3)):\n",
    "#             continue\n",
    "#         if p > max_fecha - pd.DateOffset(months=3):\n",
    "#             continue\n",
    "#         combinaciones_producto_periodo.append((p, producto))\n",
    "\n",
    "# df_producto_periodo = pd.DataFrame(combinaciones_producto_periodo, columns=[\"periodo_dt\", \"product_id\"])\n",
    "\n",
    "# # Obtener todos los clientes\n",
    "# todos_clientes = sellin['customer_id'].unique()\n",
    "\n",
    "# # 🚀 Generar combinaciones periodo-producto-cliente\n",
    "# combinaciones = []\n",
    "# for _, row in df_producto_periodo.iterrows():\n",
    "#     for cliente in todos_clientes:\n",
    "#         combinaciones.append((row['periodo_dt'], row['product_id'], cliente))\n",
    "\n",
    "# df_completo = pd.DataFrame(combinaciones, columns=[\"periodo_dt\", \"product_id\", \"customer_id\"])\n",
    "\n",
    "# # 🚦 Cruce con ventas (sell-in)\n",
    "# sellin_subset = sellin[['periodo_dt', 'product_id', 'customer_id', 'tn']]\n",
    "# df_merged = df_completo.merge(sellin_subset, on=['periodo_dt', 'product_id', 'customer_id'], how='left')\n",
    "# df_merged['tn'] = df_merged['tn'].fillna(0)\n",
    "\n",
    "# # 🚦 Cruce con tb_productos (por product_id)\n",
    "# df_merged = df_merged.merge(productos, on='product_id', how='left')\n",
    "\n",
    "# # 🚦 Cruce con stocks (por periodo y product_id)\n",
    "# df_merged = df_merged.merge(stocks[['periodo_dt', 'product_id', 'stock_final']], on=['periodo_dt', 'product_id'], how='left')\n",
    "\n",
    "# # 📅 Recuperar periodo en formato AAAAMM\n",
    "# df_merged['periodo'] = df_merged['periodo_dt'].dt.strftime('%Y%m').astype(int)\n",
    "\n",
    "# # 🚀 Dataset final para LightGBM\n",
    "# print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2030e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17193600, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f3da9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c78cc346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de filas duplicadas en df_final: 0\n"
     ]
    }
   ],
   "source": [
    "# Contar duplicados en todo el DataFrame\n",
    "num_duplicados = df_final.duplicated().sum()\n",
    "print(f\"Cantidad total de filas duplicadas en df_final: {num_duplicados}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96199a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000172, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts = df_merged.drop_duplicates()\n",
    "# ts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa1d64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df_final.copy()\n",
    "ts['periodo_dt'] = pd.to_datetime(ts['periodo'].astype(str), format='%Y%m')\n",
    "# crear alguans variables nuevas de prueba\n",
    "ts[\"month\"] = ts[\"periodo_dt\"].dt.month\n",
    "ts[\"year\"] = ts[\"periodo_dt\"].dt.year\n",
    "\n",
    "\n",
    "# Convertir columnas categóricas a tipo 'category' para LightGBM\n",
    "for col in ['cat1', 'cat2', 'cat3', 'brand']:\n",
    "    if col in ts.columns:\n",
    "        ts[col] = ts[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd15a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  product_id  customer_id        tn periodo_dt  month  year  \\\n",
      "0   201701       20001        10234   0.33579 2017-01-01      1  2017   \n",
      "1   201701       20001        10032  12.31230 2017-01-01      1  2017   \n",
      "2   201701       20001        10217   0.00000 2017-01-01      1  2017   \n",
      "3   201701       20001        10125   0.08954 2017-01-01      1  2017   \n",
      "4   201701       20001        10012   6.97324 2017-01-01      1  2017   \n",
      "\n",
      "   tn_lag_1  tn_lag_2  tn_lag_3  ...  tn_roll_mean_3  tn_roll_std_3  \\\n",
      "0       NaN       NaN       NaN  ...             NaN            NaN   \n",
      "1   0.33579       NaN       NaN  ...             NaN            NaN   \n",
      "2  12.31230   0.33579       NaN  ...        4.216030       7.013585   \n",
      "3   0.00000  12.31230   0.33579  ...        4.133947       7.082803   \n",
      "4   0.08954   0.00000  12.31230  ...        2.354260       4.000405   \n",
      "\n",
      "   tn_roll_mean_6  tn_roll_std_6  tn_roll_mean_12  tn_roll_std_12  \\\n",
      "0             NaN            NaN              NaN             NaN   \n",
      "1             NaN            NaN              NaN             NaN   \n",
      "2             NaN            NaN              NaN             NaN   \n",
      "3             NaN            NaN              NaN             NaN   \n",
      "4             NaN            NaN              NaN             NaN   \n",
      "\n",
      "   tn_roll_mean_24  tn_roll_std_24  quarter  season  \n",
      "0              NaN             NaN        1       0  \n",
      "1              NaN             NaN        1       0  \n",
      "2              NaN             NaN        1       0  \n",
      "3              NaN             NaN        1       0  \n",
      "4              NaN             NaN        1       0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'periodo_dt' a formato de tiempo si no está\n",
    "ts['periodo_dt'] = pd.to_datetime(ts['periodo_dt'])\n",
    "\n",
    "# Asegurar que está ordenado por producto y fecha\n",
    "ts = ts.sort_values(['product_id', 'periodo_dt'])\n",
    "\n",
    "# Crear lags de ventas (tn)\n",
    "for lag in range(1, 12):  # Por ejemplo, lags 1, 2 y 3 meses\n",
    "    ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Crear delta (diferencia) con el mes anterior\n",
    "ts['tn_delta'] = ts['tn'] - ts['tn_lag_1']\n",
    "\n",
    "# Crear delta relativo (proporcional)\n",
    "ts['tn_delta_pct'] = ts['tn_delta'] / ts['tn_lag_1'].replace(0, np.nan)\n",
    "\n",
    "# Crear rolling stats (medias y desviaciones)\n",
    "for window in [3, 6, 12, 24]:  # Por ejemplo, ventanas de 3 y 6 meses\n",
    "    ts[f'tn_roll_mean_{window}'] = ts.groupby('product_id')['tn'].rolling(window).mean().reset_index(0, drop=True)\n",
    "    ts[f'tn_roll_std_{window}'] = ts.groupby('product_id')['tn'].rolling(window).std().reset_index(0, drop=True)\n",
    "\n",
    "# Crear características de estacionalidad\n",
    "ts['month'] = ts['periodo_dt'].dt.month\n",
    "ts['quarter'] = ts['periodo_dt'].dt.quarter\n",
    "ts['year'] = ts['periodo_dt'].dt.year\n",
    "ts['season'] = ts['month'].apply(lambda x: 1 if x in [6, 7, 8] else 0)  # ejemplo: verano\n",
    "\n",
    "# Si querés completar valores nulos generados por lags y rolling\n",
    "# ts.fillna(0, inplace=True)\n",
    "\n",
    "print(ts.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "59871fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['tn_target'] = ts['tn'].shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d30f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_kgl = ts[ts[\"periodo\"].isin([201912])]\n",
    "ts = ts.drop(ts[ts[\"periodo\"].isin([201911,201912])].index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6dc8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_kgl['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b3d1c",
   "metadata": {},
   "source": [
    "# Sin optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02276c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 17702244, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 0.071443\n",
      "Modelo LightGBM entrenado con éxito.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "feature_columns = [col for col in ts.columns if col not in ['periodo_dt', 'tn_target']]\n",
    "\n",
    "X = ts[feature_columns]\n",
    "y = ts['tn_target']\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor(random_state=12345)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lgb_reg.fit(X, y)\n",
    "\n",
    "print(\"Modelo LightGBM entrenado con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef685f",
   "metadata": {},
   "source": [
    "# Con optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "712ad5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Target tiene NaN, se eliminarán.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.9 MiB for an array with shape (17702242,) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Target tiene NaN, se eliminarán.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39my\u001b[38;5;241m.\u001b[39misnull()\n\u001b[1;32m---> 17\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     y \u001b[38;5;241m=\u001b[39m y[mask]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Opcional: usar una muestra para pruebas (descomentar si querés)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# X = X.sample(frac=0.2, random_state=42)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# y = y.loc[X.index]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Función objetivo para Optuna\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4155\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:133\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m--> 133\u001b[0m dtype, fill_value, mask_info \u001b[38;5;241m=\u001b[39m \u001b[43m_take_preprocess_indexer_and_fill_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m flip_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:585\u001b[0m, in \u001b[0;36m_take_preprocess_indexer_and_fill_value\u001b[1;34m(arr, indexer, fill_value, allow_fill, mask)\u001b[0m\n\u001b[0;32m    583\u001b[0m     needs_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mindexer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    586\u001b[0m     needs_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(mask\u001b[38;5;241m.\u001b[39many())\n\u001b[0;32m    587\u001b[0m mask_info \u001b[38;5;241m=\u001b[39m mask, needs_masking\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.9 MiB for an array with shape (17702242,) and data type bool"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Preparar datos\n",
    "feature_columns = [col for col in ts.columns if col not in ['periodo_dt', 'tn_target']]\n",
    "feature_columns = ['periodo', 'customer_id','product_id','tn']\n",
    "X = ts[feature_columns]\n",
    "y = ts['tn_target']\n",
    "\n",
    "# Verificar NaN en y y eliminarlos\n",
    "if y.isnull().any():\n",
    "    print(\"⚠️ Target tiene NaN, se eliminarán.\")\n",
    "    mask = ~y.isnull()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "# Opcional: usar una muestra para pruebas (descomentar si querés)\n",
    "# X = X.sample(frac=0.2, random_state=42)\n",
    "# y = y.loc[X.index]\n",
    "\n",
    "# Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 12345,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True)\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)  # Ajustar según disponibilidad de memoria\n",
    "    rmses = []\n",
    "    for train_idx, valid_idx in tscv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(50),\n",
    "                lgb.log_evaluation(0)  # Desactiva logs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_valid)\n",
    "        rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# Crear y optimizar estudio Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Mostrar mejores parámetros encontrados\n",
    "print(\"Mejores parámetros encontrados:\", study.best_params)\n",
    "\n",
    "# Entrenar modelo final con los mejores parámetros\n",
    "best_params = study.best_params\n",
    "best_model = lgb.LGBMRegressor(**best_params, random_state=12345)\n",
    "best_model.fit(X, y)\n",
    "\n",
    "print(\"✅ Modelo LightGBM optimizado y entrenado con éxito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "55f4dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿X tiene NaN?: True\n",
      "¿y tiene NaN?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"¿X tiene NaN?:\", X.isnull().any().any())\n",
    "print(\"¿y tiene NaN?:\", y.isnull().any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d18b4",
   "metadata": {},
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b6a6a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kgl = dt_kgl[feature_columns]\n",
    "\n",
    "productos_a_predecir = pd.read_csv(\"datasets/product_id_apredecir201912.csv\")\n",
    "# Filtrar filas\n",
    "productos_filtrados = productos_a_predecir['product_id'].unique()\n",
    "X_kgl = X_kgl[X_kgl['product_id'].isin(productos_filtrados)]\n",
    "\n",
    "X_kgl['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "af9fcaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_reg.predict(X_kgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c1247ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1116.043838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1122.006487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>1080.209452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>1089.665181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>557.805169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>2.179084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>2.181989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>2.181989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>2.179177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>2.179084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id           tn\n",
       "0         20001  1116.043838\n",
       "1         20002  1122.006487\n",
       "2         20003  1080.209452\n",
       "3         20004  1089.665181\n",
       "4         20005   557.805169\n",
       "..          ...          ...\n",
       "775       21263     2.179084\n",
       "776       21265     2.181989\n",
       "777       21266     2.181989\n",
       "778       21267     2.179177\n",
       "779       21276     2.179084\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"product_id\": X_kgl[\"product_id\"],  \"tn\": y_pred})\n",
    "result = result.groupby(\"product_id\").agg({\"tn\":\"sum\"}).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91e87e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./kaggle/05-lgb_customer_x_cliente.csv\", index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
