{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c988217e",
   "metadata": {},
   "source": [
    "# Generación de Dataset <Período, Customer, Producto>\n",
    "\n",
    "Vale la pena predecir aquellos clientes que compraron una sola vez? No en los ultimos 3 meses, sino mas anteriormente. \n",
    "* Rta: No borra nada!!!!\n",
    "\n",
    "Como podemos saber si un producto esta discontinuado?\n",
    "* Cuando dejaron de haber ventas del mismo para siempre.\n",
    "* Estamos hablando se sell-in, que son las ventas de La Multinacional a sus clientes (cadenas de supermercados, mayoristas, distribuidores). No hablamos del sell-out que son las ventas a consumidor final.\n",
    "* La Multinacional da la bienvenida a tu idea de incorporar esos factores externos y que les expliques como afectan a sus ventas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ayer me quedó una duda respecto a la generación de filas en cero para sell in. Entiendo que es conveniente generar registros con valor cero para evitar \"huecos\" en las combinaciones de customer_id y product_id durante los períodos en que ambos están activos. Mi pregunta es: <i> Si un customer_id nunca compró un determinado producto, ¿igualmente conviene generar registros en cero para todos los períodos en los que ese cliente estuvo activo? Y, en caso de que así sea, ¿aunque el producto haya tenido ventas solo en un período y el cliente también estuvo activo en ese mismo período, igual se beneficia el análisis al agregar ese registro en cero? </i>\n",
    "* Si un customer_id nunca compró un determinado producto, ¿igualmente conviene generar registros en cero para todos los períodos en los que ese cliente estuvo activo? \n",
    " * * Afirmativo\n",
    "* Y, en caso de que así sea, ¿aunque el producto haya tenido ventas solo en un período y el cliente también estuvo activo en ese mismo período, igual se beneficia el análisis al agregar ese registro en cero?\n",
    "* * Afirmativo\n",
    "\n",
    "Si se decide utilizar solamente las 800 series de tiempo en forma individual,  ya sea para un algoritmo de la Estadistica Clasica como ARIMA  o uno de Deep Learning ,  en realidad es hacer un loop que genere 800 modelos. Ahi la informacion extra no cuenta.\n",
    "\n",
    "Si se decide utilzar un algoritmo como LightGBM es necesaria  crear un dataset estructurado a partir de las series de tiempo, y cada registro sera un   < periodo, customer_id, product_id,   multiples_campos_historicos_derivados,  informacion_externa>.   En este caso,  cada registro cuenta,  cada bit de informacion va a ayudar al LightGBM a predecir mejor, incluso un  cliente que vivio un solo mes y decidio no comprar un producto ese unico mes de efimera vida.  Ese registro contribuira a la \"probabilidad de compra\" al  \"monto promedio comprado\"  al considerarse con los datos de otros clientes ya establecidos\n",
    "\n",
    "* No le quites posibilidad de aprender al algortimo  cercenando el dataset !\n",
    "* No le quites datos outliers\n",
    "* No le quites el mes malo de 2019-08  si  existe la ingeniosa posibilidad de marcarlo como \"problematico\"\n",
    "* Se ingenioso en como incorporar a medias y lags a las ventas de un mes problematico,  aunque ello demande crear mas campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd95e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb15c1d",
   "metadata": {},
   "source": [
    "Levantamos el dataset base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9449e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas-Productos-Stocks: 2945818 filas y 13 columnas\n"
     ]
    }
   ],
   "source": [
    "# 3. MERGE INICIAL\n",
    "df = pd.read_csv(\"../data/preprocessed/base.csv\", sep=\",\")\n",
    "print(f\"Ventas-Productos-Stocks: {df.shape[0]} filas y {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2981e",
   "metadata": {},
   "source": [
    "# Iván"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe913bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas-Productos-Stocks: 2945818 filas y 13 columnas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "sellin = pd.read_csv(\"datasets/sell-in.csv\", sep='\\t')\n",
    "productos = pd.read_csv(\"datasets/tb_productos.csv\", sep='\\t')\n",
    "productos = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.csv\", sep='\\t')\n",
    "\n",
    "df = pd.merge(sellin, productos, how=\"left\", on=\"product_id\")\n",
    "df = df.merge(stocks, how=\"left\", on=[\"product_id\", \"periodo\"])\n",
    "print(f\"Ventas-Productos-Stocks: {df.shape[0]} filas y {df.shape[1]} columnas\")\n",
    "del sellin, productos, stocks\n",
    "\n",
    "df[\"periodo_dt\"] = pd.to_datetime(df[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "periodos = pd.date_range(start=df['periodo_dt'].min(), end=df['periodo_dt'].max(), freq=\"MS\")\n",
    "productos = df['product_id'].unique()\n",
    "clientes = df['customer_id'].unique()\n",
    "\n",
    "idx = pd.MultiIndex.from_product([productos, clientes, periodos], names=['product_id', 'customer_id', 'periodo'])\n",
    "completo = idx.to_frame(index=False)\n",
    "completo[\"periodo\"] = completo[\"periodo\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "\n",
    "del periodos, productos, clientes\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "completo[\"periodo_dt\"] = pd.to_datetime(completo[\"periodo\"].astype(str), format=\"%Y%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd71b1",
   "metadata": {},
   "source": [
    "Eliminar productos que no nacieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ace77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset filtrado con 21,425,136 filas.\n"
     ]
    }
   ],
   "source": [
    "nacimiento_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\"]).reset_index()\n",
    "# Renombrar columna max a muerte_cliente_dt\n",
    "nacimiento_producto = nacimiento_producto.rename(columns={'min': 'nacimiento_producto'})\n",
    "\n",
    "\n",
    "# Unir con df_final para traer fecha de muerte del cliente\n",
    "completo = completo.merge(nacimiento_producto, on='product_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt > muerte_cliente_dt\n",
    "completo = completo[completo['periodo_dt'] >= completo['nacimiento_producto']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final = df_final.drop(columns=['muerte_cliente_dt'])\n",
    "\n",
    "print(f\"✅ Dataset filtrado con {len(completo):,} filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del nacimiento_producto\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f393d",
   "metadata": {},
   "source": [
    "Eliminar productos que murieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset filtrado con 18,818,634 filas.\n"
     ]
    }
   ],
   "source": [
    "muerte_de_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"max\"]).reset_index()\n",
    "# Renombrar columna max a muerte_cliente_dt\n",
    "muerte_de_producto = muerte_de_producto.rename(columns={'max': 'muerte_de_producto'})\n",
    "\n",
    "\n",
    "# Unir con df_final para traer fecha de muerte del cliente\n",
    "completo = completo.merge(muerte_de_producto, on='product_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt > muerte_cliente_dt\n",
    "completo = completo[completo['periodo_dt'] <= completo['muerte_de_producto']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final = df_final.drop(columns=['muerte_cliente_dt'])\n",
    "\n",
    "print(f\"✅ Dataset filtrado con {len(completo):,} filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del muerte_de_producto\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd628e",
   "metadata": {},
   "source": [
    "Eliminamos clientes que murieron: por ahora no aplicarlo, porque no tendria sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c168b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset filtrado con 17,208,299 filas.\n"
     ]
    }
   ],
   "source": [
    "# df_final[\"periodo_dt\"] = pd.to_datetime(df_final[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "muerte_cliente = df.groupby(\"customer_id\")[\"periodo_dt\"].agg([\"max\"]).reset_index()\n",
    "\n",
    "# Renombrar columna max a muerte_cliente_dt\n",
    "muerte_cliente = muerte_cliente.rename(columns={'max': 'muerte_cliente_dt'})\n",
    "\n",
    "# Unir con df_final para traer fecha de muerte del cliente\n",
    "completo = completo.merge(muerte_cliente, on='customer_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt > muerte_cliente_dt\n",
    "completo = completo[completo['periodo_dt'] <= completo['muerte_cliente_dt']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final = df_final.drop(columns=['muerte_cliente_dt'])\n",
    "\n",
    "print(f\"✅ Dataset filtrado con {len(completo):,} filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8664db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del muerte_cliente\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971bbab",
   "metadata": {},
   "source": [
    "Eliminamos clientes que no nacieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e285b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset filtrado con 17,173,448 filas.\n"
     ]
    }
   ],
   "source": [
    "# df_final[\"periodo_dt\"] = pd.to_datetime(df_final[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "nacimiento_cliente = df.groupby(\"customer_id\")[\"periodo_dt\"].agg([\"min\"]).reset_index()\n",
    "\n",
    "# Renombrar columna max a nacimiento_cliente_dt\n",
    "nacimiento_cliente = nacimiento_cliente.rename(columns={'min': 'nacimiento_cliente_dt'})\n",
    "\n",
    "# Unir con df_final para traer fecha de muerte del cliente\n",
    "completo = completo.merge(nacimiento_cliente, on='customer_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt > nacimiento_cliente_dt\n",
    "completo = completo[completo['periodo_dt'] >= completo['nacimiento_cliente_dt']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final = df_final.drop(columns=['nacimiento_cliente_dt'])\n",
    "\n",
    "print(f\"✅ Dataset filtrado con {len(completo):,} filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ca870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del nacimiento_cliente\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = completo['periodo'] == 201912\n",
    "completo[mask]['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b09b2",
   "metadata": {},
   "source": [
    "Cruzamos con productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f1e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "productos = pd.read_csv(\"../data/raw/tb_productos.csv\", sep='\\t')\n",
    "productos = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "completo = completo.merge(productos, how='left', on=\"product_id\")\n",
    "del productos\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a626b",
   "metadata": {},
   "source": [
    "Cruzamos con stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10af8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>periodo_dt</th>\n",
       "      <th>nacimiento_producto</th>\n",
       "      <th>muerte_de_producto</th>\n",
       "      <th>nacimiento_cliente_dt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201701</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201702</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201703</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201704</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201705</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id  periodo periodo_dt nacimiento_producto  \\\n",
       "0       20524        10234   201701 2017-01-01          2017-01-01   \n",
       "1       20524        10234   201702 2017-02-01          2017-01-01   \n",
       "2       20524        10234   201703 2017-03-01          2017-01-01   \n",
       "3       20524        10234   201704 2017-04-01          2017-01-01   \n",
       "4       20524        10234   201705 2017-05-01          2017-01-01   \n",
       "\n",
       "  muerte_de_producto nacimiento_cliente_dt cat1     cat2        cat3  \\\n",
       "0         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "1         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "2         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "3         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "4         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "\n",
       "       brand  sku_size  stock_final  \n",
       "0  Importado     500.0          NaN  \n",
       "1  Importado     500.0          NaN  \n",
       "2  Importado     500.0          NaN  \n",
       "3  Importado     500.0          NaN  \n",
       "4  Importado     500.0          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"../data/raw/tb_stocks.csv\", sep='\\t')\n",
    "stocks = stocks.groupby(by=[\"periodo\", \"product_id\"]).agg({\"stock_final\": \"sum\"}).reset_index()\n",
    "completo = completo.merge(stocks, how='left', on=['periodo', 'product_id'])\n",
    "del stocks\n",
    "gc.collect()\n",
    "completo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f43517",
   "metadata": {},
   "source": [
    "Cruzamos con ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe83daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sellin = pd.read_csv(\"../data/raw/sell-in.csv\", sep='\\t')\n",
    "# Agrupar ventas por periodo, cliente y producto\n",
    "dt = sellin.groupby(by=[\"periodo\",\"customer_id\",\"product_id\"]).agg({\"tn\":\"sum\",\n",
    "                                                                \"cust_request_tn\":\"sum\",\n",
    "                                                                \"cust_request_qty\":\"sum\",\n",
    "                                                                \"plan_precios_cuidados\":\"first\"\n",
    "                                                                }).reset_index()\n",
    "df_completo = completo.merge(dt, how='left', on=['periodo', 'customer_id','product_id'])\n",
    "df_completo['tn'] = df_completo['tn'].fillna(0)\n",
    "del sellin, dt, completo\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d28d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>periodo_dt</th>\n",
       "      <th>nacimiento_producto</th>\n",
       "      <th>muerte_de_producto</th>\n",
       "      <th>nacimiento_cliente_dt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201701</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201702</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201703</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201704</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201705</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id  periodo periodo_dt nacimiento_producto  \\\n",
       "0       20524        10234   201701 2017-01-01          2017-01-01   \n",
       "1       20524        10234   201702 2017-02-01          2017-01-01   \n",
       "2       20524        10234   201703 2017-03-01          2017-01-01   \n",
       "3       20524        10234   201704 2017-04-01          2017-01-01   \n",
       "4       20524        10234   201705 2017-05-01          2017-01-01   \n",
       "\n",
       "  muerte_de_producto nacimiento_cliente_dt cat1     cat2        cat3  \\\n",
       "0         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "1         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "2         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "3         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "4         2019-12-01            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "\n",
       "       brand  sku_size  stock_final       tn  cust_request_tn  \\\n",
       "0  Importado     500.0          NaN  0.05300          0.05300   \n",
       "1  Importado     500.0          NaN  0.00000              NaN   \n",
       "2  Importado     500.0          NaN  0.01514          0.01514   \n",
       "3  Importado     500.0          NaN  0.00000              NaN   \n",
       "4  Importado     500.0          NaN  0.00000              NaN   \n",
       "\n",
       "   cust_request_qty  plan_precios_cuidados  \n",
       "0               2.0                    0.0  \n",
       "1               NaN                    NaN  \n",
       "2               1.0                    0.0  \n",
       "3               NaN                    NaN  \n",
       "4               NaN                    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_completo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>periodo_dt</th>\n",
       "      <th>nacimiento_producto</th>\n",
       "      <th>muerte_de_producto</th>\n",
       "      <th>nacimiento_cliente_dt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201701</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201702</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201703</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201704</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201705</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  customer_id  periodo periodo_dt  nacimiento_producto  \\\n",
       "0       20524        10234   201701 2017-01-01               201701   \n",
       "1       20524        10234   201702 2017-02-01               201701   \n",
       "2       20524        10234   201703 2017-03-01               201701   \n",
       "3       20524        10234   201704 2017-04-01               201701   \n",
       "4       20524        10234   201705 2017-05-01               201701   \n",
       "\n",
       "   muerte_de_producto nacimiento_cliente_dt cat1     cat2        cat3  \\\n",
       "0              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "1              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "2              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "3              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "4              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "\n",
       "       brand  sku_size  stock_final       tn  cust_request_tn  \\\n",
       "0  Importado     500.0          NaN  0.05300          0.05300   \n",
       "1  Importado     500.0          NaN  0.00000              NaN   \n",
       "2  Importado     500.0          NaN  0.01514          0.01514   \n",
       "3  Importado     500.0          NaN  0.00000              NaN   \n",
       "4  Importado     500.0          NaN  0.00000              NaN   \n",
       "\n",
       "   cust_request_qty  plan_precios_cuidados  \n",
       "0               2.0                    0.0  \n",
       "1               NaN                    NaN  \n",
       "2               1.0                    0.0  \n",
       "3               NaN                    NaN  \n",
       "4               NaN                    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Unir con datos reales\n",
    "df_completo[\"nacimiento_producto\"] = df_completo[\"nacimiento_producto\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "df_completo[\"muerte_de_producto\"] = df_completo[\"muerte_de_producto\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "df_completo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e96308",
   "metadata": {},
   "source": [
    "Creamos el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2215b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarte de tener 'periodo_dt' (datetime) en completo\n",
    "df_completo['periodo_dt'] = pd.to_datetime(df_completo['periodo'], format='%Y%m')\n",
    "\n",
    "# Crear DataFrame auxiliar con tn como target y fecha adelantada\n",
    "ventas_futuras = df_completo[['periodo_dt', 'customer_id', 'product_id', 'tn']].copy()\n",
    "ventas_futuras['periodo_target_dt'] = ventas_futuras['periodo_dt'] - pd.DateOffset(months=2)\n",
    "ventas_futuras = ventas_futuras.rename(columns={'tn': 'target'})\n",
    "\n",
    "# Merge con completo usando periodo adelantado\n",
    "df_completo = df_completo.merge(\n",
    "    ventas_futuras[['periodo_target_dt', 'customer_id', 'product_id', 'target']],\n",
    "    how='left',\n",
    "    left_on=['periodo_dt', 'customer_id', 'product_id'],\n",
    "    right_on=['periodo_target_dt', 'customer_id', 'product_id']\n",
    ")\n",
    "\n",
    "# Eliminar columna auxiliar\n",
    "df_completo = df_completo.drop(columns=['periodo_target_dt'])\n",
    "\n",
    "print(f\"✅ Target generado. Filas con target no nulo: {df_completo['target'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>periodo_dt</th>\n",
       "      <th>nacimiento_producto</th>\n",
       "      <th>muerte_de_producto</th>\n",
       "      <th>nacimiento_cliente_dt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201701</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201702</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201703</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201704</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201705</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201706</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03786</td>\n",
       "      <td>0.03786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201707</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201708</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201709</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201710</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201711</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07571</td>\n",
       "      <td>0.07571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201712</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20524</td>\n",
       "      <td>10234</td>\n",
       "      <td>201801</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201912</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  customer_id  periodo periodo_dt  nacimiento_producto  \\\n",
       "0        20524        10234   201701 2017-01-01               201701   \n",
       "1        20524        10234   201702 2017-02-01               201701   \n",
       "2        20524        10234   201703 2017-03-01               201701   \n",
       "3        20524        10234   201704 2017-04-01               201701   \n",
       "4        20524        10234   201705 2017-05-01               201701   \n",
       "5        20524        10234   201706 2017-06-01               201701   \n",
       "6        20524        10234   201707 2017-07-01               201701   \n",
       "7        20524        10234   201708 2017-08-01               201701   \n",
       "8        20524        10234   201709 2017-09-01               201701   \n",
       "9        20524        10234   201710 2017-10-01               201701   \n",
       "10       20524        10234   201711 2017-11-01               201701   \n",
       "11       20524        10234   201712 2017-12-01               201701   \n",
       "12       20524        10234   201801 2018-01-01               201701   \n",
       "\n",
       "    muerte_de_producto nacimiento_cliente_dt cat1     cat2        cat3  \\\n",
       "0               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "1               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "2               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "3               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "4               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "5               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "6               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "7               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "8               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "9               201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "10              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "11              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "12              201912            2017-01-01   HC  VAJILLA  Cristalino   \n",
       "\n",
       "        brand  sku_size  stock_final       tn  cust_request_tn  \\\n",
       "0   Importado     500.0          NaN  0.05300          0.05300   \n",
       "1   Importado     500.0          NaN  0.00000              NaN   \n",
       "2   Importado     500.0          NaN  0.01514          0.01514   \n",
       "3   Importado     500.0          NaN  0.00000              NaN   \n",
       "4   Importado     500.0          NaN  0.00000              NaN   \n",
       "5   Importado     500.0          NaN  0.03786          0.03786   \n",
       "6   Importado     500.0          NaN  0.00000              NaN   \n",
       "7   Importado     500.0          NaN  0.00000              NaN   \n",
       "8   Importado     500.0          NaN  0.00000              NaN   \n",
       "9   Importado     500.0          NaN  0.00000              NaN   \n",
       "10  Importado     500.0          NaN  0.07571          0.07571   \n",
       "11  Importado     500.0          NaN  0.00000              NaN   \n",
       "12  Importado     500.0          NaN  0.00000              NaN   \n",
       "\n",
       "    cust_request_qty  plan_precios_cuidados   target  \n",
       "0                2.0                    0.0  0.01514  \n",
       "1                NaN                    NaN  0.00000  \n",
       "2                1.0                    0.0  0.00000  \n",
       "3                NaN                    NaN  0.03786  \n",
       "4                NaN                    NaN  0.00000  \n",
       "5                1.0                    0.0  0.00000  \n",
       "6                NaN                    NaN  0.00000  \n",
       "7                NaN                    NaN  0.00000  \n",
       "8                NaN                    NaN  0.07571  \n",
       "9                NaN                    NaN  0.00000  \n",
       "10               1.0                    0.0  0.00000  \n",
       "11               NaN                    NaN  0.00000  \n",
       "12               NaN                    NaN  0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_completo.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e6182",
   "metadata": {},
   "source": [
    "Verifico las NaN en el target: Existen porque hay clientes que solo compraron 2 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b433ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total de NaN en target: 1431761\n"
     ]
    }
   ],
   "source": [
    "nan_count = df_completo['target'].isna().sum()\n",
    "print(f\"🔍 Total de NaN en target: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>periodo_dt</th>\n",
       "      <th>nacimiento_producto</th>\n",
       "      <th>muerte_de_producto</th>\n",
       "      <th>nacimiento_cliente_dt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312896</th>\n",
       "      <td>21151</td>\n",
       "      <td>10234</td>\n",
       "      <td>201805</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201806</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>SOPAS Y CALDOS</td>\n",
       "      <td>Salsas Dry</td>\n",
       "      <td>MAGGI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312897</th>\n",
       "      <td>21151</td>\n",
       "      <td>10234</td>\n",
       "      <td>201806</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201806</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>SOPAS Y CALDOS</td>\n",
       "      <td>Salsas Dry</td>\n",
       "      <td>MAGGI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312914</th>\n",
       "      <td>21151</td>\n",
       "      <td>10032</td>\n",
       "      <td>201805</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201806</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>SOPAS Y CALDOS</td>\n",
       "      <td>Salsas Dry</td>\n",
       "      <td>MAGGI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312915</th>\n",
       "      <td>21151</td>\n",
       "      <td>10032</td>\n",
       "      <td>201806</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201806</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>SOPAS Y CALDOS</td>\n",
       "      <td>Salsas Dry</td>\n",
       "      <td>MAGGI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312932</th>\n",
       "      <td>21151</td>\n",
       "      <td>10217</td>\n",
       "      <td>201805</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>201701</td>\n",
       "      <td>201806</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>SOPAS Y CALDOS</td>\n",
       "      <td>Salsas Dry</td>\n",
       "      <td>MAGGI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17118772</th>\n",
       "      <td>21216</td>\n",
       "      <td>10504</td>\n",
       "      <td>201910</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>201910</td>\n",
       "      <td>201911</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>VIVERE</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7.99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17118774</th>\n",
       "      <td>21216</td>\n",
       "      <td>10455</td>\n",
       "      <td>201910</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>201910</td>\n",
       "      <td>201911</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>VIVERE</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7.99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17118776</th>\n",
       "      <td>21216</td>\n",
       "      <td>10479</td>\n",
       "      <td>201910</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>201910</td>\n",
       "      <td>201911</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>VIVERE</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7.99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17118778</th>\n",
       "      <td>21216</td>\n",
       "      <td>10538</td>\n",
       "      <td>201910</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>201910</td>\n",
       "      <td>201911</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>VIVERE</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7.99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17118780</th>\n",
       "      <td>21216</td>\n",
       "      <td>10373</td>\n",
       "      <td>201910</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>201910</td>\n",
       "      <td>201911</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>VIVERE</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7.99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317257 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_id  customer_id  periodo periodo_dt  nacimiento_producto  \\\n",
       "312896         21151        10234   201805 2018-05-01               201701   \n",
       "312897         21151        10234   201806 2018-06-01               201701   \n",
       "312914         21151        10032   201805 2018-05-01               201701   \n",
       "312915         21151        10032   201806 2018-06-01               201701   \n",
       "312932         21151        10217   201805 2018-05-01               201701   \n",
       "...              ...          ...      ...        ...                  ...   \n",
       "17118772       21216        10504   201910 2019-10-01               201910   \n",
       "17118774       21216        10455   201910 2019-10-01               201910   \n",
       "17118776       21216        10479   201910 2019-10-01               201910   \n",
       "17118778       21216        10538   201910 2019-10-01               201910   \n",
       "17118780       21216        10373   201910 2019-10-01               201910   \n",
       "\n",
       "          muerte_de_producto nacimiento_cliente_dt   cat1            cat2  \\\n",
       "312896                201806            2017-01-01  FOODS  SOPAS Y CALDOS   \n",
       "312897                201806            2017-01-01  FOODS  SOPAS Y CALDOS   \n",
       "312914                201806            2017-01-01  FOODS  SOPAS Y CALDOS   \n",
       "312915                201806            2017-01-01  FOODS  SOPAS Y CALDOS   \n",
       "312932                201806            2017-01-01  FOODS  SOPAS Y CALDOS   \n",
       "...                      ...                   ...    ...             ...   \n",
       "17118772              201911            2019-10-01     HC     PROFESIONAL   \n",
       "17118774              201911            2019-10-01     HC     PROFESIONAL   \n",
       "17118776              201911            2019-10-01     HC     PROFESIONAL   \n",
       "17118778              201911            2019-10-01     HC     PROFESIONAL   \n",
       "17118780              201911            2019-10-01     HC     PROFESIONAL   \n",
       "\n",
       "                cat3   brand  sku_size  stock_final   tn  cust_request_tn  \\\n",
       "312896    Salsas Dry   MAGGI      10.0          NaN  0.0              NaN   \n",
       "312897    Salsas Dry   MAGGI      10.0          NaN  0.0              NaN   \n",
       "312914    Salsas Dry   MAGGI      10.0          NaN  0.0              NaN   \n",
       "312915    Salsas Dry   MAGGI      10.0          NaN  0.0              NaN   \n",
       "312932    Salsas Dry   MAGGI      10.0          NaN  0.0              NaN   \n",
       "...              ...     ...       ...          ...  ...              ...   \n",
       "17118772  SUAVIZANTE  VIVERE    2000.0      7.99999  0.0              NaN   \n",
       "17118774  SUAVIZANTE  VIVERE    2000.0      7.99999  0.0              NaN   \n",
       "17118776  SUAVIZANTE  VIVERE    2000.0      7.99999  0.0              NaN   \n",
       "17118778  SUAVIZANTE  VIVERE    2000.0      7.99999  0.0              NaN   \n",
       "17118780  SUAVIZANTE  VIVERE    2000.0      7.99999  0.0              NaN   \n",
       "\n",
       "          cust_request_qty  plan_precios_cuidados  target  \n",
       "312896                 NaN                    NaN     NaN  \n",
       "312897                 NaN                    NaN     NaN  \n",
       "312914                 NaN                    NaN     NaN  \n",
       "312915                 NaN                    NaN     NaN  \n",
       "312932                 NaN                    NaN     NaN  \n",
       "...                    ...                    ...     ...  \n",
       "17118772               NaN                    NaN     NaN  \n",
       "17118774               NaN                    NaN     NaN  \n",
       "17118776               NaN                    NaN     NaN  \n",
       "17118778               NaN                    NaN     NaN  \n",
       "17118780               NaN                    NaN     NaN  \n",
       "\n",
       "[317257 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (df_completo['periodo'] < 201911) & (df_completo['target'].isna())\n",
    "df_completo[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253a703",
   "metadata": {},
   "source": [
    "Guardamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.drop(columns=['periodo_dt'], inplace=True)\n",
    "df_completo.to_csv(\"../data/preprocessed/dataset.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd33182",
   "metadata": {},
   "source": [
    "# Fran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3561f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16998193, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "sellin = pd.read_csv(\"../data/raw/sell-in.csv\", sep='\\t')\n",
    "productos = pd.read_csv(\"../data/raw/tb_productos.csv\", sep='\\t')\n",
    "productos = productos.drop_duplicates(subset=['product_id'], keep='first')\n",
    "stocks = pd.read_csv(\"../data/raw/tb_stocks.csv\", sep='\\t')\n",
    "\n",
    "df = pd.merge(sellin, productos, how=\"left\", on=\"product_id\")\n",
    "df = df.merge(stocks, how=\"left\", on=[\"product_id\", \"periodo\"])\n",
    "del sellin, productos, stocks\n",
    "\n",
    "# Agrupar ventas por periodo, cliente y producto\n",
    "dt = df.groupby(by=[\"periodo\",\"customer_id\",\"product_id\"]).agg({\"tn\":\"sum\",\n",
    "                                                                \"cust_request_tn\":\"sum\",\n",
    "                                                                \"cust_request_qty\":\"sum\",\n",
    "                                                                \"cat1\":\"first\",\n",
    "                                                                \"cat2\":\"first\",\n",
    "                                                                \"cat3\":\"first\",\n",
    "                                                                \"brand\":\"first\",\n",
    "                                                                \"sku_size\":\"first\",\n",
    "                                                                \"stock_final\":\"first\",\n",
    "                                                                \"plan_precios_cuidados\":\"first\"\n",
    "                                                                }).reset_index()\n",
    "# 1. Calcular primeros períodos\n",
    "\n",
    "periodo_producto =  df.groupby(['periodo', 'product_id'])[\"tn\"].sum().rename('periodo_producto')\n",
    "nacimiento_producto = df.groupby('product_id')['periodo'].min().rename('nacimiento_producto')\n",
    "muerte_cliente = df.groupby('customer_id')['periodo'].max().rename('muerte_cliente')\n",
    "\n",
    "# 2. Crear todas las combinaciones posibles\n",
    "productos = df['product_id'].unique()\n",
    "clientes = df['customer_id'].unique()\n",
    "periodos = df['periodo'].unique()\n",
    "\n",
    "# 3. Crear matriz de combinaciones válidas usando broadcasting\n",
    "idx = pd.MultiIndex.from_product([productos, clientes, periodos], names=['product_id', 'customer_id', 'periodo'])\n",
    "completo = idx.to_frame(index=False)\n",
    "# 4 filtrar combinaciones periodo_producto\n",
    "completo = completo.merge(periodo_producto, on=['periodo', 'product_id'], how='left')\n",
    "completo = completo[completo['periodo_producto'].notna()]\n",
    "# 5 Filtrar combinaciones nacimiento_producto\n",
    "completo = completo.merge(nacimiento_producto, on='product_id', how='left')\n",
    "completo = completo[completo['periodo'] >= completo['nacimiento_producto']]\n",
    "completo = completo[completo['nacimiento_producto'] < 201910]\n",
    "\n",
    "# 6. Filtrar combinaciones muerte_cliente\n",
    "completo = completo.merge(muerte_cliente, on='customer_id', how='left')\n",
    "completo = completo[completo['periodo'] <= completo['muerte_cliente']]\n",
    "\n",
    "\n",
    "# 7. Unir con datos reales\n",
    "df_completo = completo.merge(dt, how='left')\n",
    "df_completo['tn'] = df_completo['tn'].fillna(0)\n",
    "\n",
    "# Convertir periodo a datetime con día fijo\n",
    "df_completo['periodo_dt'] = pd.to_datetime(df_completo['periodo'], format='%Y%m')\n",
    "\n",
    "# Crear columna periodo_target_dt desplazada 2 meses\n",
    "df_completo['periodo_target_dt'] = df_completo['periodo_dt'] + pd.DateOffset(months=2)\n",
    "\n",
    "# DataFrame auxiliar con ventas futuras\n",
    "ventas_futuras = df_completo[['periodo_dt', 'customer_id', 'product_id', 'tn']].copy()\n",
    "ventas_futuras = ventas_futuras.rename(columns={\n",
    "    'periodo_dt': 'periodo_target_dt',\n",
    "    'tn': 'target'\n",
    "})\n",
    "\n",
    "# Hacemos el merge usando fechas datetime directamente\n",
    "dt = pd.merge(\n",
    "    df_completo,\n",
    "    ventas_futuras,\n",
    "    how='left',\n",
    "    on=['periodo_target_dt', 'customer_id', 'product_id']\n",
    ")\n",
    "dt = dt.drop(columns=['periodo_target_dt']) # Ya usamos esta para hacer el merge\n",
    "del df_completo, ventas_futuras, completo, idx, periodo_producto, nacimiento_producto, muerte_cliente\n",
    "gc.collect()\n",
    "\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2b146",
   "metadata": {},
   "source": [
    "# Ivan Viejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que df ya contiene las columnas: periodo, customer_id, product_id, tn\n",
    "df[\"periodo_dt\"] = pd.to_datetime(df[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "# Paso 1: Rango total de periodos\n",
    "todos_los_periodos = pd.date_range(start=df[\"periodo_dt\"].min(), end=df[\"periodo_dt\"].max(), freq=\"MS\")\n",
    "\n",
    "# Paso 2: Todos los clientes únicos\n",
    "todos_los_clientes = df[\"customer_id\"].unique()\n",
    "\n",
    "# Paso 3: Determinar vida útil de cada producto\n",
    "vida_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Paso 4: Generar combinaciones (periodo, producto) considerando restricciones\n",
    "combinaciones_producto_periodo = []\n",
    "fecha_limite_nuevos = pd.to_datetime(\"2020-03\", format=\"%Y-%m\")\n",
    "\n",
    "\n",
    "\n",
    "for _, row in vida_producto.iterrows():\n",
    "    producto = row[\"product_id\"]\n",
    "    min_fecha = row[\"min\"]\n",
    "    max_fecha = row[\"max\"]\n",
    "    periodos_validos = pd.date_range(start=min_fecha, end=max_fecha, freq=\"MS\")\n",
    "    es_nuevo = min_fecha >= fecha_limite_nuevos  # solo si el producto es nuevo a partir de 2017-02\n",
    "    \n",
    "    for p in periodos_validos:\n",
    "        # if producto in productos_vitales:\n",
    "        #     combinaciones_producto_periodo.append((p, producto))\n",
    "        #     continue\n",
    "        # # Excluir primeros 3 meses si es nuevo (a partir de 2017-02)\n",
    "        # if es_nuevo and (p < min_fecha + pd.DateOffset(months=3)):\n",
    "        #     continue\n",
    "        # # Excluir últimos 3 meses del producto\n",
    "        # if p > max_fecha - pd.DateOffset(months=3):\n",
    "        #     continue\n",
    "        combinaciones_producto_periodo.append((p, producto))\n",
    "\n",
    "df_producto_periodo = pd.DataFrame(combinaciones_producto_periodo, columns=[\"periodo_dt\", \"product_id\"])\n",
    "\n",
    "# Paso 5: Generar combinaciones de todos los clientes con (periodo, producto)\n",
    "combinaciones = []\n",
    "for _, row in df_producto_periodo.iterrows():\n",
    "    periodo = row[\"periodo_dt\"]\n",
    "    producto = row[\"product_id\"]\n",
    "    for cliente in todos_los_clientes:\n",
    "        # if producto in df[df[\"customer_id\"] == cliente][\"product_id\"].unique(): ###### <------ ESTO TARDA 3 AÑOS\n",
    "        combinaciones.append((periodo, producto, cliente)) \n",
    "\n",
    "df_completo = pd.DataFrame(combinaciones, columns=[\"periodo_dt\", \"product_id\", \"customer_id\"])\n",
    "\n",
    "# Paso 6: Unir con toneladas efectivas\n",
    "df_merge = df_completo.merge(df[[\"periodo_dt\", \"product_id\", \"customer_id\", \"tn\"]],\n",
    "                             on=[\"periodo_dt\", \"product_id\", \"customer_id\"],\n",
    "                             how=\"left\")\n",
    "df_merge[\"tn\"] = df_merge[\"tn\"].fillna(0)\n",
    "\n",
    "# Paso 7: Recuperar periodo AAAAMM si lo necesitás\n",
    "df_merge[\"periodo\"] = df_merge[\"periodo_dt\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "\n",
    "# Resultado final\n",
    "df_final = df_merge[[\"periodo\", \"product_id\", \"customer_id\", \"tn\"]]\n",
    "\n",
    "# Vista previa\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e4fd7",
   "metadata": {},
   "source": [
    "Elimino los clientes que murieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset filtrado con 17,208,299 filas.\n"
     ]
    }
   ],
   "source": [
    "df_final[\"periodo_dt\"] = pd.to_datetime(df_final[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "muerte_cliente = df.groupby(\"customer_id\")[\"periodo_dt\"].agg([\"max\"]).reset_index()\n",
    "\n",
    "# Renombrar columna max a muerte_cliente_dt\n",
    "muerte_cliente = muerte_cliente.rename(columns={'max': 'muerte_cliente_dt'})\n",
    "\n",
    "# Unir con df_final para traer fecha de muerte del cliente\n",
    "df_final = df_final.merge(muerte_cliente, on='customer_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt > muerte_cliente_dt\n",
    "df_final = df_final[df_final['periodo_dt'] <= df_final['muerte_cliente_dt']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final = df_final.drop(columns=['muerte_cliente_dt'])\n",
    "\n",
    "print(f\"✅ Dataset filtrado con {len(df_final):,} filas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77557b71",
   "metadata": {},
   "source": [
    "Quito los productos nuevos a partir de 2019-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista de productos muy nuevos\n",
    "nacimiento_producto = df.groupby(\"product_id\")[\"periodo_dt\"].agg([\"min\"]).reset_index()\n",
    "nacimiento_producto = nacimiento_producto.rename(columns={'min': 'nacimiento_producto'})\n",
    "productos_muy_nuevos = nacimiento_producto[nacimiento_producto['nacimiento_producto'] > '2019-10-01']['product_id']\n",
    "\n",
    "\n",
    "df_final_copy = df_final.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Filtrar df_final para eliminar esos productos\n",
    "df_final_copy = df_final_copy[~df_final_copy['product_id'].isin(productos_muy_nuevos)]\n",
    "\n",
    "print(f\"✅ Dataset filtrado: {len(df_final_copy):,} filas restantes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8f1ef",
   "metadata": {},
   "source": [
    "Verifico que los productos que voy a predecir esten en 2019-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4765ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos los productos de 'productitos' están en df_final_copy[mask]: True\n",
      "🔍 Productos faltantes: set()\n"
     ]
    }
   ],
   "source": [
    "mask = df_final_copy['periodo'] == 201912\n",
    "df_final_copy[mask]['product_id'].nunique()\n",
    "\n",
    "productitos = pd.read_csv(\"../data/raw/product_id_apredecir201912.csv\")\n",
    "productitos['product_id']\n",
    "\n",
    "\n",
    "# Obtener los conjuntos\n",
    "productos_en_df = set(df_final_copy[mask]['product_id'].unique())\n",
    "productos_de_productitos = set(productitos['product_id'].unique())\n",
    "\n",
    "# Verificar si todos están incluidos\n",
    "estan_todos = productos_de_productitos.issubset(productos_en_df)\n",
    "\n",
    "print(f\"✅ Todos los productos de 'productitos' están en df_final_copy[mask]: {estan_todos}\")\n",
    "\n",
    "# Si querés ver cuáles faltan\n",
    "productos_faltantes = productos_de_productitos - productos_en_df\n",
    "print(f\"🔍 Productos faltantes: {productos_faltantes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65528b7",
   "metadata": {},
   "source": [
    "Verifico si hay duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4411760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hay duplicados: False\n"
     ]
    }
   ],
   "source": [
    "duplicados = df_final_copy.duplicated(subset=['periodo', 'product_id', 'customer_id'], keep=False)\n",
    "\n",
    "# Mostrar si hay duplicados\n",
    "hay_duplicados = duplicados.any()\n",
    "print(f\"✅ Hay duplicados: {hay_duplicados}\")\n",
    "\n",
    "# Si querés ver las filas duplicadas\n",
    "if hay_duplicados:\n",
    "    filas_duplicadas = df_final_copy[duplicados]\n",
    "    print(f\"🔍 Total de filas duplicadas: {len(filas_duplicadas)}\")\n",
    "    print(filas_duplicadas.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4484bde",
   "metadata": {},
   "source": [
    "Elimino clientes que no habian nacido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset final filtrado: 15,563,113 filas restantes.\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'periodo' a datetime (si no lo hiciste antes)\n",
    "df_final_copy = df_final.copy()\n",
    "\n",
    "df_final_copy[\"periodo_dt\"] = pd.to_datetime(df_final_copy[\"periodo\"].astype(str), format=\"%Y%m\")\n",
    "\n",
    "# Calcular nacimiento del cliente (primer compra de cualquier producto)\n",
    "nacimiento_cliente = df.groupby(\"customer_id\")[\"periodo_dt\"].min().reset_index().rename(columns={'periodo_dt': 'nacimiento_cliente'})\n",
    "\n",
    "# Unir con df_final_copy para traer fecha de nacimiento del cliente\n",
    "df_final_copy = df_final_copy.merge(nacimiento_cliente, on='customer_id', how='left')\n",
    "\n",
    "# Filtrar filas donde periodo_dt < nacimiento_cliente\n",
    "df_final_copy = df_final_copy[df_final_copy['periodo_dt'] >= df_final_copy['nacimiento_cliente']]\n",
    "\n",
    "# Opcional: eliminar columna auxiliar\n",
    "# df_final_copy = df_final_copy.drop(columns=['nacimiento_cliente'])\n",
    "\n",
    "print(f\"✅ Dataset final filtrado: {len(df_final_copy):,} filas restantes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789edb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del df_final_copy\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
